처음 공유는 11시부터라고 되어 있는데 알고보니 11:50분부터 시작
네트워크 신청이 매우 빠르게 마감됨 (알림 떠서 링크 눌러보면 전부 마감)

## 당근 알바 초기 엔지니어링 전략

- 초기에 제품을 빠르게 만드는게 -> 초기 사용자에게 더 많은 가치를 전달한다고 판단함
  - 제품 생산성을 고민(가장 중요한 것에 집중)할 수 밖에 없음

### 빠르게 데이터 분석하기

- 데이터 분석은 사용자의 피드백을 가장 바르게 얻을 수 있는 수단
- 가설 -> 실험 -> 검증의 루프를 도렴ㄴ서 빠른 의사결정에 도움
- 데이터 분석에 드는 비용은 데이터 분석을 위한 엔지니어링 비용 + 데이터 분석 활동에 드는 비용
- 이벤트 기반 분석 서비스 활용
  - 데이터 분석을 위한 DB와 쿼리가 피료없음

### 필요한 것만 구현하기

- 실험에 필요한 정도만 구현 -> 추가 실험이 필요하면 그 시점에 또 구현

### 효율적으로 에러 대응하기

- 기존에는 하던 작업을 멈춤 -> 원인을 파악 -> 수정
- 에러 대응은 컨텍스트 전환 비용 + 대응에 걸리는 시간이 필요
- 에러가 발생 빈도가 낮고 핵심 기능에 영향을 미치지 않는다면 바로 대응하지 않고 모니터링
- 당근 알바팀에게 중요한건 현재 작업을 빠르게 만드는 것. 에러의 우선순위가 낮다면 시간이 될 때 해결

### 클라이언트와 효율적으로 협업하기

- 클라이언트가 서버의 데이터를 유연하게 가져가기 위해 GraphQL을 활용

## 당근 채팅 시스템은 어떻게 만들까?

### 채팅 메시지는 어떻게 전달될까?

- 당근은 다양한 서비스를 위한 1:1 채팅과 커뮤니티를 위한 그룹 채팅을 제공
- 간단한 구조로 보면 chat-server, db, push-server가 존재
- 서버가 다수일때 1:1 채팅은 각 유저의 세션 정보를 저장할 공용 redis가 필요
- 서버가 10대라고 가정할 때, 서버마다 통신하면 결합도가 증가하므로 메시지 큐와 컨슈머 구조로 채팅

### 채팅 데이터는 어떻게 저장될까

- 당근 채팅의 특징은 3900만의 유저의 채팅이 서버에 영구적으로 저장됨
- 얘전에는 당근의 여러 서버가 하나의 RDB를 사용함
  - MAU가 높아지면서 데이터의 양도 폭발적으로 높아지고 있는 상황
  - 쿼리를 튜닝하고 인덱스를 붙이고 캐시를 붙이며 최적화를 했지만 물리 장비의 한계에 도달
  - scale up을 헀지만 사용자가 많아져서 peak 때 DB cpu가 90%를 넘는 상황도 발생
  - 이떄 채팅은 RDB 용량의 60%를 차지하고 있어 채팅 관련해 장애가 나면 전사에 장애가 발생
- 채팅 DB를 main DB와 분리하면서도 확장성과 실시간성을 고려함
  - 샤딩을 통해 채팅을 분산함
  - 가능한 적은 샤드에서 데이터를 얻어야 함. 이때 중요한게 샤드 키로 엑세스 패턴에 맞는 샤드 키를 선택하는지가 중요
  - 샤드키만 설정하면 자동으로 샤딩을 하고 관리하기 매우 편한 AWS dynamoDB를 사용.

## 당근의 회원 시스템을 마이크로서비스로 분리하기

- 회원이 국내 뿐 아니라 해외에서도 점차 급증함
  - 불안정한 시스템 + 누적된 기술 부채가 발생
- 초기 당근은 모놀리스 시스템으로 한 서비스에서 장애가 발생하면 전체 서비스로 전파됨
- 서비스가 성장하면서 다양한 요구사항들(개인정보, 인증수단 등)이 발생
  - 기존 회원 시스템은 누적된 기술부채로 이런 요구사항을 빠르게 진행할 수 없었음
- 안정성과 확장성을 고려해 기존 회원 시스템을 개선하기로 함
  - 마이크로 서비스로 분리
  - ruby on rails -> golang 으로 언어 변경
  - 명시적이고 확장 가능한 API로 개선
- 기존 앱을 업데이트 하지 않고 신규 회원 시스템을 사용하는 방법을 고민
  - istio의 proxy 기능을 활용해 기존 회원 시스템이 신규 회원 시스템으로 전달
  - Go 언어로 작성된 서버 sidecar를 활용해 로드밸런싱해 기존 회원 시스템이 99%에서 점차 신규 회원 시스템이 100% 응답을 제공하도록 함
