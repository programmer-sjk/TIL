# 아파치 카프카 애플리케이션 프로그래밍 with 자바

- [책 링크](https://www.yes24.com/Product/Goods/99122569)

## 1. 들어가며

### 1.1 카프카의 탄생

- 링크드인은 초기에 단방향 통신을 통해 소스 어플리케이션에서 타겟 어플리케이션으로 연동하는 소스 코드를 작성하여 운영했다. 시간이 지날수록 아키텍처는 복잡해졌고 소스/타겟 어플리케이션이 많아지면서 데이터를 전송하는 라인이 복잡해지기 시작했다.
- 링크드인의 데이터 팀은 신규 시스템을 만들기로 결정했고 그 결과물이 아파치 카프카다. 각 어플리케이션이 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화했다. 웹 사이트, 어플리케이션, 센서에서 취합한 데이터 스트림을 카프카 한 곳에서 수집하고 사용자들이 실시간으로 소비할 수 있게 동작한다.
- 기존에 1:1 매칭으로 운영하던 시스템에선 한쪽의 장애가 한쪽에 영향을 미치곤 했지만 카프카는 이러한 의존도를 타파한다. 소스 어플리케이션에서 생성되는 데이터는 어떤 타겟 어플리케이션으로 보낼 것인지 고민하지 않고 카프카로 넣으면 된다. 카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO 방식의 큐와 유사하다. 큐에 데이터를 보내는 것이 프로듀서고, 큐에서 데이터를 가져가는 것이 컨슈머다.
- 상용 환경에서 카프카는 3대 이상의 브로커에서 분산 운영하여 데이터를 안전하게 기록한다. 3대 이상으로 이루어진 카프카 클러스터 중 일부 서버에 장애가 발생하더라도 데이터를 지속적으로 복제하기 때문에 안전하게 운영할 수 있다.

### 1.2 빅데이터 파이프라인에서 카프카 역할

- 빅 데이터를 저장하고 활용하기 위해, 우선 생성되는 데이터를 모두 모으는 것이 중요한데 이때 사용되는 개념이 데이터 레이크다. 데이터 웨어 하우스와는 다르게 필터링되거나 패키지화 되지 않은 데이터가 저장된다는 점이 특징이다.
- 서비스에서 발생하는 데이터를 데이터 레이크에 모으려면 단순히 생각할 때 발생하는 데이터를 직접 end-to-end 방식으로 넣을 수 있다. 하지만 서비스가 커지고 복잡해질수록 링크드인처럼 파편화되고 복잡도가 올라가는 문제가 발생한다. 이 때 데이터 파이프라인을 안정적이고 확장성 높게 운영하기 위해 좋은 방법 중 하나가 카프카를 활용하는 것이다. 왜 카프카가 적합한지 상세히 살펴보자.
  - 높은 처리량: 카프카는 프로듀서/컨슈머가 데이터를 보내고 받을 때 모두 묶어서 전송한다. 많은 양의 데이터를 묶음 단위로 배치에서 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는데 적합하다.
  - 확장성: 카프카는 데이터 양이 가변적인 환경에서 안정적으로 확장 가능하도록 설계되었다. 데이터가 적을 때는 브로커를 최소한의 개수로 운영하다가 데이터가 많아지면 브로커 개수를 늘려 스케일 아웃 할 수 있다.
  - 영속성: 영속성은 프로그램이 종료되더라도 사라지지 않는 데이터 특성을 뜻한다. 카프카는 다른 메시징 시스템과는 다르게 전송받은 데이터를 파일 시스템에 저장한다. 파일 시스템을 사용하는 것이 느리다고 생각하겠지만 카프카는 OS 레벨에서 파일 I/O 성능 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성해서 사용한다.
  - 고가용성: 3개 이상의 서버로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
- 카프카 클러스터를 3대 이상의 브로커들로 구성해야 하는 이유
  - 브로커를 1대만 유지한다면 테스트 목적으로만 사용한다.
  - 브로커를 2대로 유지하면 한 대의 브로커에 장애가 발생하더라도 한 대가 살아 있어 안정적으로 데이터를 처리할 수 있다. 하지만 브로커 간에 데이터가 복제되는 시간차이로 일부 데이터가 유실될 가능성이 있다. 예를 들면 leader가 데이터를 받고 follower가 복제를 해야 하는데 leader가 죽은 경우.
  - 유실을 막기 위해 min.insync.replicas 옵션을 사용할 수 있는데 2로 설정하면 최소 2개 이상의 브로커에 데이터가 완전히 복제됨을 보장한다. 이 옵션을 2로 설정하면 브로커를 3대 이상으로 운영해야 한다.
  - 정리하면 유실없이 데이터를 복제하기 위해 min.insync.replicas 값을 2로 설정해야 한다. 그래야 최소 2개 이상의 브로커에 데이터가 완전히 복제되니까. 근데 브로커가 2대이면 한 대가 죽을 경우 replicas 2보다 작은 한 대의 브로커만 받기 때문에 에러가 발생한다. 따라서 3대로 운영하고 min.insync.replicas 값이 2면 카프카 한 대가 죽어도 정상적으로 동작한다.

### 1.3 데이터 레이크 아키텍처와 카프카 미래

- 데이터 레이크를 구성하는 아키텍처는 크게 람다 아키텍처와 카파 아키텍처가 있다.
- 람다 아키텍처는 기존 e2e로 데이터를 수집하는 레거시를 개선하기 위해 구성된 아키텍처다. 배치 데이터를 일괄 처리하는 배치 레이어, 가공된 데이터를 제공하는 서빙 레이어, 실시간으로 데이터를 분석하는 스피드 레이어로 구성된다.
- 람다 아키텍처는 데이터를 배치 처리하는 레이어와 실시간 처리를 분담할 수 있었지만, 레이어가 2개로 나뉘기 때문에 생기는 단점들도 있었다. 제이 크랩스는 람다 아키텍처에서 배치 레이어를 제거한 카파 아키텍처를 제안했다.
- 카파 아키텍처에서는 스피드 레이어에서 데이터를 모두 처리할 수 있어 효율적으로 개발과 운영을 할 수 있었으나 서비스에서 생성되는 모든 종류의 데이터를 스트림 처리해야 했고, 서비스에서 생성된 모든 데이터가 스피드 레이어에 들어오는 것을 감안하면 내결함성과 장애 허용 특징을 지녀야 했다. 아파치 카프카는 이런 특성에 정확히 부합하는 플랫폼이다.

## 2. 카프카 빠르게 시작해보기

### 2.2.1 kafka-topic.sh

- 카프카 클러스터에는 토픽이 여러개 존재할 수 있다. 토픽에는 파티션이 존재하는데 파티션의 개수는 최소 1개부터 시작한다. 토픽을 생성하는 방법은 2가지가 있는데 아래와 같다.
  - 컨슈머, 프로듀서가 생성되지 않은 토픽에 데이터를 요청할 때
  - 커맨드라인 툴로 명시적으로 토픽을 생성할 때
- 토픽을 생성할 때는 명시적으로 생성하는 걸 추천한다. 토픽마다 처리되어야 하는 데이터 특성이 다르기 때문이다.
- 토픽 생성 예시
  - `bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic test`
  - `bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 --config retention.ms=172800000 --topic test`
    - `--partitions` 옵션은 파티션 개수를 지정하며 최소 개수는 1개이다. 이 옵션을 지정하지 않으면 브로커 설정파일의 num.partitions 옵션값을 따른다.
    - `--replication-factor`는 파티션을 복제할 개수이다. 1은 복제하지 않고 사용한단 의미이다.
    - `--config`를 통해 추가적인 옵션을 설정할 수 있는데 retention.ms는 토픽의 데이터를 유지하는 기간으로 172800000ms는 2일을 의미한다. 즉 2일이 지난 토픽의 데이터는 삭제된다.
- 토픽 리스트 조회예시
  - `bin/kafka-topics.sh --bootstrap-server localhost:9092 --list test`
- 토픽 상세 조회
  - `bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic test`
- 다양한 명령어들

  ```txt
    // 파티션 늘리기
    bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic test --alter --partitions 2

    // 리텐션 늘리기
    bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name test --alter --add-config retention.ms=86400000

    // 리텐션 확인
    bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name test --describe
  ```

### 2.2.2 kafka-console-producer.sh

- 토픽에 넣는 데이터는 레코드라고 부르며, 키-값으로 이루어져있다. 키가 없이 메시지를 보내면 아래와 같다.
  - `bin/kafka-console-producer.sh  --bootstrap-server localhost:9092 --topic test`
- 키를 추가한다면 명령어는 아래와 같다.
  - `bin/kafka-console-producer.sh  --bootstrap-server localhost:9092 --topic test --property "parse.key=true" --property "key.separator=:"`
  - 키 구분값을 명시적으로 : 으로 지정했고 없다면 기본설정은 탭(\t)이다.
- 키가 없으면(null) 라운드 로빈 방식으로 파티션에 적재되고 키가 있다면 동일한 파티션으로 전송된다.
- 만약 파티션 개수가 늘어나면 새로 프로듀싱되는 레코드들은 어느 파티션으로 갈까?
  - 키를 가진 메시지의 경우 파티션이 추가되면 파티션과 메시지 키의 일관성이 보장되질 않는다. 즉 이전에 키를 가진 메시지가 파티션 0번에 들어갔다면 파티션을 늘린 후 0번으로 간다는 보장이 없다. 파티션을 추가하더라도 일관성을 보장하고 싶다면 커스텀 파티셔너를 만들어야 한다.

### 2.2.3 kafka-console-consumer.sh

- 토픽으로 전송한 데이터는 kafka-console-consumer 명령어로 확인할 수 있고 --from-beginning 옵션을 주면 가장 처음 데이터부터 출력한다.
  - `bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning`
- 만약 데이터의 키와 값을 확인하고 싶다면 --property 옵션을 사용한다.
  - `bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --property print.key=true --property key.separator="-" --group test-group --from-beginning`
  - 위 명령어에서 group 옵션을 통해 컨슈머 그룹을 생성했다. 컨슈머 그룹은 1개 이상의 컨슈머로 이루어져 있다. 컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋을 한다. 커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 브로커에 저장하는 것이다.
- kafka-console-consumer 명령어로 데이터를 가져가게 되면 토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져간다. 이로 인해 프로슈서가 넣은 데이터의 순서와 컨슈머가 가져가는 데이터의 순서가 달라질 수 있다. 만약 토픽에 넣은 데이터의 순서를 보장하고 싶다면 가장 좋은 방법은 파티션 1개로 구성된 토픽을 만드는 것이다. 한 개의 파티션에서는 데이터의 순서를 보장하기 때문이다.

### 2.2.4 kafka-consumer-group.sh

- 컨슈머 그룹은 따로 생성 명령어를 날리지 않고 컨슈머가 동작할 때 그룹이름을 지정하면 새로 생성된다. 생성된 컨슈머 그룹의 리스트는 아래 명령어로 확인 가능하다.
  - `bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list`
- 컨슈머 그룹의 이름을 토대로 어떤 토픽의 데이터를 가져가는지 확인하려면 아래 명령어가 사용된다.
  - `bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group test-group --describe`
  - 컨슈머 그룹의 상세정보를 확인하는 것은 컨슈머 개발이나 카프카 운영할 때 중요하게 활용된다. 컨슈머 그룹이 중복되지 않았는지 컨슈머 랙이 있진 않은지 활용할 수 있다.
