# 가상 면접 사례로 배우는 대규모 시스템 설계 기초 2

- [책 링크](https://product.kyobobook.co.kr/detail/S000211656186)

## 근접성 서비스

- 근접성 서비스는 현재 위치에서 가까운 시설을 찾는데 이용된다.

### 문제 이해 및 설계 범위 확정

```text
지원자: 사용자가 검색 반경을 지정할 수 있어야 하나요? 검색 반경내에 사업장이 충분치 않으면 시스템이 알아서 넓혀도 될까요?
면접관: 일단은 주어진 반경 내의 사업장을 대상으로 한다고 하시죠.

지원자: 최대 허용 반경은 얼마입니까? 20km로 가정해도 괜찮을까요?
면접관: 네 좋습니다.

지원자: 사용자가 UI에서 검색 반경을 변경할 수 있어야 하나요?
면접관: 네. 0.5km, 1km, 2km, 5km, 20km 내에서 선택할 수 있어야 합니다.

지원자: 사업장 정보는 어떻게 시스템에 추가되고, 삭제되고, 갱신됩니까? 사업장 정보가 사용자에게 실시간으로 보여져야 할까요?
면접관: 사업장 소유주가 사업장 정보를 시스템에 추가,삭제,갱신할 수 있어야 합니다. 추가되거나 갱신된 정보는 다음날까지 반영된다고 가정합시다.
```

- 위 대화에 근거하여 **`다음 세 가지 기능에 집중하자`**.
  - 사용자의 위치와 검색 반경 정보에 매칭되는 사업장 목록을 반환
  - 사업장 소유주가 사업장 정보를 추가,삭제,갱신할 수 있도록 하되 그 정보가 실시간으로 반영될 필요는 없다고 가정
  - 고객은 사업장의 상세 정보를 살필 수 있어야 함

### 개략적 설계안 제시 및 동의 구하기

- RESTFUL API 관례를 따르는 간단한 API를 만들어 보도록 하겠다.
  - **`GET /v1/search/nearby`**
- 이 API는 특정 검색 기준에 맞는 사업장 목록을 반환한다. 실제로 사용되는 어플리케이션의 경우 페이지 단위로 반환하겠지만 여기서는 신경쓰지 않겠다. API 호출 시에 전달할 인자는 다음과 같다.
  - `latitude` (위도), `longitude` (경도), `radius` (선택적 인자로 기본값은 5000m)
- 반환되는 결과는 다음과 같은 형태를 띤다.
  - `{ total: 10, businesses: [{ business object }]}`
  - business object는 각 사업장을 표현하는 객체로 페이지에 표시될 모든 정보를 포함한다.
- 아래는 사업장 객체 관련 API이다.
  - `GET /v1/businesses/:id` 특정 사업자의 상세 정보 반환
  - `POST /v1/businesses/:id` 새로운 사업자 추가
  - `PUT /v1/businesses/:id` 사업장 상세 정보 갱신
  - `DELETE /v1/businesses/:id` 특정 사업장 정보 삭제

#### 데이터 모델

- 주변 사업장 검색, 사업장 정보 확인. **`이 두 가지 용도로 읽기 연산은 굉장히 자주 수행된다`**.
- 한편 쓰기 연산 빈도는 낮은데, 사업장 정보를 추가하거나 삭제, 편집하는 행위는 빈번하지 않기 때문이다.
- **`읽기 연산이 압도적인 시스템에서는 MySQL 같은 관계형 데이터베이스가 바람직할 수 있다`**.
- 시스템의 핵심이 되는 테이블은 business와 지리적 위치 색인 테이블이다.

  - **`지리적 위치 색인 테이블은`** 위치 정보 연산의 효율성을 높이는데 쓰인다. 지오해시(geohash) 지식이 필요하므로 뒤에서 논의한다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/system-design2/proximity.png" width="500">

- 위 그림에서 **`LBS는 위치 기반 서비스이다`**. 주어진 위치와 반경 정보를 가지고 주변 사업장을 검색한다.
  - 쓰기 요청이 적고 읽기 요청이 빈번하게 발생하는 서비스이다.
  - QPS가 높다. 특히 특정 시간대의 인구 밀집 지역일수록 그 경향이 심하다.
  - 무상태 서비스이므로 수평적 규모 확장이 쉽다.

#### 주변 사업장 검색 알고리즘

- 실제로 많은 회사가 **`Redis의 지오해시나 PostGIS 확장을 설치한 Postgres 데이터베이스를 활용한다`**.
- 지리적 정보 색인을 만드는 방법에는 여러 알고리즘이 있지만 **`지오해시나 쿼드트리가 많이 쓰이고 있다`**.
- 이 둘을 가볍게 비교해보자.
  - 지오해시
    - 구현과 사용이 쉽고 트리를 새로 구축할 필요가 없다.
    - 지정 반경 이내 사업장 검색을 지원한다.
    - 인구 밀도에 따라 동적으로 격자 크기를 조정할 수는 없다.
    - 색인 갱신이 쉽다. 색인에서 사업장 하나를 삭제하려면 지오해시 값과 사업장 식별자가 같은 열 하나를 제거하기만 하면 된다.
  - 쿼드 트리
    - 트리를 구축해야 해서 구현하기가 살짝 더 까다롭다.
    - 가장 근거리의 k개의 무언가를 찾기 쉽다.
    - 인구 밀도에 따라 동적으로 격자 크기를 조정할 수 있다.
    - 지오해시보다 색인 갱신은 까다롭다.

### 상세 설계

- 지오해시나 쿼드트리 둘 다 널리 사용되지만 **`본 설계에서는 좀 더 단순한 지오해시를 사용하도록 하겠다`**.
- 지오해시 테이블 구성 방법은 두 가지이다.
  - 각각의 지오해시에 연결되는 모든 사업장 ID를 JSON 배열로 만들어 같은 열에 저장하는 방안이다.
  - 지오해시에 해당하는 사업장 ID를 각각 별도의 열로 저장하는 방법이다. 따라서 같은 지오해시에 해당하는 여러 열이 존재한다.
- 위 방법 중 두번째 방법을 추천한다.
  - 방안 1의 경우, 사업자 정보를 갱신하려면 JSON 배열을 읽고 사업장 ID를 찾아내야 한다. 새 사업장을 등록해야 하는 경우에도 이미 데이터가 있는지 전부 살펴봐야 한다.

#### 지리 정보 색인의 규모 확장

- **`지리 정보 색인의 규모를 확장할 때 성급하게 샤딩 방법을 결정하는 실수를 저지르곤 한다`**. 하지만 현재 보고 있는 설계안의 경우 필요한 전체 데이터 양은 많지 않다. 색인 전부를 최신 DB 서버 한 대에 수용할 수 있다. 하지만 읽기 연산의 빈도가 높다면 서버 한대의 CPU와 네트워크 대역폭으로는 감당하지 못할 수도 있다. 그런 상황에선 여러 DB 서버로 부하를 분산해야 한다.
- **`관계형 DB의 부하분산에는 두 가지 방법이 있다`**. 하나는 읽기 연산을 지원할 사본 DB를 늘리는 방법이고 다른 하나는 샤딩을 적용하는 것이다. 지오해시 테이블은 샤딩이 까다로우므로 샤딩을 강제할 필요는 없다. 따라서 이번 설계에서는 읽기 부하를 나눌 방법으로 읽기 DB를 두는 방법을 택하겠다.

#### 캐시

- 캐시 도입 전에 이런 질문을 던져야 한다. **`정말 필요한가?`** 정말 좋은 결과로 이어지리라는 결론을 내리기는 어려울 것이다.
- 대부분 읽기 중심이고 DB 데이터 크기가 작아서 모든 데이터는 한 대의 DB 서버에 수용가능하다. 이런 경우 DB 버퍼 풀에 의해 캐시되어 I/O 부하가 크게 좌우되지 않는다.
- 만약 캐시를 사용하기로 했다면 **`가장 직관적인 캐시 키는 사용자의 위도와 경도 정보다`**. 하지만 사용자가 이동하면 위도와 경도 정보가 미세하게 변한다. 위치가 조금 달라지더라도 변화가 없어야 이상적이다. 지오해시나 쿼드트리는 이 문제를 효과적으로 해결한다. 같은 격자 내 모든 사업장이 같은 해시 값을 갖도록 만들 수 있기 때문이다.

## 주변 친구

- 앞서 살펴본 근접성 서비스와 비슷해 보이지만 두 기능 사이에는 큰 차이가 있다.
- **`근접성 서비스의 경우 사업장 주소는 정적이지만 주변 친구 위치는 자주 바뀔 수 있기 때문이다`**.

### 문제 이해 및 설계 범위 확정

```text
지원자: 지리적으로 얼마나 가까워야 주변에 있다고 할 수 있나요?
면접관: 5마일입니다. 이 수치는 설정 가능해야 합니다.

지원자: 그 거리는 두 사용자 사이의 직선거리라고 가정해도 될까요?
면접관: 네 좋습니다.

지원자: 얼마나 많은 사용자가 이 앱을 사용하나요? 10억명을 가정하고 그 중 10% 정도가 이 기능을 활용한다고 생각해도 될까요?
면접관: 네 좋습니다.

지원자: 사용자의 이동 이력을 보관해야 하나요?
면접관: 네. 이동 이력은 기계 학습 등 다양한 용도로 사용될 수 있으니까요

지원자: 친구가 10분 이상 비활성 상태면 해당 사용자를 주변 친구 목록에서 사라지도록 하게 할까요? 아니면 마지막 위치를 표시해야 할까요?
면접관: 사라지게 합시다.
```

- 기능 요구사항
  - 사용자는 앱에서 주변 친구를 확인할 수 있어야 한다. 주변 친구에 보이는 해당 친구까지 거리, 해당 정보가 갱신된 시간이 함께 표시되어야 한다.
  - 친구 목록은 몇 초마다 한번씩 갱신되어야 한다.

### 개략적 설계안 제시 및 동의 구하기

- 먼저 떠오르는 방법은 공용 백엔드를 사용하는 것이다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/system-design2/find-friend-common-backend.png" width="500">

- 이 **`백엔드는 어떤 역할을 해야 할까`**?
  - 모든 활성 상태 사용자의 위치 변화 내역을 수신한다.
  - 사용자 위치 변경 내역을 수신할 때마다 해당 사용자의 모든 친구를 찾아서 그 친구들의 단말로 변경 내역을 전달한다.
  - 두 사용자 사이의 거리가 특정 임계치보다 먼 경우에는 변경 내역을 전송하지 않는다.
- 단순하고 명쾌한 설명 같지만, 큰 규모에 적용하기 쉽지 않다는 문제가 있다. 문제의 가정은 동시 접속 사용자가 천만명 정도라는 것이다. 위치 정보를 30초마다 갱신한다고 하면 초당 334,000번의 위치 정보 갱신을 처리해야 한다.
- 우선은 소규모 백엔드를 위한 개략적 설계안부터 만들어보자.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/system-design2/find-friend-basic.png" width="500">

- **`친구 위치 정보 변경은 거의 실시간에 가깝게 처리하는 서버 클러스터이다`**. 각 클라이언트는 웹 소켓 서버와 지속적으로 연결을 유지한다. 검색 반경 내 친구 위치가 변경되면 웹소켓 연결을 통해 클라이언트로 전송된다. 웹소켓 서버는 클라이언트 앱이 처음 실행되면 온라인 상태인 모든 친구 위치를 해당 클라이언트로 전송하는 역할도 한다. 그 절차는 나중에 상세히 보자.
- **`레디스 pub/sub은 초경량 메시지 버스다`**. 레디스 pub/sub에 **`새로운 채널을 생성하는 것은 아주 값싼 연산이다`**. 기가바이트급 메모리를 갖춘 최신 레디스 서버에는 수백만개의 채널을 생성할 수 있다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/system-design2/find-friend-pub-sub.png" width="500">

- 웹소켓 서버를 통해 수신한 특정 사용자의 위치 정보 변경 이벤트는 사용자에게 배정된 pub/sub 채널에 발행한다. 해당 사용자의 친구 각각과 연결된 웹소켓 연결 핸들러는 해당 채널의 구독자로 설정되어 있다. 따라서 특정 사용자의 위치가 바뀌면 사용자의 모든 친구의 웹소켓 연결 핸들러가 호출된다. 각 핸들러는 위치 변경 이벤트를 수신할 친구가 활성 상태면 거리를 다시 계산해서 검색 반경 이내면 갱신된 위치와 갱신 시간을 웹소켓 연결을 통해 해당 친구의 클라이언트 앱으로 보낸다.
- 모바일 클라이언트가 위치 변경 내역을 전송할 때 절차를 살펴보자.
  - 모바일 클라이언트가 변경된 위치를 로드밸런서에 전송한다.
  - 로드 밸런서는 위치 변경 내역을 클라이언트와 연결된 웹소켓 서버로 보낸다.
  - 웹소켓 서버는 해당 이벤트를 위치 이동 이력 DB에 저장한다.
  - 웹소켓 서버는 새 위치를 위치 정보 캐시에 보관하며 TTL도 새롭게 갱신한다.
  - 웹소켓 서버는 레디스 pub/sub 서버의 해당 사용자의 채널에 새 위치를 발행한다.
  - 레디스 pub/sub에 발생된 이벤트는 모든 구독자에게 broadcase로 전달된다. 결과적으로 각 구독자의 웹소켓 연결 핸들러는 이벤트를 수신한다.
  - 웹소켓 연결 핸들러는 새위치를 기반으로 사용자와 메시지를 받은 사용자 사이의 거리를 계산해서 검색 반경을 넘지 않는다면 구독자의 클라이언트 앱으로 전송한다. 검색 반경을 넘었다면 보내지 않는다.

#### 데이터 모델

- 살펴 봐야 할 주제로 **`데이터 모델이`** 있다. 위치 정보 캐시와 위치 이동 이력 DB를 살펴보자.
- 위치 정보 캐시
  - 본 설계안에서는 **`DB 대신 레디스를 사용해 이 캐시를 구현한다`**.
  - 주변 친구 기능은 사용자의 현재 위치만을 이용하기에 하나만 보관하면 충분하다.
  - 레디스는 읽기/쓰기 연산 속도가 엄청 빠르기 때문에 이런 목적에 아주 적합하다.
  - TTL을 지원하므로 친구가 활성 상태가 아닌 경우에는 사용자 정보를 자동으로 제거할 수도 있다.
  - 주변 친구 기능에서 제공되는 위치 정보는 영속성을 보장할 필요가 없다는 사실을 유의하자.
- 위치 이동 이력 데이터 베이스
  - **`우리가 필요로 하는 것은 막대한 쓰기 연산 부하를 감당할 수 있고, 수평적 규모 확장이 가능한 데이터베이스다`**.
  - 카산드라는 그런 요구에 잘 부합한다.
  - RDB도 사용할 수 있으나 이력 데이터 양이 너무 많을 수 있어 샤딩이 필요하다.
  - **`사용자 ID를 기준 삼는 샤딩 방안이 가장 기본이다`**. 부하를 모든 샤드에 고르게 분산시킬 수 있고, DB 운영 관리도 간편하다.

### 상세 설계

- **`웹 소켓 서버`**
  - 웹소켓 클러스터도 사용률에 따라 규모를 자동으로 늘리는 것은 그다지 어렵지 않다.
- **`클라이언트 초기화`**
  - 모바일 클라이언트는 기동되면 웹소켓 클러스터 내의 서버 가운데 하나와 지속성 연결을 맺는다.
  - 웹소켓 연결이 초기화되면 클라이언트는 해당 모바일 단말의 위치, 즉 사용자의 위치 정보를 전송한다.
  - 그 정보를 받은 웹소켓 연결 핸들러는 다음 작업을 수행한다.
    - 위치 정보 캐시에 사용자 위치를 갱신한다.
    - 사용자 DB를 조회해 모든 친구 정보를 가져온다.
    - 위치 정보 캐시에 모든 친구의 위치를 한번에 가져온다.
    - 캐시가 돌려준 친구 위치 각각에 대해 웹소켓 서버는 해당 친구와 사용자 사이의 거리를 계산한다. 거리가 검색 반경 이내이면 친구의 위치를 웹소켓 연결을 통해 클라이언트에 반환한다.
    - 웹소켓 서버는 더불어 각 친구의 레디스 pub/sub 채널을 구독한다.
    - 사용자의 현재 위치를 레디스 pub/sub 채널을 통해 모든 친구에게 전송한다.
- **`사용자 데이터베이스`**
  - 사용자 상세 정보 데이터, 친구 관계 데이터 두 종류의 데이터가 보관된다.
  - 설계의 규모를 감안하면 한 대의 RDB 서버로는 감당할 수 없다. 하지만 사용자 ID를 기준으로 샤딩하면 관계형 DB라해도 수평적 규모 확장이 가능하다. 관계형 DB 샤딩은 널리 사용되는 기술이다.
- **`위치 정보 캐시`**
  - 위치 정보를 캐시하기 위해 레디스를 사용하였다. 시스템이 가장 붐빌때 천만 명의 사용자가 활성화되어 있고, 위치 정보 보관에 100 바이트가 필요하다고 가정하면 수 GB 이상의 메모리를 갖춘 레디스 한 대로 모든 위치를 캐시할 수 있다.
  - 하지만 천만 명의 활성 사용자가 대략 30초마다 변경된 위치 정보를 전송한다고 가정하면 레디스 서버는 초당 334K에 요청이 오는데 고사양 서버를 쓴다 해도 살짝 부담되는 수치이다. 다행스럽게 캐시할 데이터는 쉽게 샤딩할 수 있다. 각 사용자의 위치 정보는 서로 독립적인 데이터이므로 사용자 ID를 기준으로 여러 서버에 샤딩하면 부하를 고르게 분배할 수 있다.
- **`레디스 pub/sub 서버`**
  - 모든 온라인 친구에게 보내는 위치 변경 내역 메시지의 라우팅 계층으로 레디스 pub/sub 서버를 사용한다.
  - 선택한 이유는 pub/sub 채널을 만드는 비용이 아주 저렴하기 때문이다.
  - 채널 하나를 유지하기 위해서는 구독자 관계를 추적하기 위한 해시 테이블과 연결 리스트가 필요한데, 아주 소량의 메모리만을 사용한다.
  - 주변 친구 기능을 사용하는 모든 사람들에게 채널을 하나씩 할당하면, 10억 사용자의 10%가 친구 기능을 쓴다고 가정하고 1억개라고 추정된다. 한 사람의 친구 중 100명이 주변 친구 기능을 사용한다고 가정하고, 구독자 한 명을 추적하기 위해 내부 해시 테이블과 연결 리스트에 20바이트를 저장한다고 가정하자. 모든 채널을 저장하는데는 200GB의 메모리가 필요하니, 100GB 최신 레디스 pub/sub 서버 두 대면 될 것이다.
- **`분산 레디스 pub/sub 서버 클러스터`**
  - pub/sub 서버가 구독자에게 전송해야 하는 데이터는 초당 1400만 건에 달하기에 한 대의 서버로 감당할 수 없다.
  - 수백 대의 레디스 서버에 채널을 분산할 방법은 무엇일까? 다행인점은 모든 채널을 독립적이라는 사실이다. 그러니 메시지를 발행할 사용자 ID를 기준으로 pub/sub 서버들을 샤딩하면 된다. 하지만 현실적으로 수백대의 서버와 관련된 문제이므로 서비스 탐색 컴포넌트를 도입해 이 문제를 푼다. 가장 널리 알려진 주키퍼 등이 사용된다.

### 마무리

- 이 설계안의 **`핵심 컴포넌트는 다음과 같다`**.
  - 웹소켓: 클라이언트와 서버 사이의 실시간 통신을 지원한다.
  - 레디스: 위치 데이터의 빠른 읽기/쓰기를 지원한다.
  - 레디스 pub/sub: 한 사용자의 위치 정보 변경 내역을 모든 온라인 친구에게 전달하는 라우팅 계층이다.

## 분산 메시지 큐

- **`메시지 큐를 사용하면 어떤 이점을 얻을 수 있을까?`**
  - 결합도 완화: 메시지 큐를 사용하면 컴포넌트 사이의 강한 결합이 사라지므로 각각을 독립적으로 갱신할 수 있다.
  - 규모 확장성 개선: 생산자와 소비자 시스템 규모를 트래픽 부하에 맞게 독립적으로 늘릴 수 있다. 트래픽이 많이 몰리는 시간에 소비자를 추가하여 처리 용량을 늘린다.
  - 가용성 개선: 시스템의 특정 컴포넌트에 장애가 발생해도 다른 컴포넌트는 큐와 상호작용을 이어나갈 수 있다.
  - 성능 개선: 메시지 큐를 사용하면 비동기 통신이 쉽게 가능하다. 생산자는 응답을 기다리지 않고 메시지를 보낼 수 있고 소비자는 읽을 메시지가 있는 경우에만 메시지를 소비하면 된다.
- 메시지 큐 대 이벤트 스트리밍 플랫폼
  - 엄밀하게 말하면 카프카는 메시지 큐가 아니라 이벤트 스트리밍 플랫폼이다.
  - 하지만 지원하는 기능이 서로 닮아가면서 점차 구분이 희미해지고 있다.
- 이번 장에서는 데이터 장기 보관, 메시지 반복 서비스 등의 부가 기능을 갖춘 분산 메시지 큐를 설계해 볼 것이다.

### 문제 이해 및 설계 범위 확정

```text
지원자: 메시지의 형태와 평균 크기를 알려주실 수 있나요?
면접관: 텍스트 형태 메시지만 지원하면 되고, 메시지 크기는 수 킬로바이트 수준이라고 보면 됩니다.

지원자: 메시지는 반복적으로 소비할 수 있어야 하나요?
면접관: 네 하나의 메시지를 여러 소비자가 수신하는 것이 가능해야 합니다.

지원자: 메시지는 큐에 전달된 순서대로 소비되어야 하나요?
면접관: 생산된 순서 그대로 소비되어야 합니다.

지원자: 데이터의 지속성은 얼마 동안 보장되어야 하나요?
면접관: 2주라고 가정합시다.

지원자: 어떤 메시지 전달 방식을 지원해야 하나요? 최대 한 번, 최소 한 번, 정확히 한 번 중에서요.
면접관: 최소 한번 방식은 반드시 지원해야 합니다.
```

- 기능 요구사항
  - 생산자는 메시지 큐에 메시지를 보낼 수 있고 소비자는 메시지 큐를 통해 메시지를 수신할 수 있다.
  - 메시지는 반복적으로 수신할 수 있어야 하고, 단 한번만 수신하도록 설정될 수도 있어야 한다.
  - 오래된 이력 데이터는 삭제될 수 있다.
  - 메시지 크기는 수 킬로바이트 수준이다.
  - 메시지가 생산된 순서대로 소비자에게 전달할 수 있어야 한다.

### 개략적 설계안 제시 및 동의 구하기

- 가장 널리 쓰이는 메시지 모델은 **`일대일과 발행-구독 모델이다`**.
  - 일대일 모델은 큐를 소비하는 소비자가 많아도 전송된 메시지를 오직 한 소비자만 가져갈 수 있다.
  - 일대일 모델은 데이터 보관을 지원하지 않기 때문에 본 설계에서는 발행-구독 모델이 좀 더 적합하다.
  - 발행 구독 모델은 토픽이라는 새로운 개념을 도입해야 한다. 토픽은 메시지를 주제별로 정리하는데 사용되며 메시지를 보내고 받을 때는 토픽에 보내고 받게 된다. 이 모델에서 토픽에 전달된 메시지는 해당 토픽을 구독하는 모든 소비가에게 전달된다.
- **`토픽에 보관되는 데이터의 양이 서버 한 대로 감당하기 힘들어지면 어떻게 될까?`**
  - 이 문제를 해결하는 한 가지 방법은 파티션, 즉 샤딩 기법을 활용하는 것이다.
  - 토픽을 여러 파티션으로 분할한 다음 메시지를 모든 파티션에 균등하게 나눠 보낸다.
  - 파티션은 메시지 큐 클러스터 내의 서버에 고르게 분산 배치되며, 파티션을 유지하는 서버를 브로커라고 부른다.
  - 파티션을 브로커에 분산하는 것이 높은 규모 확장서을 달성하는 비결이다. 토픽의 용량을 확장하고 싶으면 파티션 개수를 늘리면 되기 때문이다.
  - 각 파티션은 FIFO 큐처럼 동작해, 같은 파티션 안에서는 순서가 보장된다.
  - 토픽을 구독하는 소비자가 여럿인 경우, 이 소비자들을 소비자 그룹이라고 부른다. 같은 그룹 내의 소비자들은 메시지를 병렬로 소비할 수 있다.
- 한가지 문제는 **`데이터를 병렬로 읽으면 처리량은 좋아지지만 파티션 안에 있는 메시지를 순서대로 소비할 수 없다`**.
  - 어떤 파티션의 메시지는 오직 한 소비자만 읽을수 있도록 하면 문제를 해결할 수 있다.
  - 모든 소비자를 같은 소비자 그룹에 두면 같은 파티션의 메시지는 오직 한 소비자만 가져갈 수 있으므로 일대일 모델을 수렴하게 된다.
  - 파티션은 가장 작은 저장 단위로, 미리 충분한 파티션을 할당해두면 파티션의 수를 동적으로 늘리는 일은 피할 수 있다. 처리 용량을 늘리려면 소비자를 더 추가하면 된다.

### 상세 설계

- **`데이터의 장기 보관 요구사항을 만족하면서 높은 대역폭을 제공하기 위해 아래 세 가지 결정을 내렸다`**.
  - 회전 디스크: 높은 순차 탐색 성능과 현대 OS가 제공하는 적극적 디스크 캐시 전략을 이용한다.
  - 메시지가 소비자에게 전달되기 까지 아무 수정 없이 전송이 가능하도록 설계한다. 전송 데이터 양이 큰 경우 복사에 드는 비용을 최소화한다.
  - 일괄처리: 소규모 I/O가 많으면 높은 대역폭을 처리하기 어렵다. 생산자는 메시지를 일괄 전송하고 소비자도 가능하면 메시지를 일괄 수신하도록 한다.

#### 데이터 저장소

- **`메시지 큐의 트래픽 패턴을 살펴보자`**.
  - 읽기와 쓰기 빈번히 발생한다.
  - 갱신, 삭제 연산을 발생하지 않는다.
  - 순차적인 읽기/쓰기가 대부분이다.
- **`첫 번째 선택지는 데이터베이스이다`**.
  - RDB를 사용한다면 토픽별로 테이블을 만든다. 토픽에 보내는 메시지는 테이블에 새로운 레코드에 추가한다.
  - NoSQL을 사용한다면 토픽별로 컬렉션을 만든다. 토픽에 보내지는 메시지는 하나의 문서가 된다.
  - DB라면 데이터 저장 요구사항은 맞출 수 있지만 **`읽기 연산과 쓰기 연산이 빈번하게 발생하는 DB를 설계하긴 어렵다`**.
- **`두 번째 선택지는 쓰기 우선 로그 WAL(Write Ahead Log) 이다`**.
  - WAL은 새로운 항목이 추가되기만 하는 일반 파일이다.
  - WAL은 다양한 시스템에서 사용되는 기술인데 MySQL의 redo log가 WAL로 구현되어 있고 아파치 주키퍼도 해당 기술을 활용한다.
  - 지속성을 보장해야 하는 메시지는 디스크에 WAL로 보관할 것을 추천한다. **`WAL에 대한 접근 패턴은 읽기/쓰기 모두 순차적으로 접근 패턴이 순차적일 때 디스크는 아주 좋은 성능을 보인다.`**
- 회전식 디스크가 느려지는 것은 데이터 접근 패턴이 무작위일 때다. 순차적 접근 패턴을 활용하면 수백 MB/sec 성능을 달성하는게 어렵지 않다. 비용 구조도 이쪽이 더 만족스럽다.

#### 메시지 자료 구조

- 메시지 구조는 높은 대역폭 달성의 열쇠다. 설계에서 **`메시지가 전달되는 과정에서 불필요한 복사가 일어나지 않도록 함으로써 높은 대역폭을 달성할 것이다`**. 아래는 메시지 자료 구조의 스키마 사례다.

  ```
    필드 이름 | 데이터 자료형
    ------------------------
    key        byte[]
    value      byte[]
    topic      string
    partition  integer
    offset     long
    timestamp  long
    size       integer
    crc        integer
  ```

#### 일괄 처리

- **`일괄 처리는`** 아래의 이유로 시스템 성능에 매우 중요하다.
  - OS로 하여금 여러 메시지를 한 번의 네트워크 요청으로 전송하기에 비싼 네트워크 왕복 비용을 제거할 수 있다.
  - 브로커가 여러 메시지를 한 번에 로그에 기록하면 더 큰 규모의 순차 쓰기 연산이 발생하고 OS가 관리하는 디스크 캐시에서 더 큰 규모의 연속된 공간을 점유하게 된다. 결과적으로 더 높은 디스크 접근 대역폭을 달성할 수 있다.
- **`얼마나 많은 메시지를 일괄 처리하는 것이 좋을까?`** 이에 대한 답은 결국 **`대역폭과 응답 지연 사이에서 타협점을 찾는 문제다`**. 일괄 처리할 메시지의 양을 늘리면 대역폭을 늘어나지만 응답속도는 느려진다. 일괄 처리가 가능할 양의 메시지가 쌓이길 기다려야 하기 때문이다. 양을 줄이면 메시지는 더 빨리 보낼 수 있으니 지연은 줄어들지만 대역폭은 손해를 본다.

#### 푸시 VS 풀

- 한 가지 중요하게 봐야 할 것은 **`브로커가 데이터를 소비자에게 보낼 것이냐 아니면 소비자가 브로커에게서 가져갈 것이냐 하는 부분이다`**.
- **`푸시 모델의 장점은`** 브로커는 메시지를 받는 즉시 소비자에게 보내는 점이다. 단점은 소비자가 메시지를 처리하는 속도가 느릴 경우 소비자에게 부하가 걸릴 가능성이 있다. 또한 생산자가 데이터 전송 속도를 좌우하므로 소비자는 처리가 가능한 컴퓨팅 자원을 준비해 두어야 한다.
- **`풀 모델의 장점은`** 소비하는 속도를 소비자가 알아서 결정한다. 또 소비하는 속도가 느리다면 소비자를 늘려 해결할 수도 있고 생산 속도를 따라잡을 때까지 기다릴 수 있다. 단점은 브로커에 메시지가 없어도 소비자는 계속 통신하기에 컴퓨팅 자원이 낭비된다. 이 문제를 보완하기 위해 많은 메시지 큐가 롱 폴링을 지원한다. 당장 가져갈 메시지가 없어도 일정 시간 기다리는 것이다.
- **`대부분의 메시지 큐는 푸시 모델 대신 풀 모델을 지원한다`**.

#### 소비자 재조정

- **`소비자 재조정은 어떤 소비자가 어떤 파티션을 책임지는지 다시 정하는 프로세스다`**.
- 새로운 소비자가 합류하거나 기존 소비자가 그룹을 떠나거나, 어떤 소비자에 장애가 발생하거나 파티션이 조정되는 경우 발생한다.
- 이 절차에 코디네이터가 중요한 역할을 한다. 코디네이터는 소비자 재조정을 위해 소비자들과 통신하는 브로커 노드다. 코디네이터는 소비자로부터 오는 하트비트 메시지를 살피고 각 소비자의 파티션 내 오프셋 정보를 관리한다.

#### 상태 저장소

- 메시지 큐 브로커의 상태 저장소에는 아래 정보들이 저장된다.
  - 소비자에 대한 파티션의 배치 관계
  - 각 소비자 그룹이 각 파티션에서 마지막으로 가져간 메시지의 오프셋
- 소비자 상태 정보 데이터가 이용되는 패턴은 다음과 같다.
  - 읽기와 쓰기가 빈번하게 발생하지만 양은 많지 않다.
  - 데이터 갱신은 빈번하게 일어나지만 삭제되는 일은 거의 없다.
  - 읽기와 쓰기 연산은 무작위적 패턴을 보인다.
  - 데이터의 일관성이 중요하다.
- **`데이터의 일관성 및 높은 읽기/쓰기 속도에 대한 요구사항을 고려할 때 주키퍼 같은 키-값 저장소를 사용하는 것이 바람직하다`**.
- 주키퍼는 계층적 키-값 저장소 기능을 제공하는 분산 시스템에 필수적인 서비스이다.

#### 복제

- 분산 시스템에서 **`하드웨어 장애는 흔한 일이므로 무시해서는 안 된다. 이런 문제를 해결하기 위해 사용하는 방법은 복제다`**.
- 생산자는 파티션에 메시지를 보낼 때 리더 파티션에게만 보내고 다른 사본은 리더로부터 새 메시지를 지속적으로 가져와 동기화 한다.
- 풀어야 할 마지막 문제는 리더와 복제간 그 모두들 어떻게 동기화 시킬것 인가 하는 점이다. 동기화 된 사본(ISR)은 리더와 동기화 된 사본을 의미한다. 이때 동기화되었다는 것은 토픽의 설정에 따라 달라진다. ISR이 필요한 이유는 무엇인가? ISR은 성능과 영속성 사이의 타협점이다. 이때 ACK 설정에 따라 영속성과 성능 사이의 타협점을 결정한다.

#### 메시지 전달 방식

- **`최대 한번`**
  - 메시지를 최대 한 번만 전달하는 방식이다. 메시지가 전달 과정에서 소실되더라도 다시 전달되는 일은 없다.
  - 지표 모니터링이나 소량의 데이터 손실은 감수할 수 있는 어플리케이션에 적합하다.
- **`최소 한번`**
  - 최소 한번은 같은 메시지가 한 번 이상 전달될 수 있으나 메시지 소실은 발생하지 않는다.
  - 이 방법은 같은 메시지가 여러 번 전송될 수 있다. 소비자가 중복을 직접 제거할 수 있는 어플리케이션의 경우에느 충분히 괜찮은 방식이다.
- **`정확히 한번`**
  - 사용자 입장에서는 편리하지만 구현하기 가장 까다로운 전송 방식이다.
  - 지불, 매매, 회계 등 금융 관련에는 이 전송 방식이 적합하다. 중복을 허용하지 않으며 멱등성 처리가 되어 있지 않는 어플리케이션엔 특히 중요하다.

## 지표 모니터링 및 경보 시스템

- 이번 장에서는 규모 확장이 용이한 지표 모니터링 및 경보 시스템의 설계안을 살펴보도록 하겠다.

### 문제 이해 및 설계 범위 확정

```text
지원자: 시스템의 고객은 누구인가요? 대형 IT 업체가 사용할 시스템을 설계하나요? 아니면 Datadog 같은 SaaS 제품을 설계하나요?
면접관: 회사 내부에서 사용할 시스템입니다.

지원자: 어떤 지표를 수집해야 하나요?
면접관: 시스템 운영 지표를 수집해야 합니다. 이 운영 지표는 CPU, 메모리, 디스크 사용량 같은 지표일 수 있구요. 서버가 처리하는 초당 요청 수와 같은 지표일 수도 있습니다.

지원자: 모니터링할 인프라 규모는 어느 정도 인가요?
면접관: 일간 능동 사용자 수는 1억 명이구요. 1000개의 서버 풀이 있고, 풀마다 100개의 서버 하드웨어를 유지하고 있습니다.

지원자: 지표 데이터는 얼마나 유지해야 하나요?
면접관: 1년 동안은 보관해야 합니다.

지원자: 경보 채널로는 어떤것들을 지원해야 하나요?
면접관: 이메일, 전화, 웹훅 등을 지워나는 것으로 합시다.

지원자: 에러 로그나 엑세스 로그 등에 대한 수집 기능도 제공해야 하나요?
면접관: 아닙니다.
```

### 개략적 설계안 제시 및 동의 구하기

- 지표 모니터링 및 경보 시스템은 **`아래 다섯개의 컴포넌트로 구성된다`**.
  - 데이터 수집
  - 데이터 전송
  - 데이터 저장소
  - 경보
  - 시각화
- 데이터 모델
  - 지표 데이터는 통상 시계열(timestamp) 데이터 형태로 기록한다.
  - 값 집합에 타임스탬프가 붙은 형태로 기록한다는 뜻이다.
- 데이터 접근 패턴
  - **`이 시스템에 대한 쓰기 부하는 막대하다. 시점을 막론하고 많은 데이터가 기록될 수 있다`**.
  - 반면 읽기 부하는 시각화와 경보 서비스에 의해 일시적으로 치솟았다가 사라지는 편이라고 봐야 한다.

#### 데이터 저장소 시스템

- 데이터 저장소는 본 설계의 핵심이다. 우선 저장소 시스템을 직접 설계하거나 MySQL 같은 범용 저장소는 추천하지 않는다. 범용 DB는 이론적으로는 시계열 데이터를 처리할 수 있지만 본 설계의 부하를 감당하려면 전문가 수준의 튜닝이 필요하다.
- NoSQL은 어떨까? 시계열 데이터를 효율적으로 처리할 수 있는 카산드라나 빅테이블이 있지만 확장이 용이한 스키마를 설계해야 하는데 그러러면 NoSQL에 내부 구조에 대한 해박한 지식이 필요하다.
- **`시계열 데이터에 최적화 된 저장소 시스템은 InfluxDB와 Prometheus 이다`**. 다량의 시계열 데이터를 저장하고 빠른 실시간 분석을 지원하는 것이 특징이다. 8CPU 코어와 32GB 램을 갖춘 InfluxDB 서버 한 대로 초당 250,000의 쓰기 연산 처리가 가능하다.

### 상세 설계

#### 지표 수집

- **`지표를 수집할 때는 때로 데이터가 소실되어도 큰 문제는 아니다`**. 지표를 보내는 클라이언트는 성공적으로 데이터가 전송되었는지 신경 쓰지 않아도 된다.
- 지표 데이터 수집 방법에는 **`풀과 푸시 모델이 있다. 어느쪽이 더 나은가?`** 정답은 없지만 자세히 알아보자.
- **`풀 모델`**
  - 실행중인 어플리케이션(서버, DB, 큐, 캐시 클러스터)에서 주기적으로 지표 데이터를 가져오는 흐름이다.
  - 이 방안은 서버가 수시로 추가/삭제되는 대규모 운영 환경에는 적용하기 어렵다. 다행히 주키퍼 같은 서비스 탐색 기술을 활용하면 이 문제를 해결할 수 있다.
- **`푸시 모델`**
  - 서버들이 직접 지표를 지표 수집기에 전송하는 모델이다.
  - 푸시 모델의 경우 모니터링 대상 서버에 통상 수집 에이전트라고 부르는 SW를 설치한다.
  - 수집 에이전트는 서버에서 지표 데이터를 받아 모은 다음 주기적으로 수집기에 전달한다.
  - 데이터 집계는 수집기에 보내는 데이터 양을 줄이는 효과적인 방법이다. 트래픽의 양이 막대하여 수집기가 일시적으로 데이터를 처리하지 못하게 되면 에이전트는 내부의 버퍼에 일시적으로 데이터를 보관하고 나중에 재전송할 수도 있다.
- **`풀 vs 푸시 모델 장단점 비교`**
  - 어떤 모델이 우리 상황에 적합할까? 정답은 없고 두 모델 모두 널리 사용되고 있다.
    - 풀 모델을 사용한 사례로는 프로메테우스가 있다.
    - 푸시 모델을 사용한 사례로는 아마존 CloudWatch가 있다.

#### 지표 전송 파이프라인의 규모 확장

- **`지표 수집기는 엄청난 양의 데이터를 받아 처리해야 한다`**. 또 자동으로 규모 확장이 가능하도록 설정해야 한다.
- 시계열 DB에 **`장애가 발생하면 데이터 손실이 발생할 가능성이 있다. 이 경우 카프카 같은 큐를 두면 문제를 해소할 수 있다`**.
- 지표 수집기는 데이터를 카프카에게 전송한다. 그럼 아파치 스톰이나 스파크 같은 소비자들이 데이터를 받아 시계열 DB에 저장한다.
- 이 방법에는 몇 가지 장점이 있다.
  - 카프카는 고도로 안정적이고 규모 확장성이 뛰어난 분산 메시지 플랫폼이다.
  - 데이터 수집 컴포넌트와 처리 컴포넌트 사이의 결합도를 낮춘다.
  - DB에 장애가 생겨도 데이터가 소실되지 않는다. 카프카에 보관해두면 되기 때문이다.

#### 경보 시스템

- 기업이 필요로 하는 규모를 바로 지원 가능한 경보 시스템은 시장에 많다.
- 그리고 대부분이 유명 시계열 DB와 통합되어 있고 다양한 알림 채널을 지원한다.
- 따라서 실무에서는 경보 시스템을 밑바닥부터 구현하겠다는 아이디어는 수용되기 어렵다.

#### 시각화 시스템

- 시각화 시스템은 데이터 계층 위에 만들어진다.
- 품질 좋은 시각화 시스템은 구현하기 어렵기에 사용품을 구입해서 쓰자고 주장하는게 바람직하다.
- 예를 들어 그라파나는 그런 용도에 아주 잘맞는 시스템이다.

## 호텔 예약 시스템

### 문제 이해 및 설계 범위 확정

```text
지원자: 시스템 규모는 어느 정도 입니까?
면접관: 5000개 호텔에 100만개 객실을 갖춘 호텔 체인을 위한 웹사이트를 구축한다고 가정합시다.

지원자: 대금은 예약 시에 지불하나요, 아니면 호텔에 도착했을 때 지불하나요?
면접관: 시간 제한이 있으니 예약할 때 전부 지불한다고 합시다.

지원자: 고객은 객실을 호텔의 웹 사이트에서만 예약할 수 있나요, 아니면 전화 같은 다른 시스템으로도 할 수 있나요?
면접관: 호텔 웹사이트나 앱에서만 가능하다고 합시다.

지원자: 예약을 취소할 수도 있나요?
면접관: 물론입니다.

지원자: 추가로 고려할 사항이 있을까요?
면접관: 10% 초과 예약이 가능해야 합니다. 호텔은 일부 고객이 예약을 취소할 것을 예상해서 초과 예약을 허용하곤 합니다.

지원자: 시간이 제한되어 있어서 객실 검색은 범위에 넣지 않겠습니다.
면접관: 좋습니다.

지원자: 더 고려할 사항이 있나요?
면접관: 객실 가격은 유동적입니다. 그날 객실에 여유가 얼마나 있는지에 따라 달라진다고 하겠습니다. 또한 매일 달라질 수 있습니다.
```

- 규모 추정
  - 총 5_000개 호텔, 100만 개의 객실이 있다고 가정한다. 평균적으로 객실의 70%가 사용 중이고 평균 투숙 기간은 3일이라고 가정한다.
  - 일일 예상 예약 건수는 `1백만 * 70% / 3 = 233,333` 건수로 반올림하면 240,000 건수가 된다.
  - 초당 예약 건수는 계산해보면 3으로 초당 예약 트랜잭션 수는 그다지 높지 않다.

### 개략적 설계안 제시 및 동의 구하기

#### 데이터 모델

- **`시스템 규모가 크지 않은 것은 알았으나 대규모 이벤트가 있는 경우에는 트래픽이 급증할 수도 있으니 대비해야 한다`**. 이런 요구사항을 종합적으로 고려하였을 때 본 설계에서는 RDBMS를 선택할 것이다.
  - **`RDB는 읽기 빈도가 쓰기 연산에 비해 높은 작업 흐름을 지원한다`**. 호텔 웹 사이트/앱을 방문하는 사용자의 수는 실제로 객실을 예약하는 사용자에 비해 압도적으로 많다. **`NoSQL은 대체로 쓰기 연산에 최적화 되어 있다`**. RDB는 읽기가 압도적인 작업 흐름을 충분히 잘 지원한다.
  - **`RDB는 ACID 속성을 보장한다`**. ACID 속성은 예약 시스템을 만드는 경우 중요하다. 이 속성이 만족되지 않으면 잔액이 마이너스가 되는 문제, 이중 청구 문제, 이중 예약 문제를 방지하기 어렵다. RDB는 일반적으로 ACID 속성을 보장한다.

#### 개략적 설계

- 이 호텔 예약 시스템에서는 마이크로 서비스 아키텍처를 사용하며 아래와 같은 흐름이다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/system-design2/hotel-reserve.png" width="500">

### 상세 설계

#### 동시성 문제

- 중요한 문제 중 하나는 **`이중 예약을 어떻게 방지할 것이냐 하는 것이다`**.
  - 사용자가 예약 버튼을 여러 번 누를 수 있고, 여러 사용자가 같은 객실을 동시에 예약하려 할 수 있다.
- 사용자가 예약 버튼을 여러 번 누르는 경우, 예약 API 요청에 멱등 키를 추가하는 방안이다. 여러 번 호출해도 동일한 결과를 내는 API를 멱등 API라고 부른다. 상세한 절차는 아래 흐름을 보자.
  - 예약 주문서를 만들고 고객이 계속 버튼을 누른다. 고객이 결제 전에 검토할 수 있는 예약 주문서를 반환하는데 이떄 reservation_id를 넣는다. 이 ID는 전역적 유일성을 보증하는 ID 생성기가 만들어 낸 것이어야 한다.
  - 사용자가 예약 완료 버튼을 두 번 눌러도 reservation_id가 테이블의 PK이므로 중복된 데이터는 생성되지 않는다.
- 이번에는 **`두 사용자가 동시에 잔여 객실이 하나 밖에 없는 객실을 예약하려 들면 어떻게 될까?`**
  - DB 트랜잭션 격리 수준이 serializable 수준이 아니라면 한 객실에 이중 예약이 발생한다.
- **`이 문제는 어떤 형태로는 락을 활용해야 한다`**. 아래에서 락을 살펴보겠다.
  - **`비관적 락`**
    - 비관적 락은 사용자가 레코드를 갱신하려는 순간 락을 걸어 동시 업데이트를 방지하는 기술이다.
    - MySQL의 경우 SELECT ~ FOR UPDATE 문을 실행하면 SELECT가 반환한 레코드에 락이 걸린다.
    - 동시에 접근한 트랜잭션 중 하나가 먼저 실행되면 다른 트랜잭션은 앞의 트랜잭션이 종료되기를 기다려야 한다.
    - 장점은 구현이 쉽고 데이터에 대한 경합이 심할 때 유용하다.
    - 단점은 deadlock이 발생할 수가 있고 성능이 낮다. 트랜잭션이 오랫동안 락을 잡고 있으면 다른 트랜잭션은 락이 걸린 자원에 접근할 수 없다.
  - **`낙관적 락`**
    - 낙관적 락은 여러 사용자가 동시에 같은 자원을 갱신하려 시도하는 것을 허용한다.
    - 테이블에 version 이라는 새 컬럼을 추가하고 레코드를 수정하기 전 버전을 읽는다.
    - 레코드에 갱신할 때 버전 번호에 1을 더한 다음 DB에 기록한 뒤, 값이 1만큼 큰게 아니라면 단계를 다시 반복한다.
    - 낙관적 락은 락을 걸지 않으므로 비관적 락보다는 빠르지만 동시성 수준이 아주 높으면 성능이 급격하게 나빠진다.
    - 장점으로는 락을 걸 필요가 없고 동시 예약을 막는다. 단점으로는 데이터에 대한 경쟁이 치열한 상황에선 성능이 좋지 못하다.

#### 시스템 규모 확장

- 일반적으로 호텔 예약 시스템은 부하가 높지 않지만 이벤트가 발생하거나, 유명 호텔 예약 사이트랑 연동되면 QPS가 천 배 늘어날 수도 있다.
- **`DB 규모를 늘리는 한 가지 방법은 샤딩을 적용해 데이터를 분산시키는 것이다`**. 샤딩에서는 데이터를 어떻게 분배할지 먼저 정해야 하는데, 시스템의 대부분 질의는 hotel_id를 조건으로 사용하므로 자연스럽게 hotel_id를 샤딩 조건으로 쓰면 좋다는 결론이 나온다.
- **`DB 속도나 확장성이 문제가 되기 시작하면 DB 앞에 캐시 계층을 두고 잔여 객실 및 예약 로직이 실행되도록 할 수 있다`**. 이렇게 하면 일부 잔여 객실은 DB가 처리하고 나머지는 캐시가 담당한다. 그러나 레디스 캐시의 잔여 객실이 충분해 보여도 결국 DB를 한 번 확인할 필요는 있다. 최종 진실은 결국 DB안에 있기 때문이다.
- **`캐시를 추가하면 확장성과 처리량은 대폭 증가하지만 DB와 캐시 사이에 데이터 일관성에 대한 문제에 직면하게 된다`**.
  - 예를 들어 캐시에는 잔여 객실이 있다고 나오지만 DB에는 없는 경우, 사용자가 예약을 하면 DB에서 락이나 낙관적 락을 이용해 오류가 발생하게 될 것이다. 클라이언트는 마지막 객실이 예약되었다는 오류 메시지를 보게 된다.
  - 캐시를 두면 장점은 읽기 질의를 캐시가 처리하므로 DB의 부하가 줄어들고 읽기를 메모리에서 실행하므로 높은 성능을 보장할 수 있다.
  - 캐시를 두면 단점은 DB와 캐시 데이터의 불일치로 인해 사용자 경험에 어떤 영향을 끼치게 될지 신중히 고민해야 한다.

## 실시간 게임 순위표

### 문제 이해 및 설계 범위 확정

- 요구사항을 나열해보면 아래와 같다.
  - 순위표에 상위 10명의 플레이러를 표시한다.
  - 특정 사용자의 순위를 표시한다.
  - 어떤 사용자보다 4순위 위와 아래에 있는 사용자를 표시한다.
- 비 기능적 요구사항은 아래와 같다.
  - 점수 업데이트는 실시간으로 순위표에 반영한다.
- 개략적 규모를 추정해보자.
  - 게임을 하는 사용자가 24시간 동안 고르게 분포한다고 가정하면 DAU가 500만명인 게임의 경우 초당 평균 50명의 사용자가 게임을 플레이하게 된다. 하지만 사용랴이 균등한 경우는 별로 없기에 **`저녁시간이 피크일 가능성이 높다. 이를 고려해 최대 부하는 5배인 초당 250명의 사용자를 감당해야 한다`**.

### 개략적 설계

- **`전반적인 흐름은 다음과 같다`**.
  - 사용자가 승리하면 클라이언트는 게임 서비스에 요청을 보낸다.
  - 게임 서비스는 승리에 대한 유효성을 체크하고 순위표 서비스에 점수 갱신 요청을 보낸다.
  - 순위표 서비스는 순위표 저장소에 기록된 사용자의 점수를 갱신한다.
  - 사용자의 클라이언트는 순위표 서비스에 직접 요청하여 상위 10명의 순위와 특정 사용자의 순위를 가져온다.
- **`게임 서비스와 순위표 서버 사이에 메시지 큐가 필요할까?`**
  - 이는 게임 점수가 어떻게 사용되는지에 따라 달라진다.
  - 데이터가 다른 곳에서도(순위표 서비스, 푸시 알림 서비스) 이용되면 카프카에 데이터를 넣는 것이 합리적일 수 있다.
  - 본 설계에서는 면접관이 요청한 사항은 아니므로 메시지 큐는 제외한다.

#### 데이터 모델

- **`순위표 저장소는 핵심 구성 요소이다`**. 가장 간단하게 생각해볼 만한 것은 RDBMS 이다.
- RDBMS는 데이터가 적을 때는 효과적이지만 **`레코드가 수백만개 이상이 되면 성능이 나빠진다`**. SQL DB는 지속적으로 변하는 대량의 정보를 신속하게 처리하지 못한다. 수백만 레코드에 순위를 매기려면 대략 수십 초 정도가 걸리므로 실시간성을 요구하는 어플리케이션에는 적합하지 않다. 데이터가 지속적으로 변경되기 때문에 캐시 도입도 불가능하다. **`결론적으로 RDBMS는 시스템에서 요구되는 다량의 읽기 부하는 처리하기 어렵다`**.
- 수백만명의 사용자에 대해서 **`예측 가능한 성능을 제공하고 일반적인 순위를 제공할 수 없을까? 한 가지 해결책은 레디스를 사용하는 것이다`**.
  - 레디스는 메모리에서 동작하므로 빠른 읽기와 쓰기가 가능하고 sorted set 이라는 자료형을 제공한다.
  - 정렬 집합은 score을 기반으로 정렬되어 있으며 순위표에 딱 어울린다. 내부적으로 해시 테이블과 스킵 리스트라는 자료구조를 사용한다.
  - 정렬 집합은 삽입이나 갱신시 올바르게 정렬되며 새 원소를 추가하거나 검색하는 시간 복잡도가 O(log(n)) 이므로 RDB보다 성능이 좋다.

#### 저장소 요구사항

- 고려해야 할 요소는 CPU 사용량 및 I/O 사용량이다. 추정치에 따르면 갱신 연산의 최대 QPS는 2500/s 정도였다. 이는 단일 레디스 서버로 감당 가능하다.
- 한 가지 **`걱정되는 부분은 영속성이다. Redis 노드에도 장애는 발생할 수 있다`**. 보통은 레디스에 복제를 두는 식으로 구성한다.

### 상세 설계

- 만약 클라우드 인프라를 이용하고 있다면 **`AWS API 게이트웨이와 AWS 람다 두 가지 기술을 사용할 수 있다`**.
- 람다는 서버리스 컴퓨팅 플랫폼 중 하나로 필요할 때만 실행되며 트래픽에 따라 그 규모가 자동으로 확장된다.
- 게임은 API 게이트웨이를 호출하고, 이 게이트웨이는 적절한 람다 함수를 호출한다. 람다 함수는 스토리지의 명령을 호출해 얻은 결과를 API 게이트웨이에 반환하며 최종적으로 어플리케이션에 전달한다.
- **`람다 함수를 사용하면 서버를 만들지 않아도 질의를 실행할 수 있다`**. 람다 함수에서 레디스를 호출할 수 있는 클라이언트를 제공한다. 또한 **`람다는 규모 확장, 환경 설정, 유지 보수 등의 문제를 직접 관리할 필요가 없는 장점이 있다`**.

#### 레디스 규모 확장

- 500만 DAU 정도라면 한 대의 레디스 캐시 서버로도 충분히 지원할 수 있다.
- 그러나 원래 규모의 100배인 5억 DAU를 처리한다고 가정하면 샤딩이 필요하다.
- **`샤딩 방안으로 고정 파티션과 해시 파티션을 알아보자`**.
  - 고정 파티션
    - 순위표에 등장하는 점수의 범위에 따라 파티션을 나누는 방안이다.
    - 한 달 동안 획득할 수 있는 점수 범위가 1에서 1000이라고 했을 때 그 데이터를 범위별로 나누는 것이다.
  - 해시 파티션
    - 레디스 클러스터를 사용하는 것으로 사용자들의 점수가 특정 대역에 과도하게 모여 있는 경우 효과적이다.
    - 레디스 클러스터는 여러 노드에 데이터를 자동으로 샤딩하는 방법을 제공한다.
- 레디스 노드의 크기를 조정할 때는 여러 가지를 고려해야 한다. 쓰기 작업이 많은 어플리케이션은 장애에 대비해 스냅샷을 생성할 때 필요한 모든 쓰기 연산을 감당할 수 있어야 한다. 따라서 쓰기 연산이 많은 어플리케이션은 메모리를 두 배 할당하는 것이 안전하다.

## 결제 시스템

### 문제 이해 및 설계 범위 확정

- 기능 요구사항
  - 대금 수신: 결제 시스템이 판매자를 대신하여 고객으로부터 대금을 수령한다.
  - 대금 정산: 결제 시스템이 전 세계의 판매자에게 대금을 송금한다.
- 비기능 요구사항
  - 신뢰성 및 내결함성: 결제 실패는 신중히 처리해야 한다.
  - 시스템 간의 결제 정보가 일치하는지 비동기적으로 확인한다.
- 개략적인 규모 추정
  - 하루에 100만 건의 트랜잭션을 처리해야 하는데 이는 초당 10 건의 트랜잭션이다.
  - 10 TPS는 일반적인 DB로 처리하는데 문제 없으므로 결제 트랜잭션의 정확한 처리에 초점을 맞춰야 한다.

### 개략적 설계안 제시 및 동의 구하기

- 결제 흐름은 크게 대금 수신 흐름과 대금 정산 흐름으로 세분화 된다.
- 구매자가 주문을 하면 아마존의 은행 계좌로 돈이 들어오는데 이것이 바로 대금 수신 흐름이다. 제품이 배송되고 나면 계좌에 묶여있던 판매 대금에서 수수료를 제외한 잔액이 판매자의 은행 계좌로 지급된다. 이것이 대금 정산 흐름이다.

#### 대금 수신 흐름

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/system-design2/money-receive.png" width="500">

- 결제 서비스
  - 결제 서비스는 사용자로부터 이벤트를 수락하고 결제 프로세스를 조율한다.
  - 자금 세탁이나 범죄 행위의 증거가 있는지 평가하는 위험 점검을 통과한 결제만 처리한다.
  - 위험 확인 서비스는 매우 복잡하고 전문화 되어 있어 보통 제 3자 제공업체를 이용한다.
- 결제 실행자
  - 결제 실행자는 결제 서비스 공급자를 통해 결제 주문 하나를 실행한다.
- 결제 서비스 공급자
  - 결제 서비스 공급자(PSP)는 A 계정에서 B 계정으로 돈을 옮기는 역할을 담당한다.
  - 구매자의 신용카드 계좌에서 돈을 인출하는 역할을 맡는다.
- 카드 유형
  - 카드사는 신용 카드 업무를 처리하는 조직이다. 잘 알려진 카드 유형으로는 비자, 마스터 카드, 디스커버리 등이 있다.
- 원장
  - 원장은 결제 트랜잭션에 대한 금융 기록이다. 사용자가 판매자에게 1달러를 결제하면 사용자로부터 1달러를 인출하고 판매자에게 1달러를 지급하는 기록을 남긴다. 전자상거래 웹사이트의 총 수익을 계산하거나 향후 수익을 예측하는 등, 결제 후 분석에 중요한 역할을 한다.
- 일반적인 결제 흐름은 다음과 같다.
  - 사용자가 주문하기 버튼을 클릭하면 결제 이벤트가 생성되어 결제 서비스로 전송된다.
  - 결제 서비스는 결제 이벤트를 DB에 저장한다.
  - 결제 실행자는 결제 주문을 DB에 저장한다.
  - 결제 실행자가 외부 PSP를 호출하여 신용 카드 결제를 처리한다.
  - 결제 실행자가 결제를 성공적으로 처리하고 나면 결제 서비스는 지갑을 갱신하여 판매자의 잔고를 기록한다.
  - 지갑 서버는 갱신된 잔고 정보를 DB에 저장한다.
  - 지갑 서비스가 판매자 잔고를 성공적으로 갱신하면 결제 서비스는 원장을 호출한다.
  - 원장 서비스는 새 원장 정보를 DB에 추가한다.

#### 결제 서비스 데이터 모델

- 결제 서비스에는 결제 이벤트와 결제 주문의 두 개 테이블이 필요하다.
- 결제 시스템용 저장소를 고를 때 성능은 가장 중요한 사항은 아니다. 대신 아래에 중점을 둔다.
  - 안정성이 검증되었는가? 다른 대형 금융 회사에서 수년동안 긍정적인 피드백을 받으며 사용되었나?
  - 모니터링 및 데이터 탐사에 필요한 도구가 풍부하게 지원되는가?
  - DBA 채용 시장이 성숙했는가? 쉽게 말해 DBA를 쉽게 채용할 수 있나? 중요한 요소다.
- 일반적으로 NoSQL 보다는 ACID 트랜잭션을 지원하는 전통적인 관계형 DB를 선호한다.

### 상세 설계

- 분산 시스템에서 오류와 장애는 피할 수 없을 뿐 아니라 흔한 일이다.
- 고객이 결제 버튼을 여러 번 누르면 어떻게 될까? 여러번 요금이 청구되나? 네트워크 연결 불량으로 결제 실패는 어떻게 처리해야 하나?
- 이번 절에서는 시스템을 더 빠르고 안전하게 만드는데 초점을 둔다.

#### PSP 연동

- 결제 시스템이 은행이나 비자 or 마스터카드와 같은 카드 시스템에 직접 연결하는 경우는 매우 특수하다. 아주 큰 회사만이 가능할 것이다.
- 회사가 민감한 결제 정보를 안전하게 저장할 수 있다면 API를 통해 PSP와 연동하는 방법을 택할 수 있다. 반대로 민감한 결제 정보를 저장하지 않기로 결정했다면 PSP가 제공하는 안전한 외부 결제 페이지를 사용한다. 많은 기업들이 민감한 정보를 저장하지 않는 방식을 택한다.
- 외부 결제 페이지의 작동 방식을 살펴보자.
  - 사용자가 브라우저에서 결제 버튼을 클릭한다. 클라이언트느 결제 정보를 담아 결제 서비스를 호출한다.
  - 결제 서비스는 PSP로 결제 등록 요청을 전송한다. 요청에는 금액, 토오하, 결제 요청 만료일, 리다이렉션 URL 등의 결제 정보가 포함된다.
  - PSP는 결제 서비스에 토큰을 반환한다. 토큰은 결제 요청을 유일하게 식별하는 PSP가 발급한 UUID이다.
  - 결제 서비스는 PSP가 제공하는 외부 결제 페이지를 호출하기 전에 토큰을 DB에 저장한다.
  - 토큰을 저장하고 클라이언트는 PSP가 제공하는 외부 결제 페이지를 표시한다. 모바일 클라이언트는 일반적으로 PSP SDK를 연동한다.
  - 사용자는 신용 카드 번호, 소유자 이름, 유효기간 등의 민감한 정보를 PSP가 제공하는 페이지에 입력한 다음 결제 버튼을 클릭하고 PSP가 결제 처리를 시작한다.
  - PSP가 결제 상태를 반환한다.
  - 사용자는 리다이렉션 URL이 가리키는 웹 페이지로 보내진다.
  - 비동기적으로 PSP는 웹훅을 통해 결제 상태와 함께 결제 서비스를 호출한다. 웹훅은 결제 시스템 측에서 PSP를 처음 설정할 때 등록한 URL이다. 결제 시스템이 웹훅을 통해 결제 이벤트를 다시 수신하면 결제 상태를 추출하여 결제 주문 DB 테이블의 status 필드를 최신 상태로 업데이트 한다.

#### 조정

- 시스템이 비동기적으로 통신하는 경우 메시지가 전달되거나 응답이 반환된다는 보장이 없다. 시스템 성능을높이기 위해 비동기 통신을 자주 사용하는 결제 사업에 일반적인 문제다. PSP나 은행도 비동기 통신을 선호한다. 그렇다면 어떻게 정확성을 보장할 수 있을까?
- 답은 조정이다. 서비스 간 상태를 주기적으로 비교해 일치하는지 확인하는 것이다.
  - 매일 밤 PSP나 은행은 고객에게 정산 파일을 보낸다. 조정 시스템은 정산 파일의 세부 정보를 읽어 원장 시스템과 비교한다.
  - 조정은 결제 시스템의 내부 일관성을 확인할 때도 사용된다. 예를 들어 원장과 지갑의 상태가 같은지 확인할 수 있다.
  - 조정 중에 발견된 차이는 일반적으로 재무팀에 의뢰하여 수동으로 고친다.

#### 결제 지연 처리

- 결제 요청은 많은 컴포넌트를 거치며 내부 및 외부의 다양한 처리 주체와 연동한다. 대부분 결제 요청은 몇 초만에 처리되지만 완료되거나 거부되기 까지 몇 시간이 걸리는 경우도 있다. 다음은 결제 요청이 평소보다 오래 걸리는 몇 가지 사례이다.
  - PSP가 해당 결제 요청의 위험성이 높다고 보고 담당자 검토를 요구하는 경우
  - 신용 카드사가 구매 확인 용도로 추가 정보를 요청하는 3D 보안 인증 같은 추가 보호 장치를 요구하는 경우
- 결제 서비스는 시간이 오래 걸리는 이런 요청도 처리할 수 있어야 한다. PSP에 의해 구매 페이지가 제공되는 경우 PSP는 다음과 같이 처리한다.
  - PSP는 결제가 대기 상태임을 클라이언트에게 알리고 클라이언트는 이를 사용자에게 표시한다. 클라이언트는 또한 고객이 현재 결제 상태를 확인할 수 있는 페이지도 제공한다.
  - PSP는 우리 회사를대신하여 대기중인 결제의 진행 상황을 추적하고, 상태가 바뀌면 PSP에 등록된 웹훅을 통해 결제 서비스에 알린다.
- 결제 요청이 최종적으로 완료되면 PSP는 웹훅을 호출한다. 결제 서비스는 내부 시스템에 기록된 정보를 업데이트 하고 고객에게 배송을 완료한다.
