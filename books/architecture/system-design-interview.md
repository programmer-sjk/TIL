# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

- [책 링크](https://product.kyobobook.co.kr/detail/S000001033116)

## 사용자 수에 따른 규모 확장성

- 천리길도 한 걸음부터라는 말이 있듯, 서버가 한 대인 간단한 시스템부터 설계해보자.
- 클라이언트는 웹과 앱이고 서버 한대와 DB 한 대가 있다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/architecture/system-design-interview/simple.png" width="500">

### 어떤 데이터베이스를 사용할 것인가?

- 전통적인 관계형 DB와 비관계형 DB 사이에서 고를 수 있다. 차이점을 알아보자.
- RDBMS는 데이터를 테이블과 열, 커럼으로 표현한다. SQL을 사용해 테이블을 관계에 따라 조인하여 합칠 수 있다.
- 비 관계형 DB는 NoSQL이라고 부른다. 키-값 저장소, 그래프 저장소, 컬럼 저장소, 문서 저장소가 대표적이다.
- 대부분 RDBMS가 최선일텐데 그 이유는 40년 이상 시장에서 살아남아 작동해온 시스템이기 때문이다.
- 그 외에도 아래 같은 경우 비 관계형 DB가 바람직한 선택일 수 있다.
  - 아주 낮은 지연시간이 요구됨
  - 다루는 데이터가 비정형이나 관계형 데이터가 아님 (schema가 고정되어 있지 않음)
  - 아주 많은 양의 데이터를 저장하고 조회할 필요가 있음

### 수직적 규모 확장 VS 수평적 규모 확장

- 수직적 규모 확장은 scale up 이며 서버에 고사양 자원(cpu, memory)를 확장하는 행위를 말한다.
- 수평적 규모 확장은 scale out 이며 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.
- 서버로 유입되는 트래픽이 적을 때는 수직적 확장도 선택 방법이며 장점은 단순함이다. 하지만 수직적 확장은 자원을 무한대로 증설할 수 없는 한계가 있으며 장애에 대한 자동복구나 다중화 방안을 지원하지 않는다.
- 이런 이유로 대규모 애플리케이션을 지원하는 데는 수평적 규모 확장이 보다 적절하다.
- 앞에 간단한 시스템 설계에서는 사용자가 웹 서버에 바로 연결된다. 너무 많은 사용자가 접속하면 부하가 심하기 때문에 로드밸런서를 도입해야 한다.

### 로드밸런서

- 로드밸런서는 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.
- 사용자는 로드밸런서의 공개 IP주소로 접속한다. 따라서 웹 서버가 클라이언트의 접속을 직접 처리하지 않는다.
- 보안을 위해 로드밸런서와 뒷단의 서버 간 통신에는 사설 IP를 사용한다. 같은 네트워크에 속해야만 통신이 가능하기 때문에 외부 인터넷에서는 뒷단의 서버에 직접 접속할 수 없다.
- 로드 밸런서에 두 개 이상의 서버가 연결되면 장애를 자동복구하지 못하는 문제가 해소되며, 웹 계층의 가용성이 향상된다.

### DB 다중화

- 일반적으로 Master DB에 쓰기 연산을 수행하고 Slave DB에 읽기 연산을 수행하도록 다중화한다.
- DB를 다중화 해두면 아래와 같은 이점들이 존재한다.
  - 쓰기 연산과 읽기 연산이 분산되므로 병렬로 처리할 수 있는 쿼리 수가 늘어나므로 성능이 좋아진다.
  - 하나의 DB에 장애가 발생하더라도 다른 DB의 데이터를 가져와 계속 서비스를 할 수 있게 된다.
- DB를 Master, Slave 한 대씩 다중화한 상황에서 DB 하나가 다운되면 무슨 상황이 벌어지게 될까?
  - Slave가 다운된 상황이라면 읽기연산은 한시적으로 Master가 수행하게 된다. 새로운 Slave가 곧 추가되어 기존의 장애 서버를 대체한다.
  - Master가 다운된 상황이라면 Slave가 Master로 승격되어 쓰기 연산을 처리하게 된다. 이때 Slave의 데이터가 최신 데이터가 아닐 수 있는데 없는 데이터는 복구 스크립트를 돌려서 추가해야 한다.

### 캐시

- 캐시는 자주 사용되는 데이터를 메모리에 두고, 디스크에 접근하지 않고 빠른 응답을 제공하기 위해 사용된다.
- 캐시는 DB보다 훨씬 빠르다. 캐시를 두면 성능이 개선될 뿐 아니라 DB 부하를 줄일 수 있다.
- 캐시를 사용할 때는 아래 사항들을 고려해야만 한다.
  - 캐시는 어떤 데이터에 바람직한가: 자주 조회되지만 자주 갱신되는 않는 데이터
  - 어떤 데이터를 캐시에 둬야 할까: 캐시는 데이터를 휘발성 메모리에 두기에 영속적으로 보관할 데이터를 캐시에 두면 안된다.
  - 캐시 데이터의 만료 기간: 만료 시간이 너무 짧으면 DB를 자주 호출하기 때문에 적절한 만료 기한을 설정해야 한다.
  - 캐시의 일관성: 여기서 일관성은 DB와 캐시 데이터가 같은지 여부이다. 시스템이 크질때 캐시와 저장소 사이에 일관성을 유지하는것은 어려운 문제이다.
  - SPOF: 캐시 서버를 한대만 두면 단일 장애 지점이 될 수 있다. 결과적으로 SPOF를 피하려면 캐시 서버를 분산시켜야 한다.
  - 캐시 메모리: 메모리가 너무 작으면 데이터가 자주 밀려나버려 성능이 떨어진다. 이를 위해 조금 과하게 메모리를 할당하는 방법이 있다.
  - 데이터 방출 정책: 캐시가 꽉 차면 기존 데이터를 보내야 한다. LRU(Recently Used), LFU(Frequently Used, 사용빈도) 등 정책을 적용해야 한다.

### 컨텐츠 전송 네트워크 CDN

- CDN은 정적 컨텐츠를 전송하는 네트워크이다. 이미지, 비디오, CSS, JS 파일 등을 캐시할 수 있다.
- 사용자가 웹 사이트에 방문하면 사용자에게 가장 가까운 CDN 서버가 정적 컨텐츠르 전달하게 된다.
- CDN 동작에 대해 설명한다.
  - 사용자는 이미지 URL을 이용해 CDN이 제공하는 이미지에 접근한다.
  - CDN 캐시에 이미지가 없는 경우, CDN 서버는 원본 서버(웹 서버, S3)에 요청해 파일을 가져온다.
  - 원본 서버가 파일을 CDN 서버에 반환하며 HTTP 헤더에 TTL 값이 들어있다. CDN 서버는 파일을 캐시하고 사용자에게 반환한다.
  - 다른 사용자의 접속이 들어오면 만료되지 않은 캐시된 파일의 경우 CDN 서버가 제공한다.

<img src="https://github.com/programmer-sjk/TIL/blob/main/images/architecture/system-design-interview/cdn.png" width="500">

- CDN 사용시 고려할 점
  - CDN은 비용이 나가므로 자주 사용되지 않는 컨텐츠는 캐싱에서 빼는것이 좋다.
  - 만료 기한이 너무 짧지도 길지도 않은 적절한 시간을 잘 설정해야 한다.
  - CDN 자체가 죽었을 때 웹 서버가 어떻게 동작할지 고려해야 한다. 가령 CDN이 응답이 없을 경우, 클라이언트가 원본 서버에게 요청하도록 구성할 수 있다.

### 무상태 웹 계층

- 로그인 같은 상태 정보를 관계형 DB나 NoSQL과 같은 저장소에 보관하고 필요할 때 가져오는게 바람직한 전략이다.
- 만약 어플리케이션 서버가 상태 정보를 관리하면 클라이언트마다 특정 서버에만 접속해야 하는데 이는 로드밸런서에 부담을 주고 서버 장애시 처리하기도 복잡해진다.
- 어플리케이션 서버가 상태 정보를 공유 저장소로부터 가져오면 상태 정보는 웹 서버로부터 분리되며, 이런 구조는 단순하고 안정적이며 규모 확장이 쉽다.

### 메시지 큐

- 메시지 큐는 메시지의 무손실(큐에 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관되는 특성)을 보장하는 비동기 통신을 지원하는 컴포넌트다.
- 메시지 큐를 이용하면 서비스 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 어플리케이션을 구성하기 좋다. 생산자는 소비자가 다운되어 있어도 메시지를 발행할 수 있고 소비자는 생산자가 다운되어도 메시지를 수신할 수 있다.

### 데이터베이스의 규모 확장

- 저장할 데이터가 많아지면 DB에 대한 부하도 증가한다. DB 규모를 확장하는 방법은 수직적 확장과 수평적 확장이 있다.
- 수직적 확장은 CPU, RAM, DISK를 증설하는 방법이지만 몇 가지 약점이 있다. 하드웨어는 한계가 있으므로 사용자가 계속 늘어나면 한 대 서버로는 감당하기 어렵게 된다. 또 SPOF 위험성이 크며 고성능 서버로 갈 수록 비용이 높아진다.
- 수평적 확장은 샤딩이라고도 부르는데, 더 많은 서버를 추가하여 성능을 향상시킨다. 샤딩 키를 정할 때는 데이터를 고르게 분할할 수 있도록 하는게 중요하다. 샤딩은 DB 확장을 실현하는 훌륭한 기술이지만 풀어야 할 새로운 문제들도 생긴다. 데이터가 특정 샤드에만 많이 쌓이거나 특정 샤드에 쿼리가 집중되어 과부하가 걸리는 경우이다. 가령 유재석, 아이유, 백종원이 한 샤드에 저장되어 있다면 다른 샤드에 비해 더 과부하가 걸리게 된다. 또한 여러 샤드 서버로 쪼개고 나면 데이터를 조인하기가 쉽지 않기에, DB를 비정규화하여 하나의 테이블에서 쿼리가 수행되도록 하는 것도 염두해야 한다.

## 시스템 설계 면접 공략법

- 시스템 설계 면접은 전부 제각각이다. 훌륭한 설계 면접은 정해진 결말도, 정답도 없다. 하지만 절차나 범위에 공통적인 부분이 있다.
- 시스템 설계 면접을 볼 때 생각 없이 바로 답을 내놓는 행위는 부정적 신호다. 바로 답을 내지 말고 속도를 늦춰라. 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하라. 엔지니어가 가져야 할 중요한 기술은 올바른 질문을 하는 것, 적절한 가정을 하는 것, 시스템 구축에 필요한 정보를 모으는 것이다.
- 시스템 면접에서 해야 할 것은 다음과 같다.
  - 질문을 통해 확인하자. 스스로 내린 가정이 옳다고 믿지 말아라.
  - 문제의 요구사항을 이해해라.
  - 정답이나 최선의 답안은 없다는 점을 명심하자.
  - 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라. 면접관과 소통해라.
- 시스템 면접에서 하지 말아야 할 것은 다음과 같다.
  - 전형적인 면접 문제들에 대비하지 않은 상태에서 면접장에 가지 말자.
  - 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말자.
  - 진행중 막혔다면 힌트를 요청해라. 다시 말하지만 소통을 주저하지 말고 침묵 속에서 설계를 진행하지 말라.

## 처리율 제한 장치의 설계

- 네트워크 시스템에서 처리율 제한 장치는 트래픽의 처리율을 제어하기 위한 장치이다. HTTP로 예를 들면 특정 시간 내에 전송되는 클라이언트의 요청 횟수를 제한한다. 처리율 제한 장치의 좋은 점은 Dos 공격을 방지하고, 비용을 절감하며 봇이나 크롤링 도구 같은 접근으로부터 서버의 과부하를 막는다.

### 문제 이해 및 설계 범위 확정

- 면접관과 소통하며 어떤 제한 장치를 구현해야 하는지 분명히 할 수 있다.

  ```text
  지원자: 어떤 기준으로 제한해야 할까요? IP 주소를 사용해야 하나요? 아니면 사용자 ID? 생각하는 기준이 있을까요?
  면접관: 다양한 형태의 제어 규칙을 정의할 수 있도록 유연한 시스템이어야 합니다.

  지원자: 시스템 규모는 스타트업 정도의 회사일까요? 아니면 사용자가 많은 큰 기업을 위한 제품일까요?
  면접관: 대규모 요청을 처리할 수 있어야 합니다.

  지원자: 시스템이 분산 환경에서 동작해야 하나요?
  면접관: 그렇습니다.

  지원자: 처리율 제한 장치는 독립된 서비스입니까? 아니면 어플리케이션 코드에 포함될 수 있나요?
  면접관: 그 결정은 본인이 내려주시면 됩니다.

  지원자: 사용자의 요청이 처리율 제한 장치로 걸러질 경우 사용자에게 그 사실을 알려야 할까요?
  면접관: 그렇습니다.
  ```

- 아래에 요구사항을 정의해놓았다.
  - 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
  - 가능한 적은 메모리를 사용하며 HTTP 응답 시간에 나쁜 영향을 주면 안된다.
  - 분산형 처리율 제한으로 여러 서버에서 공유할 수 있어야 한다.
  - 요청이 제한되면 사용자에게 그 사실을 알려야 한다.

### 개략적 설계안 제시 및 동의 구하기

- 클라이언트는 처리율 제한 장치를 둘 수 있는 장소가 못 된다. 쉽게 위변조가 가능하기 때문에 서버측에 둔다.
- 처리율 제한 장치를 API가 있는 어플리케이션 서버에 두는 것도 방법이지만, 처리율 제한 미들웨어를 만들어 미들웨어가 API로 가는 요청을 통제하도록 구성할수도 있다.
  - 그렇다면 처리율 제한 장치를 서버에 둘까? 미들웨어 서버인 게이트웨이에 두어야 할까?
  - 정답은 없다. 기술 스택이나 개발자 인력, 우선 순위, 목표에 따라 달라질 수 있다.
  - 설계가 마이크로 서비스에 기반하고 있고, 사용자 인증이나 IP 허용목록을 위해 API 게이트웨이를 이미 사용하고 있다면 처리율 제한 기능은 게이트웨이에 포함시키는게 좋다.
  - 처리율 제한 서비스를 직접 만드는건 시간이 들기에 인력이나 시간이 없다면 상용 API 게이트웨이를 쓰는게 바람직할 것이다.
- 처리율 제한 알고리즘은 여러가지인데 각각 장단점을 가지고 있다. 필요하면 나중에 공부해보길
  - 토큰 버킷
  - 누출 버킷
  - 고정 윈도 카운터
  - 이동 윈도 로그
  - 이동 윈도 카운터
- 처리율 제한 알고리즘의 아이디어는 단순하다. 요청 수를 추적할 수 있는 카운터를 추적 대상별(사용자, IP, 엔드포인트)로 두고 한도를 넘어서 도착한 요청은 거부하는 것이다.
- 이 카운터를 디스크에 두면 느리기 때문에 메모리상에 동작하는 캐시가 바람직하다. 레디스는 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 기반 저장장치로 INCR과 EXPIRE 명령어를 지원한다. 동작 원리는 클라이언트가 처리율 제한 미들웨어에게 요청을 보낸다. 미들웨어는 레디스의 카운터를 가져와서 한도를 초과했는지 검사하고 초과했다면 요청을 거부한다.

### 상세 설계

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장될까? 보통 설정 파일 형태로 만들어져서 디스크에 저장된다.
- 처리가 제한된 요청은 어떻게 처리되는가? HTTP 429 응답(too many request)을 클라이언트에게 보낸다. 경우에 따라 메시지 큐에 보관했다가 나중에 처리할 수도 있을것이다.
- 전반적인 흐름을 클라이언트가 요청하면 API 앞단에 있는 처리율 제한 미들웨어에서 제한 규칙에 의거해 처리율 제한이 걸리지 않았다면 API 서버에게 요청을 보내고 제한이 걸렸다면 429 에러를 보내거나 경우에 따라 메시지 큐에 보관할 수도 있다.
- 분산 환경에서 처리율 제한 장치를 구현하면 경쟁 조건과 동기화 문제를 풀어야 한다.
  - 경쟁 조건은 병행성이 심한 환경에서 redis의 count 값을 동시에 같은 값으로 읽어 하나씩 업데이트하여 count 값이 잘못되는 문제로 lock을 사용하면 시스템의 성능이 떨어지므로 루아 스크립트를 쓰거나 sorted set이라고 불리는 자료구조를 활용하는 방법이 있다.
  - 동기화 이슈는 처리율 제한 장치가 여러개 일때 동기화 하는 이슈로 보통 하나의 레디스를 사용해 동기화된 하나의 데이터를 바라본다.

## 안정 해시 설계

- 수평적 규모 확장성을 달성하기 위해서는 요청을 서버에 균등하게 나누는 것이 중요하다.

### 해시 키 재배치 문제

- N개의 캐시 서버가 있다고 가정하자. 이 서버들에 부하를 균등하게 나누는 보편적인 방법은 아래의 계산을 적용하는것이다.

  ```
    serverIndex = hash(key) % N (N은 서버 개수)
  ```

- 서버가 4대라면 해시 값을 4의 나머지 연산을 통해 나온 값으로 서버의 인덱스를 지정한다. 이 방법은 서버가 고정으로 운영되고 데이터 분포가 균등할때는 잘 동작한다. 문제는 서버가 추가되거나 삭제되면 문제가 생긴다. 4대의 서버 중 한대의 서버가 장애가 발생하면 3으로 나머지 연산을 하기 때문에 같은 키라도 다른 서버의 인덱스를 가리킨다. 결과적으로 대규모 캐시 미스가 발생하게 된다.
