# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

- [책 링크](https://product.kyobobook.co.kr/detail/S000001033116)

## 사용자 수에 따른 규모 확장성

- 천리길도 한 걸음부터라는 말이 있듯, 서버가 한 대인 간단한 시스템부터 설계해보자.
- 클라이언트는 웹과 앱이고 서버 한대와 DB 한 대가 있다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/architecture/system-design-interview/simple.png" width="500">

### 어떤 데이터베이스를 사용할 것인가?

- 전통적인 **`관계형 DB와 비관계형 DB 사이에서 고를 수 있다`**. 차이점을 알아보자.
- RDBMS는 데이터를 테이블과 열, 컬럼으로 표현한다. SQL을 사용해 테이블을 관계에 따라 조인하여 합칠 수 있다.
- 비 관계형 DB는 NoSQL이라고 부른다. 키-값 저장소, 그래프 저장소, 컬럼 저장소, 문서 저장소가 대표적이다.
- 대부분 RDBMS가 최선일텐데 그 이유는 40년 이상 시장에서 살아남아 작동해온 시스템이기 때문이다.
- 그 외에도 **`아래 같은 경우 비 관계형 DB가 바람직한 선택일 수 있다`**.
  - 아주 낮은 지연시간이 요구됨
  - 다루는 데이터가 비정형이나 관계형 데이터가 아님 (schema가 고정되어 있지 않음)
  - 아주 많은 양의 데이터를 저장하고 조회할 필요가 있음

### 수직적 규모 확장 VS 수평적 규모 확장

- **`수직적 규모 확장은`** scale up 이며 서버에 고사양 자원(cpu, memory)를 확장하는 행위를 말한다.
- **`수평적 규모 확장은`** scale out 이며 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.
- 서버로 유입되는 트래픽이 적을 때는 수직적 확장도 선택 방법이며 장점은 단순함이다. 하지만 **`수직적 확장은 자원을 무한대로 증설할 수 없는 한계가 있으며 장애에 대한 자동복구나 다중화 방안을 지원하지 않는다`**.
- 이런 이유로 대규모 애플리케이션을 지원하는 데는 수평적 규모 확장이 보다 적절하다.
- 앞에 간단한 시스템 설계에서는 사용자가 웹 서버에 바로 연결된다. 너무 많은 사용자가 접속하면 부하가 심하기 때문에 로드밸런서를 도입해야 한다.

### 로드밸런서

- **`로드밸런서는 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다`**.
- 사용자는 로드밸런서의 공개 IP주소로 접속한다. 따라서 웹 서버가 클라이언트의 접속을 직접 처리하지 않는다.
- 보안을 위해 로드밸런서와 뒷단의 서버 간 통신에는 사설 IP를 사용한다. 같은 네트워크에 속해야만 통신이 가능하기 때문에 외부 인터넷에서는 뒷단의 서버에 직접 접속할 수 없다.
- 로드 밸런서에 두 개 이상의 서버가 연결되면 장애를 자동복구하지 못하는 문제가 해소되며, 웹 계층의 가용성이 향상된다.

### DB 다중화

- 일반적으로 Master DB에 쓰기 연산을 수행하고 Slave DB에 읽기 연산을 수행하도록 다중화한다.
- **`DB를 다중화 해두면 아래와 같은 이점들이 존재한다`**.
  - 쓰기 연산과 읽기 연산이 분산되므로 병렬로 처리할 수 있는 쿼리 수가 늘어나므로 성능이 좋아진다.
  - 하나의 DB에 장애가 발생하더라도 다른 DB의 데이터를 가져와 계속 서비스를 할 수 있게 된다.
- DB를 Master, Slave 한 대씩 다중화한 상황에서 **`DB 하나가 다운되면 무슨 상황이 벌어지게 될까?`**
  - Slave가 다운된 상황이라면 읽기연산은 한시적으로 Master가 수행하게 된다. 새로운 Slave가 곧 추가되어 기존의 장애 서버를 대체한다.
  - Master가 다운된 상황이라면 Slave가 Master로 승격되어 쓰기 연산을 처리하게 된다. 이때 Slave의 데이터가 최신 데이터가 아닐 수 있는데 없는 데이터는 복구 스크립트를 돌려서 추가해야 한다.

### 캐시

- 캐시는 자주 사용되는 데이터를 메모리에 두고, 디스크에 접근하지 않고 빠른 응답을 제공하기 위해 사용된다.
- **`캐시는 DB보다 훨씬 빠르다. 캐시를 두면 성능이 개선될 뿐 아니라 DB 부하를 줄일 수 있다`**.
- **`캐시를 사용할 때는 아래 사항들을 고려해야만 한다`**.
  - 캐시는 어떤 데이터에 바람직한가: 자주 조회되지만 자주 갱신되는 않는 데이터
  - 어떤 데이터를 캐시에 둬야 할까: 캐시는 데이터를 휘발성 메모리에 두기에 영속적으로 보관할 데이터를 캐시에 두면 안된다.
  - 캐시 데이터의 만료 기간: 만료 시간이 너무 짧으면 DB를 자주 호출하기 때문에 적절한 만료 기한을 설정해야 한다.
  - 캐시의 일관성: 여기서 일관성은 DB와 캐시 데이터가 같은지 여부이다. 시스템이 크질때 캐시와 저장소 사이에 일관성을 유지하는것은 어려운 문제이다.
  - SPOF: 캐시 서버를 한대만 두면 단일 장애 지점이 될 수 있다. 결과적으로 SPOF를 피하려면 캐시 서버를 분산시켜야 한다.
  - 캐시 메모리: 메모리가 너무 작으면 데이터가 자주 밀려나버려 성능이 떨어진다. 이를 위해 조금 과하게 메모리를 할당하는 방법이 있다.
  - 데이터 방출 정책: 캐시가 꽉 차면 기존 데이터를 보내야 한다. LRU(Recently Used), LFU(Frequently Used, 사용빈도) 등 정책을 적용해야 한다.

### 컨텐츠 전송 네트워크 CDN

- **`CDN은 정적 컨텐츠를 전송하는 네트워크이다`**. 이미지, 비디오, CSS, JS 파일 등을 캐시할 수 있다.
- 사용자가 웹 사이트에 방문하면 사용자에게 가장 가까운 CDN 서버가 정적 컨텐츠르 전달하게 된다.
- CDN 동작에 대해 설명한다.
  - 사용자는 이미지 URL을 이용해 CDN이 제공하는 이미지에 접근한다.
  - CDN 캐시에 이미지가 없는 경우, CDN 서버는 원본 서버(웹 서버, S3)에 요청해 파일을 가져온다.
  - 원본 서버가 파일을 CDN 서버에 반환하며 HTTP 헤더에 TTL 값이 들어있다. CDN 서버는 파일을 캐시하고 사용자에게 반환한다.
  - 다른 사용자의 접속이 들어오면 만료되지 않은 캐시된 파일의 경우 CDN 서버가 제공한다.

<img src="https://github.com/programmer-sjk/TIL/blob/main/images/architecture/system-design-interview/cdn.png" width="500">

- CDN 사용시 고려할 점
  - CDN은 비용이 나가므로 자주 사용되지 않는 컨텐츠는 캐싱에서 빼는것이 좋다.
  - 만료 기한이 너무 짧지도 길지도 않은 적절한 시간을 잘 설정해야 한다.
  - CDN 자체가 죽었을 때 웹 서버가 어떻게 동작할지 고려해야 한다. 가령 CDN이 응답이 없을 경우, 클라이언트가 원본 서버에게 요청하도록 구성할 수 있다.

### 무상태 웹 계층

- **`로그인 같은 상태 정보를 관계형 DB나 NoSQL과 같은 저장소에 보관하고 필요할 때 가져오는게 바람직한 전략이다`**.
- 만약 어플리케이션 서버가 상태 정보를 관리하면 클라이언트마다 특정 서버에만 접속해야 하는데 이는 로드밸런서에 부담을 주고 서버 장애시 처리하기도 복잡해진다.
- 어플리케이션 서버가 상태 정보를 공유 저장소로부터 가져오면 상태 정보는 웹 서버로부터 분리되며, 이런 구조는 단순하고 안정적이며 규모 확장이 쉽다.

### 메시지 큐

- **`메시지 큐는 메시지의 무손실(큐에 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관되는 특성)을 보장하는 비동기 통신을 지원하는 컴포넌트다`**.
- 메시지 큐를 이용하면 서비스 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 어플리케이션을 구성하기 좋다. 생산자는 소비자가 다운되어 있어도 메시지를 발행할 수 있고 소비자는 생산자가 다운되어도 메시지를 수신할 수 있다.

### 데이터베이스의 규모 확장

- 저장할 데이터가 많아지면 DB에 대한 부하도 증가한다. **`DB 규모를 확장하는 방법은 수직적 확장과 수평적 확장이 있다`**.
- 수직적 확장은 CPU, RAM, DISK를 증설하는 방법이지만 몇 가지 약점이 있다. 하드웨어는 한계가 있으므로 사용자가 계속 늘어나면 한 대 서버로는 감당하기 어렵게 된다. 또 SPOF 위험성이 크며 고성능 서버로 갈 수록 비용이 높아진다.
- 수평적 확장은 샤딩이라고도 부르는데, 더 많은 서버를 추가하여 성능을 향상시킨다. 샤딩 키를 정할 때는 데이터를 고르게 분할할 수 있도록 하는게 중요하다. 샤딩은 DB 확장을 실현하는 훌륭한 기술이지만 풀어야 할 새로운 문제들도 생긴다. 데이터가 특정 샤드에만 많이 쌓이거나 특정 샤드에 쿼리가 집중되어 과부하가 걸리는 경우이다. 가령 유재석, 아이유, 백종원이 한 샤드에 저장되어 있다면 다른 샤드에 비해 더 과부하가 걸리게 된다. 또한 여러 샤드 서버로 쪼개고 나면 데이터를 조인하기가 쉽지 않기에, DB를 비정규화하여 하나의 테이블에서 쿼리가 수행되도록 하는 것도 염두해야 한다.

## 시스템 설계 면접 공략법

- 시스템 설계 면접은 전부 제각각이다. 훌륭한 설계 면접은 정해진 결말도, 정답도 없다. 하지만 절차나 범위에 공통적인 부분이 있다.
- 시스템 설계 면접을 볼 때 생각 없이 **`바로 답을 내놓는 행위는 부정적 신호다`**. 바로 답을 내지 말고 속도를 늦춰라. 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하라. **`엔지니어가 가져야 할 중요한 기술은 올바른 질문을 하는 것, 적절한 가정을 하는 것, 시스템 구축에 필요한 정보를 모으는 것이다`**.
- 시스템 면접에서 해야 할 것은 다음과 같다.
  - 질문을 통해 확인하자. 스스로 내린 가정이 옳다고 믿지 말아라.
  - 문제의 요구사항을 이해해라.
  - 정답이나 최선의 답안은 없다는 점을 명심하자.
  - 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라. 면접관과 소통해라.
- 시스템 면접에서 하지 말아야 할 것은 다음과 같다.
  - 전형적인 면접 문제들에 대비하지 않은 상태에서 면접장에 가지 말자.
  - 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말자.
  - 진행중 막혔다면 힌트를 요청해라. 다시 말하지만 소통을 주저하지 말고 침묵 속에서 설계를 진행하지 말라.

## 처리율 제한 장치의 설계

- 네트워크 시스템에서 **`처리율 제한 장치는 트래픽의 처리율을 제어하기 위한 장치이다`**. HTTP로 예를 들면 특정 시간 내에 전송되는 클라이언트의 요청 횟수를 제한한다. 처리율 제한 장치의 좋은 점은 Dos 공격을 방지하고, 비용을 절감하며 봇이나 크롤링 도구 같은 접근으로부터 서버의 과부하를 막는다.

### 문제 이해 및 설계 범위 확정

- 면접관과 소통하며 어떤 제한 장치를 구현해야 하는지 분명히 할 수 있다.

  ```text
  지원자: 어떤 기준으로 제한해야 할까요? IP 주소를 사용해야 하나요? 아니면 사용자 ID? 생각하는 기준이 있을까요?
  면접관: 다양한 형태의 제어 규칙을 정의할 수 있도록 유연한 시스템이어야 합니다.

  지원자: 시스템 규모는 스타트업 정도의 회사일까요? 아니면 사용자가 많은 큰 기업을 위한 제품일까요?
  면접관: 대규모 요청을 처리할 수 있어야 합니다.

  지원자: 시스템이 분산 환경에서 동작해야 하나요?
  면접관: 그렇습니다.

  지원자: 처리율 제한 장치는 독립된 서비스입니까? 아니면 어플리케이션 코드에 포함될 수 있나요?
  면접관: 그 결정은 본인이 내려주시면 됩니다.

  지원자: 사용자의 요청이 처리율 제한 장치로 걸러질 경우 사용자에게 그 사실을 알려야 할까요?
  면접관: 그렇습니다.
  ```

- 아래에 요구사항을 정의해놓았다.
  - 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
  - 가능한 적은 메모리를 사용하며 HTTP 응답 시간에 나쁜 영향을 주면 안된다.
  - 분산형 처리율 제한으로 여러 서버에서 공유할 수 있어야 한다.
  - 요청이 제한되면 사용자에게 그 사실을 알려야 한다.

### 개략적 설계안 제시 및 동의 구하기

- 클라이언트는 처리율 제한 장치를 둘 수 있는 장소가 못 된다. 쉽게 위변조가 가능하기 때문에 서버측에 둔다.
- 처리율 제한 장치를 API가 있는 어플리케이션 서버에 두는 것도 방법이지만, 처리율 제한 미들웨어를 만들어 미들웨어가 API로 가는 요청을 통제하도록 구성할수도 있다.
  - 그렇다면 처리율 제한 장치를 서버에 둘까? 미들웨어 서버인 게이트웨이에 두어야 할까?
  - 정답은 없다. 기술 스택이나 개발자 인력, 우선 순위, 목표에 따라 달라질 수 있다.
  - 설계가 마이크로 서비스에 기반하고 있고, 사용자 인증이나 IP 허용목록을 위해 API 게이트웨이를 이미 사용하고 있다면 처리율 제한 기능은 게이트웨이에 포함시키는게 좋다.
  - 처리율 제한 서비스를 직접 만드는건 시간이 들기에 인력이나 시간이 없다면 상용 API 게이트웨이를 쓰는게 바람직할 것이다.
- 처리율 제한 알고리즘은 여러가지인데 각각 장단점을 가지고 있다. 필요하면 나중에 공부해보길
  - 토큰 버킷
  - 누출 버킷
  - 고정 윈도 카운터
  - 이동 윈도 로그
  - 이동 윈도 카운터
- **`처리율 제한 알고리즘의 아이디어는 단순하다`**. 요청 수를 추적할 수 있는 카운터를 추적 대상별(사용자, IP, 엔드포인트)로 두고 한도를 넘어서 도착한 요청은 거부하는 것이다.
- 이 카운터를 디스크에 두면 느리기 때문에 메모리상에 동작하는 캐시가 바람직하다. 레디스는 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 기반 저장장치로 `INCR`과 `EXPIRE` 명령어를 지원한다. 동작 원리는 클라이언트가 처리율 제한 미들웨어에게 요청을 보낸다. 미들웨어는 레디스의 카운터를 가져와서 한도를 초과했는지 검사하고 초과했다면 요청을 거부한다.

### 상세 설계

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장될까? 보통 설정 파일 형태로 만들어져서 디스크에 저장된다.
- 처리가 제한된 요청은 어떻게 처리되는가? HTTP 429 응답(too many request)을 클라이언트에게 보낸다. 경우에 따라 메시지 큐에 보관했다가 나중에 처리할 수도 있을것이다.
- **`전반적인 흐름은`** 클라이언트가 요청하면 API 앞단에 있는 처리율 제한 미들웨어에서 제한 규칙에 의거해 처리율 제한이 걸리지 않았다면 API 서버에게 요청을 보내고 제한이 걸렸다면 429 에러를 보내거나 경우에 따라 메시지 큐에 보관할 수도 있다.
- 분산 환경에서 처리율 제한 장치를 구현하면 경쟁 조건과 동기화 문제를 풀어야 한다.
  - 경쟁 조건은 병행성이 심한 환경에서 redis의 count 값을 동시에 같은 값으로 읽어 하나씩 업데이트하여 count 값이 잘못되는 문제로 lock을 사용하면 시스템의 성능이 떨어지므로 루아 스크립트를 쓰거나 sorted set이라고 불리는 자료구조를 활용하는 방법이 있다.
  - 동기화 이슈는 처리율 제한 장치가 여러개 일때 동기화 하는 이슈로 보통 하나의 레디스를 사용해 동기화된 하나의 데이터를 바라본다.

## 안정 해시 설계

- 수평적 규모 확장성을 달성하기 위해서는 **`요청을 서버에 균등하게 나누는 것이 중요하다`**.

### 해시 키 재배치 문제

- N개의 캐시 서버가 있다고 가정하자. 이 서버들에 부하를 균등하게 나누는 보편적인 방법은 아래의 계산을 적용하는것이다.

  ```
    serverIndex = hash(key) % N (N은 서버 개수)
  ```

- 서버가 4대라면 해시 값을 4의 나머지 연산을 통해 나온 값으로 서버의 인덱스를 지정한다. 이 방법은 서버가 고정으로 운영되고 데이터 분포가 균등할때는 잘 동작한다. **`문제는 서버가 추가되거나 삭제되면 문제가 생긴다`**. 4대의 서버 중 한대의 서버가 장애가 발생하면 3으로 나머지 연산을 하기 때문에 **`같은 키라도 다른 서버의 인덱스를 가리킨다`**. 결과적으로 대규모 캐시 미스가 발생하게 된다.

### 안정 해시

- 안정 해시는 **`해시 테이블 크기가 조정될 때 일부의 키만 재배치하는 해시 기술이다`**. 이와 달리 전통적 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.
- 해시 함수로 SHA-1을 택하면 해시 공간의 범위는 0~2^160-1까지라고 알려져있다. 이 해시 공간의 양 끝을 구부려 접어서 링을 만든다고 가정하자. 해시 함수를 이용해 서버 IP나 이름을 해시해서 링 위에 배치할 수 있다. **`여기서 사용된 해시 함수는 나머지 연산을 사용하지 않는다. 나머지 연산을 사용하면 슬롯 수에 따라 무조건 재배치된다`**.
- 링 위에 4개의 서버를 s0~s3이라고 가정하자. s0 ~ s1 사이에 있는 해시 값들은 s1 서버에 저장되고 s1 ~ s2 사이에 있는 해시 값들은 s2 서버에 저장된다. 새로운 서버 s4가 s3 ~ s0 사이에 추가되면 s3 ~ s4 사이에 있는 해시 값들만 s4에 재배치된다. 만약 s4 서버가 빠질 경우, s3 ~ s4에 있던 해시 값들이 s0으로 재배치됨으로써 재배치를 최소화 할 수 있다.

### 마치며

- **`안정 해시의 이점은 다음과 같다`**.
  - 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.
  - 데이터가 보다 균등하게 분포되므로 수평적 규모 확장성을 달성하기 쉽다.
  - 핫스팟 키 문제를 줄인다. 특정한 샤드에 접근이 빈번하면 서버 과부하 문제가 발생할 수 있는데, 안정 해시는 데이터를 좀 더 균등하게 분배하므로 이런 가능성을 줄인다.
- 안정 해시는 실제로 널리 쓰이는 기술이다. 그 중 유명한 사례를 몇개 예로 든다.
  - Dynamo DB의 파티셔닝 관련 컴포넌트
  - 카산드라 클러스터에서의 데이터 파티셔닝
  - 디스코드 채팅 어플리케이션

## 키 값 저장소 설계

- 키 값 저장소는 키 값 데이터베이스라고 불리기도 하는 비 관계형 데이터베이스다.
- 키는 유일해야 하며 키를 통해서만 값에 접근할 수 있다. **`성능상의 이유로 키는 짧을수록 좋다`**. 값은 배열일수도 있고 객체일 수도 있다. 보통 값으로 무엇이 오든 상관하지 않는다.

### 문제 이해 및 설계 범위

- 완벽한 설계란 없다. 읽기, 쓰기, 메모리 사용량 사이에 균형을 찾고, 일관성과 가용성 사이에서 적당한 설계를 만들었다면 쓸만한 답안일 것이다. 이번 장에서는 **`아래 특성을 갖는 키 값 저장소를 설계해 볼 것이다`**.
  - 큰 데이터를 저장할 수 있어야 한다.
  - 높은 가용성을 제공해야 한다. 설사 장애가 있더라도 빨리 응답해야 한다.
  - 높은 규모 확장성을 제공해야 한다. 트래픽 양에 따라 자동으로 서버 증설/삭제가 이뤄진다.
  - 데이터 일관성 수준은 조정이 가능해야 한다.

### 단일 서버 키 값 저장소

- 한 대 서버로 키 값 저장소를 설계하는 것은 쉽다. 가장 직관적인 방법은 키 값 쌍을 전부 메모리에 해시 테이블로 저장하는 것이다.
- 하지만 한 대 서버로 부족한 때가 곧 찾아온다. **`많은 데이터를 저장하려면 분산 키 값 저장소를 만들 필요가 있다`**.

### 분산 키 값 저장소

- 분산 키 값 저장소는 키 값을 여러 서버에 분산시켜 저장한다. **`분산 시스템을 설계할 때는 CAP 정리를 이해하고 있어야 한다`**.

#### CAP 정리

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/cap.png" width="600">

- CAP 정리는 **`데이터 일관성, 가용성, 파티션 감내라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하단 정리이다`**.
  - 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했냐에 관계없이 같은 데이터를 봐야 한다.
  - 가용성: 일부 노드에 장애가 발생해도 항상 응답을 받을 수 있어야 한다.
  - 파티션 감내: 파티션 감내는 두 노드 사이에 통신 장애가 발생했음을 의미한다. 파티션 감내는 네트워크에 문제가 생기더라도 시스템은 계속 동작하여야 한다는 것을 의미한다.
- **`CAP 정리는 어떤 두 가지를 충족하려면 나머지 하나는 반드시 희생되어야 한다는 것을 의미한다`**.
  - CP 시스템: 일관성과 파티션 감내를 지원하는 키 값 저장소. 가용성을 희생한다.
  - AP 시스템: 가용성과 파티션 감내를 지원하는 키 값 저장소. 일관성을 희생한다.
  - CA 시스템: 일관성과 가용성을 지원한다. 그러나 네트워크 장애는 피할 수 없는 일로 여겨지므로, 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계되어야 한다. 그러므로 실세계에 CA 시스템은 존재하지 않는다.
- 세 대의 복제 노드 n1, n2, n3에 데이터를 복제해서 보관하는 상황을 상상해보자. 이때 n3에 장애가 발생하고 n3에 저장되었으나 아직 n1, n2로 전달되지 않은 데이터가 있다면 n1, n2는 오래된 사본을 가지고 있을 것이다. 일관성을 선택한다면 세 서버 사이의 데이터 불일치 문제를 피하기 위해 n1, n2에 대해 쓰기 연산을 중단시켜야 한다. 이러면 가용성이 깨진다. 은행권 시스템은 보통 일관성을 양보하지 않는다. 네트워크 파티션 때문에 일관성이 깨질 것 같으면 해결될때까지 오류를 반환해야 한다.
- 만약 가용성을 선택했다면, 설사 낡은 데이터를 반환할 위험이 있더라도 계속 읽기 연산을 허용해야 한다. 아울러 n1, n2는 계속 쓰기 연산을 허용할 것이고 파티션 문제가 해결된 뒤에 새 데이터를 n3에 전송할 것이다. 분산 키 값 저장소를 만들 때는 요구사하에 맞도록 CAP 정리를 적용해야 한다.

#### 시스템 컴포넌트

- 키 값 저장소 구현에 사용될 핵심 컴포넌트 및 기술들을 살펴보자.
- **`데이터 파티션`**
  - 규모가 클수록 전체 데이터를 한 대 서버에 저장하는것은 불가능하다. 단순한 해결책은 데이터를 작은 파티션으로 분할한 다음 여러 서버에 저장하는 것이다. 데이터를 파티션 단위로 나눌 때 다음 두가지 문제를 고려해야 한다.
    - 데이터를 여러 서버에 고르게 분산할 수 있는가.
    - 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화 할 수 있는가
  - 이전에 다룬 안정 해시는 이런 문제를 해결하는데 적합한 기술이다.
- **`데이터 다중화`**
  - 높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화할 필요가 있다. 이를 위해 어떤 키를 해시 링 위에 배치한 후, 그 지점부터 시계 방향으로 링을 순회하면서 만나는 N개 서버에 데이터 사본을 보관할 수 있다.
- **`데이터 일관성`**
  - 여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다. 정족수 합의 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있다. N대의 서버에 쓰기 연산이 성공한것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 한다.
  - 위에서 W, R, N 값을 정하는 것은 응답 지연과 데이터 일관성 사이의 타협점을 찾는 전형적인 과정이다. W, R의 값이 1이라면 중재자는 한 대 서버로부터 응답만 받으면 되니 응답 속도는 빠를 것이다. 값이 1보다 크다면 데이터 일관성의 수준은 높아지지만 응답은 느려진다. 면접 시에 N, W, R을 어떻게 정해야 할까?
    - 빠른 읽기 연산 시스템 (R=1, W=N)
    - 빠른 쓰기 연산 시스템 (W=1, R=N)
    - 강한 일관성이 보장 (W +R > N)
    - 약한 일관성 (W + R <= N)
- **`일관성 모델`**
  - 일관성 모델은 데이터 일관성의 수준을 결정하며 종류가 다양하다.
  - 강한 일관성 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다.
  - 약한 일관성: 가장 최근의 데이터를 반환하지 못할수도 있다.
  - 최종 일관성: 약한 일관성의 형태로, 갱신 결과가 결국에는 모든 사본에 반영되는 모델이다.
- **`비 일관성 해소 기법`**
  - 데이터를 다중화하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성이 높다. 버저닝과 벡터 시계는 그 문제를 해소하기 위해 등장한 기술이다. 버저닝은 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것을 의미한다. 따라서 각 버전의 데이터는 변경 불가능하다.
  - 벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것이다. 어떤 버전이 선행 버전이고 후행 버전인지 판별하는데 쓰인다.
- **`쓰기 경로`**
  - 쓰기 요청이 특정 노드에 전달되면 아래와 같은 절차를 따른다.
    - 쓰기 요청이 디스크의 커밋 로그에 기록된다.
    - 데이터가 메모리 캐시에 기록된다.
    - 메모리 캐시가 가득차거나 어떤 임계치에 도달하면 디스크에 있는 SSTable에 기록된다. SSTable은 Sorted String Table의 약어로 <키,값> 순서쌍을 정렬된 리스트 형태로 관리하는 테이블이다.
- **`읽기 경로`**
  - 읽기 요청을 받으면 아래와 같은 절차를 따른다.
  - 노드는 데이터가 메모리 캐시에 있는지 살핀다. 있는 경우 클라이언트에게 반환한다.
  - 메모리에 없으면 블룸 필터를 검사해 어떤 SSTable에 키가 보관되어 있는지 알아낸다.
  - SSTable에서 데이터를 가져온다.
  - 해당 데이터를 클라이언트에게 반환한다.

### 요약

- 분산 키 값 저장소가 가져야 하는 **`목표와 목표를 이루는데 사용된 기술을 정리하면 아래와 같다`**.
  - 대규모 데이터 저장: 안정 해시를 사용해 서버들에 부하 분산
  - 읽기 연산에 대한 가용성: 데이터를 여러 데이터 센터에 다중화
  - 쓰기 연산에 대한 가용성: 버저닝, 벡터 시계를 사용한 충돌 해소
  - 데이터 파티션: 안정 해시
  - 점진적 규모 확장성: 안정 해시
  - 조절 가능한 데이터 일관성: 정족수 합의

## 분산 시스템을 위한 유일 ID 생성기 설계

- 유일 ID를 생성한다고 했을 때 `DB의 auto_increment 속성이 설정된 기본 키를 사용하면 되지 않을까?` 생각할 수 있다.
  - 분산 환경에서는 DB 한 대로는 그 요구를 감당할 수 없을뿐더러, 여러 DB를 쓰는 경우 지연 시간을 낮추기가 힘들다.

### 문제 이해 및 설계 범위 확정

- 시스템 설계 면접을 푸는 첫 단계는 적절한 질문을 통해 모호함을 없애고 설계 방향을 정하는 것이다.

  ```text
  지원자: ID는 어떤 특성을 갖나요?
  면접관: ID는 유일해야 하고 정렬 가능해야 합니다.

  지원자: 새로운 레코드에 붙일 ID는 항상 1만큼 큰 값이어야 하나요?
  면접관: 언제나 1씩 증가하진 않습니다. 확실한 것은 아침보다 저녁에 만든 ID가 큰 값을 가집니다.

  지원자: ID는 숫자로만 구성되나요?
  면접관: 그렇습니다.

  지원자: 시스템 규모는 어떻게 되나요?
  면접관: 초당 i0,000 ID를 생성할 수 있어야 합니다.
  ```

- 문제에 대한 **`요구사항은 다음과 같다`**.
  - ID는 유일해야 하며 숫자로만 구성되어야 한다.
  - ID는 64 비트로 표현될 수 있는 값이다.
  - ID는 발급 날짜에 따라 정렬 가능해야 한다.
  - 초당 10,000개의 ID를 만들 수 있어야 한다.

### 개략적 설계안 제시 및 동의 구하기

- 분산 시스템에서 **`유일성이 보장되는 ID를 만드는 방법은 여러 가지다`**. 아래와 같은 선택지를 살펴본다.
  - 다중 마스터 복제
  - UUID
  - 티켓 서버
  - 트위터 스노플레이크 접근법

#### 다중 마스터 복제

- **`DB의 auto_incrment 기능을 활용하는 방법으로`** ID 값이 1이 아니라 마스터 DB 수만큼 증가시킨다.
- 이 방법은 다음과 같은 중대한 단점이 있다.
  - 여러 데이터 센터에 걸쳐 규모를 늘리기 어렵다.
  - ID가 시간 흐름에 맞추어 커지도록 보장할수는 없다.
  - DB를 추가하거나 삭제될 때 잘 동작하도록 만들기 어렵다.

#### UUID

- UUID는 **`유일성이 보장되는 ID를 만드는 간단한 방법으로`** 128비트짜리 수이다.
- UUID 장점은 만드는게 단순해 서버 사이의 조율이 필요없어 동기화 이슈가 없다. 각 서버가 자기가 UUID를 만드는 구조이므로 규모 확장도 쉽다.
- 현재 설계와 관련해 UUID의 단점은 128비트로 요구사항은 64비트다. ID를 시간순으로 정렬할 수 없고 숫자가 아닌 다른 값이 포함될 수 있다.

#### 티켓 서버

- 티켓 서버는 유일성을 보장하는 ID를 만들어내는 또 하나의 방법이다.
- 이 아이디어의 핵심은 **`auto_increment 기능을 갖춘 DB를 중앙 집중형으로 하나만 사용하는 것이다`**.
- 장점은 유일성이 보장되는 숫자로만 구성된 ID를 쉽게 만들 수 있고, 구현하기 쉬우며 중소 규모 어플리케이션에 적합하다.
- 단점은 티켓 서버가 SPOF가 된다. 이 서버에 장애가 발생하면 모든 시스템이 영향을 받는다. 이 이슈를 피하기 위해 티켓 서버를 여러대 준비하면 동기화 같은 새로운 문제가 발생하게 된다.

#### 트위터 스노플레이크

- 트위터는 **`스노플레이크라고 부르는 독창적인 ID 생성 기법을 사용한다`**. 64 bit를 여러 section으로 분할한다.
- 사인 비트, 타임 스탬프, 데이터 센터 ID, 서버 ID, 일련 번호들이 64bit를 구성한다.

### 상세 설계

- 데이터 센터 ID, 서버 ID는 시스템이 시작할 때 결정되며 운영 중에는 바뀌지 않는다.
- 타임스탬프는 ID 구조에서 41비트를 차지하고 있고 시간 흐름에 따라 점점 커지므로 ID는 시간 순으로 정렬 가능하게 된다.

## URL 단축기 설계

### 문제 이해 및 설계 범위 확정

- 시스템의 **`기본적 기능은 아래와 같다`**.
  - URL 단축: 주어진 긴 URL을 훨씬 짧게 줄인다.
  - URL 리다이렉션: 축약된 URL로 HTTP 요청이 오면 원래 URL로 안내
  - 높은 가용서오가 규모 확장성, 장애 감내가 요구됨
- 시스템 성능 추정
  - 쓰기 연산: 매일 1억개의 단축 URL 생성
  - 초당 쓰기 연산: 1억 / 24 / 3600 = 1160
  - 읽기 연산: 읽기 연산은 쓰기 연산에 비해 10배 많다고 가정하면 초당 11,600회 발생
  - URL 단축 서비스를 10년 운영한다고 가정하면 1억 _ 365 _ 10 = 3650억개의 레코드를 보관
  - 축략 전 URL 평균 길이를 100 이라고 가정하자. 10년동안 필요한 용량은 `3650억 * 100` 바이트로 36.5TB이다.

### 개략적 설계안 제시 및 동의 구하기

- 클라이언트는 서버와 API 엔드포인트를 통해 서버와 통신한다. **`URL 단축키는 기본적으로 두 개의 엔드포인트를 필요로 한다`**.
  - **`URL 단축용 엔드포인트`**: 새 단축 URL을 생성하고 싶은 클라이언트는 단축할 URL을 POST 요청으로 보내야 한다.
  - **`URL 리다이렉션 엔드포인트`**: 단축 URL에 대해 HTTP 요청이오면 원래 URL로 보내주기 위한 엔드포인트
- 단축 URL을 받은 서버는 원래 URL로 바꾸어서 301 응답의 Location 헤더에 넣어 반환한다.
  - **`301 Permanetly Moved`**: 이 응답은 영구적으로 이관되었단 의미로 브라우저는 이 응답을 캐시한다. 따라서 동일한 단축 URL에 요청을 보낼 때 브라우저는 캐시된 원래 URL로 요청을 보낸다.
  - **`302 Found`**: 일시적으로 Location 헤더가 지정하는 URL에 의해 처리되어야 한다는 응답이다. 클라이언트는 언제나 단축 URL 서버에 먼저 보내진 후 원래 URL로 리다이렉션 한다.
- 단축 URL 서버 부하를 줄여야 한다면 301을 사용하는게 좋다. 첫 번째 URL만 단축 URL 서버로 전달되기 때문이다. 반대로 트래픽 분석이 중요할 때는 302를 쓰는게 클릭 발생율이나 발생 위치를 추적하는데 좀 더 유리하다.

### 상세 설계

- 데이터 모델의 경우 `<단축 URL, 원래 URL>` 순서 쌍을 관계형 DB에 저장하는 것이 좋다. 실제 테이블은 더 많은 컬럼을 가질 수 있지만 필수 컬럼은 `id, shortURL, longURL` 세개의 컬럼을 가진다.
- 해시 값에는 숫자와 소문자, 대문자가 올 수 있으니 **`해시 길이 하나당 62개의 문자가 올 수 있다`**. 62^n 승이 3650억보다 큰 n의 최소값을 찾아야 한다. n이 7이면 3.5조개의 URL을 만들 수 있다. 요구사항을 만족시키기 충분하므로 해시 값의 길이는 7로 하겠다.
- 보통 해시 값은 7보다 크다. **`어떻게 줄일 수 있을까?`** 첫 번째 해결책은 해시 값에서 처음 7개의 글자만 이용하는 것이다. 하지만 이렇게 되면 충돌할 확률이 높기 때문에 실제 충돌이 발생하면 사전에 정한 문자열을 해시값에 덧붙인다. 충돌은 해소할 수 있지만 단축 URL을 생성할 떄 한 번 이상 DB에 쿼리해야 하므로 오버헤드가 크다. DB 대신 블룸 필터를 사용하면 성능을 높일 수 있다. 블룸 필터는 어떤 집합에 특정 원소가 있는지 검사할 수 있는 확률론에 기초한 공간 효율이 좋은 기술이다.
- **`진법 변환은 URL 단축키를 구현할 때 흔히 사용되는 접근법이다`**. 62진법을 쓰는 이유는 hashvalue에 사용할 수 있는 문자 개수가 62개이기 때문이다. 단축 URL은 원래 URL을 62진법으로 변환한 값이 사용된다.

#### URL 단축키 상세 설계

- **`URL 단축키는 시스템의 핵심 컴포넌트이므로, 그 처리 흐름이 단순하고 기능적으로 언제나 동작해야 한다`**.
- URL 단축키 상세 설계 절차를 정리하면 아래와 같다.
  - 입력으로 긴 URL을 받는다.
  - DB에 URL이 있다면 단축 URL을 만든 적이 있다는 의미로 단축 URL을 반환한다.
  - DB에 없다면 유일한 ID를 생성해 PK로 사용한다.
  - 62진법을 사용해 긴 URL을 변환하고 이를 단축 URL로 만든다.
  - ID, 단축 URL, 원본 URL을 DB에 저장하고 단축 URL을 클라이언트에 응답한다.

## 알림 시스템 설계

- 알림 시스템은 단순히 모바일 푸시 알림에 한정되지 않고, 모바일 푸시 알림, SMS 메시지, 이메일이 포함될 수 있다.

### 문제 이해 및 설계 범위 확정

- 하루에 백만 건 이상의 알림을 처리하는 확장성 높은 시스템을 구축하는게 쉬운 과제는 아니다. 알림 시스템이 어떻게 구현되는지에 대한 깊은 이해가 필요하다.

  ```text
  지원자: 어떤 종류의 알림을 지원해야 하나요?
  면접관: 푸시 알림, SMS 메시지, 이메일입니다.

  지원자: 실시간 시스템이어야 하나요?
  면접관: 가능한 빨리 전달되어야 하지만 시스템에 부하가 있을 때 약간의 지연은 무방합니다.

  지원자: 어떤 종류의 단말을 지원해야 하나요?
  면접관: IOS, 안드로이드, 랩탑을 지원해야 합니다.

  지원자: 사용자 알림 설정에 따라 알림을 받지 않을 수 있나요?
  면접관: 네 설정을 통해 알림을 받지 않을 수 있습니다.

  지원자: 하루에 몇 건의 알림을 보낼 수 있어야 하나요?
  면접관: 천 만 건의 모바일 푸시 알림, 백만 건의 SMS 메시지, 5백만 건의 이메일을 보낼 수 있어야 합니다.
  ```

### 개략적 설계안 제시 및 동의 구하기

- 알림 유형별 지원 방안
  - IOS에 알림을 보내려면 APNS가 필요하다. APNS란 애플리 제공하는 원격 서비스로 푸시 알림을 IOS로 보내는 역할을 담당한다.
  - 안드로이드도 IOS와 비슷한 절차로 전송된다. APNS 대신 FCM(Firebase Cloud Message)을 사용하다는 점만 다르다.
  - SMS이나 이메일을 보낼때는 보통 제 3의 서비스를 많이 이용한다.
- 연락처 수집 절차
  - 알림을 보내려면 모바일 단말 토큰, 전화번호, 이메일 등의 정보가 필요하다.
  - 사용자가 앱을 설치하거나 회원가입을 하면 DB에 해당 정보들을 저장한다. 이메일과 핸드폰 정보는 사용자 테이블에, 단말 토큰은 device 테이블에 저장한다. 한 사용자가 여러 단말을 가질 수 있고 알림은 모든 단말에 전송되어야 한다는 점을 반영한다.

#### 개략적 설계안 초기 버전

- 아래 그림은 개략적 설계의 초안이다. MSA 환경에서 N대의 서비스가 알림 서비스를 사용하고 있다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/alarm-init.png" width="500">

- 위 설계에는 몇 가지 문제가 있다.
  - 알림 서비스에 서버가 하나뿐이라 SPOF가 될 수 있고, DB나 캐시등의 저장소를 늘릴 방법이 없다. 또한 알림을 보내는 것은 자원을 많이 필요로 하는 자원일 수 있다. 모든 것을 한 서버에서 처리하면 사용자 트래픽이 몰리는 시간에 시스템이 과부하 상태에 빠질 수 있다.

#### 개략적 설계안 개선 버전

- 아래 그림은 개선된 버전이다. DB와 캐시를 분리하고 알림 서버를 증설해 수평적 규모 확장이 이루어지도록 한다. 메시지 큐를 이용해 시스템 컴포넌트 사이의 강한 결합을 끊는다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/alarm-improved.png" width="500">

- 위 구성 중 메시지 큐와 작업 서버에 대해서만 좀 더 알아보자.
  - 메시지 큐: 시스템 간 의존성을 제거하기 위해 사용하고 대량의 알림이 전송될 때를 대비해 버퍼 역할도 한다.
  - 작업 서버: 메시지 큐에서 전송할 아림을 꺼내서 제 3자 서비스로 전달하는 역할을 담당하는 서비스다.
- 컴포넌트들이 협력하여 알림을 전송하는 절차를 살펴보자.
  - 다른 서비스들에서 API를 호출해 알림 서버로 알림을 보낸다.
  - 알림 서버는 사용자 정보, 단말 토큰, 알림 설정을 DB나 캐시로부터 가져온다.
  - 알림 서버는 전송할 알림에 맞는 이벤트를 만들어서 메시지 큐에 넣는다.
  - 작업 서버는 메시지 큐에서 알림 이벤트를 꺼내 알림을 제 3자 서비스로 보낸다.

### 상세 설계

- 분산 환경에서 안정성을 확보하기 위해 몇 가지를 고려해야 한다.
  - 데이터 손실 방지: 알림 시스템의 가장 중요한 요구사항 중 하나는 알림이 소실되면 안 된다는 것이다. 알림이 지연되거나 순서가 틀려도 괜찮지만 사라지면 곤란하다. 이를 위해 알림 시스템은 알림 데이터를 DB에 보관하고 재시도 메커니즘을 구현해야 한다.
  - 알림 중복 전송 방지: 분산 시스템의 특성 상 알림이 중복되어 전송되기도 할 것이다. 빈도를 줄이려면 중복을 탐지하는 메커니즘을 도입하고 오류를 신중하게 처리해야 한다. 간단히 보면 알림의 ID를 검사해 처리된 이벤트인지 검사한다. 중복된 이벤트라면 버리고 그렇지 않으면 알림을 보낸다.
- 알림 템플릿
  - 대형 알림 시스템은 하루에도 수백만건의 알림을 보내는데 알림 메시지 형식은 대부분 비슷하다.
  - 알림 템플릿은 이런 유사성을 고려해 알림 메시지의 모든 부분을 처음부터 다시 만들 필요 없도록 해준다.
  - 템플릿을 사용하면 알림의 형식을 일관성있게 유지할 수 있고 알림 작성에 드는 시간도 줄일 수 있다.
- 알림 설정
  - 사용자는 많은 알림을 받을 경우 쉽게 피곤함을 느낀다. 따라서 많은 서비스들이 사용자가 알림 설정을 상세히 조정할 수 있도록 하고 있다.
- 전송률 제한
  - 사용자에게 너무 많은 알림을 보내지 않도록 하는 한 가지 방법은, 한 사용자가 받을 수 있는 알림의 빈도를 제한하는 것이다. 알림은 너무 많이 보내면 사용자가 알림 기능을 아예 꺼버릴 수 있기 때문에 고려할 사항이다.
- 재시도 방법
  - 알림 전송에 실패하면 해당 알림을 재시도 전용 큐에 넣는다. 같은 문제가 계속해서 발생하면 개발자에게 통지한다.

## 뉴스 피드 시스템 설계

- 뉴스 피드란 무엇인가? 뉴스 피드는 홈 중앙에 지속적으로 업데이트 되는 스토리들로 사진, 비디오, 앱 활동, 사용자가 팔로하는 사람들, 페이지, 그룹으로부터 나오는 좋아요 등을 포함한다고 설명한다. 뉴스 피드 시스템 설계는 유명한 면접 문제로 페이스북, 인스타 피드 설계 등이 있다.

### 문제 이해 및 설계 범위 확정

```text
  지원자: 모바일 앱과 웹을 둘 다 지원해야 하나요?
  면접관: 둘 다 지원해야 합니다.

  지원자: 중요한 기능은 어떤 것이 있을까요?
  면접관: 사용자는 뉴스 피드에 새로운 스토리를 올릴 수 있어야 하고, 친구들이 올리는 스토리도 볼 수 있어야 합니다.

  지원자: 뉴스 피드는 어떤 순서로 표시되나요? 최신 포스트가 위에 오도록 하나요? 아니면 점수 기준이 있습니까?
  면접관: 단순히 시간 흐름 역순이라고 가정합시다.

  지원자: 한 명의 사용자는 최대 몇명의 친구를 가질 수 있나요?
  면접관: 최대 5,000 명입니다.

  지원자: 트래픽 규모는 어느 정도 입니까?
  면접관: 매일 천만 명이 방문한다고 가정합시다.
```

### 개략적 설계안 제시 및 동의 구하기

- 살펴볼 설계안은 피드 발행과 뉴스 피드 생성 두 가지 부분으로 나뉜다.
  - 피드 발행: 사용자가 스토리를 포스팅하면 해당 데이터를 캐시와 DB에 저장한다. 새 포스팅은 친구의 뉴스 피드에도 전송된다.
  - 뉴스 피드 생성: 모든 친구의 포스팅은 최신순으로 만든다.
- 뉴스 피드 API
  - 피드 발생 API: POST /v1/me/feed
  - 피드 읽기 API: GET /v1/me/feed
- 피드 발행 절차
  - 웹 서버는 요청을 받아 새 포스팅을 DB와 캐시에 저장한다.
  - 새 포스팅을 친구의 뉴스 피드에 푸시한다. 캐시에 보관하여 빠르게 읽어갈 수 있도록 한다.
  - 친구들에게 새 포스팅이 올라왔음을 알리거나 별도의 알림 서비스가 있다면 메시지를 전달한다.

### 상세 설계

#### 피드 발행 흐름 상세 설계

- 팬아웃은 어떤 사용자의 새 포스팅을 그 사용자와 친구 관계에 있는 모든 사용자에게 전달하는 과정이다. 팬아웃에는 두 가지 모델이 있다. 하나는 쓰기 시점에 팬아웃이고 다른 하나는 읽기 시점에 팬아웃하는 모델이다. 각각의 동작원리를 좀 더 살펴보자.
  - 쓰기 시점에 팬아웃하는 모델: 포스팅이 완료되면 바로 사용자의 캐시에 해당 포스팅을 기록하는 방법이다. 뉴스 피드가 실시간으로 갱신되며 친구 목록에 있는 사용자에게 즉시 전송된다. 또한 뉴스 피드를 읽는데 드는 시간이 짧은 장점이 있다. 단점으로는 친구가 많은 경우 사용자 모두의 뉴스 피드를 갱신하는데 많은 시간이 소요될 수 있고 서비스를 자주 사용하지 않는 사용자들끼리 갱신하므로 리소스가 낭비될 수 있다.
  - 읽기 시점에 팬아웃하는 모델: 사용자가 피드를 읽어야 하는 시점에 뉴스 피드를 갱신한다. 비활성화 사용자, 접속을 잘 하지 않는 사용자의 경우 이 모델이 유리하다. 단점으로는 모든 사용자가 피드를 읽는 시점에 갱신하기 때문에 뉴스 피드를 읽는 시간이 더 소요된다.
- 본 설계에서는 장점은 취하고 단점을 버리는 전략을 취한다. 뉴스 피드를 빠르게 읽는 것은 중요하므로 대부분의 사용자에 대해서는 실시간 갱신을 사용한다. 친구나 팔로워가 많은 사용자의 경우 필요할 때 가져가도록 하는 풀 모델을 사용해 시스템 과부하를 낮출 생각이다.
- 팬아웃 서비스의 동작은 아래와 같다.
  - 그래프 DB에서 친구 ID 목록을 가져온다. 그래프 DB는 친구 관계나 친구 추천을 관리하기 적합하다.
  - 사용자 정보 캐시에서 친구들 정보를 가져온다. 그런 후 사용자 설정에 따라 친구 일부를 걸러낸다(무시하기 설정한 경우)
  - 친구 목록과 새 스토리의 포스팅 ID를 메시지 큐에 넣는다.
  - 팬아웃 작업 서버가 메시지 큐에서 데이터를 꺼내어 뉴스 피드 데이터를 뉴스 피드 캐시에 넣는다. 캐시에는 <포스트 ID, 사용자 ID>의 순서쌍을 보관한다. 전체 포스팅 정보를 저장하지 않는 이유는 메모리 요구량이 지나치게 늘어날 수 있기 때문이다. 따라서 캐시에는 ID만 보관한다. 보통 뉴스 피드는 최신 스토리를 보려고 하는 경우가 많기에 전체 피드 ID를 저장할 필요는 없다. 서비스에 맞게 캐시에 저장하는 개수를 조정해야 한다.

#### 피드 읽기 흐름 상세 설계

- 사용자가 뉴스 피드를 읽기 위해 /v1/me/feed로 요청을 전달한다.
- 로드 밸런서가 요청을 웹 서버 중 하나로 보낸다.
- 웹 서버는 피드를 가져오기 위해 뉴스 피드 서비스를 호출한다.
- 뉴스 피드 서비스는 캐시에서 포스팅 ID 목록을 가져온다.
- 뉴스 피드에 표시할 사용자 이름, 사진, 포스팅 컨텐츠, 이미지 등을 사용자 캐시와 포스팅 캐시에서 가져와 완전한 뉴스 피드를 만든다.
- 생성한 뉴스 피드를 JSON 형태로 클라이언트에게 보낸다. 클라이언트는 해당 피드를 렌더링 한다.

## 채팅 시스템 설계

### 문제 이해 및 설계 범위 확정

- 어떤 채팅 앱을 설계하려는지 확실히 해 두는 것이 면접에서 가장 중요하다. 위챗이나 왓츠앱처럼 1:1 채팅에 집중하는 앱들이 있는가 하면 슬랙과 같은 그룹 채팅에 중점을 둔 업무용 앱이나 게임 채팅에 쓰이는 디스코드 같은 대규모 그룹의 소통과 응답지연이 낮은 음성 채팅에 집중하는 앱도 있다.

```text
  지원자: 어떤 앱을 설계해야 하나요? 1:1 채팅입니까 그룹 채팅 앱입니까?
  면접관: 둘 다 지원해야 합니다.

  지원자: 모바일 앱인가요? 웹 앱인가요?
  면접관: 둘 다입니다.

  지원자: 처리해야 하는 트래픽 규모는 어느 정도 입니까?
  면접관: 일별 액티브 사용자 수 기준으로 5천만명을 처리할 수 있어야 합니다.

  지원자: 그룹 채팅의 경우 인원 제한이 있습니까?
  면접관: 최대 100명까지 참여할 수 있습니다.

  지원자: 중요 기능엔 어떤게 있습니까? 첨부 파일도 지원할 수 있어야 하나요?
  면접관: 1:1 채팅, 그룹 채팅, 사용자 접속상태 표시를 지원해야 합니다. 텍스트 메시지만 주고 받는다고 가정합시다.

  지원자: 메시지 길이에 제한이 있나요?
  면접관: 100,000자 이하여야 합니다.

  지원자: 채팅 이력은 얼마나 보관해야 하나요?
  면접관: 영원히요.
```

- 정리하면 다음과 같은 기능이 요구된다.
  - 응답지연이 낮은 일대일 채팅 기능
  - 최대 100명까지 참여할 수 있느 그룹 채팅 기능
  - 사용자의 접속 상태 표시 기능
  - 5천만 DAU의 채팅 제공

### 개략적 설계안 제시 및 동의 구하기

- 채팅 시스템의 경우 클라이언트는 모바일 앱이거나 웹 어플리케이션이다. 클라이언트는 직접 통신하지 않고 채팅 서비스와 통신한다.
- 채팅 서비스는 아래 기능을 제공해야 한다.
  - 클라이언트로부터 메시지 수신
  - 메시지 수신자 결정 및 전달
  - 수신자가 접속 상태가 아니라면 접속할 때 까지 해당 메시지 보관
- HTTP 메서드는 메시지 전송 용도로는 괜찮은 선택이다. 하지만 메시지 수신 시나리오는 복잡하다. HTTP는 클라이언트가 연결을 만드는 프로토콜이다. 하지만 채팅 서버가 임의로 클라이언트에게 메시지를 보내는 데는 쉽게 쓰일 수 없다. 서버가 연결을 만드는 것첢 동작할 수 있는 폴링, 롱 폴링, 웹 소켓과 같은 기술들이 발전해왔다.
  - 폴링: 클라이언트가 주기적으로 서버에게 새 메시지가 있냐고 물어보는 방법이다. 폴링 비용은 폴링을 자주할수록 올라간다. 답해줄 메시지가 없는 경우 서버 자원이 불필요하게 낭비된다는 문제도 있다.
  - 롱 폴링: 폴링은 여러가지로 비 효율적일 수 있어서 롱 폴링이 나왔다. 롱 폴링의 경우 클라이언트는 새 메시지가 반환되거나 타임아웃 될 때까지 연결을 유지한다. 이 방법도 서버 입장에서 클라이언트가 연결을 해제했는지 알 수 없고, 여전히 비효율적이다.
  - 웹 소켓: 웹 소켓은 서버가 클라이언트에게 비동기 메시지를 보낼 때 가장 널리 사용하는 기술이다. 웹 소켓 연결은 클라이언트가 시작한다. 한 번 맺어진 연결은 영구적이며 양방향이다. 이 연결을 통해 서버는 클라이언트에게 비동기적으로 메시지를 전송할 수 있다.

#### 규모 확장성

- 트래픽 규모가 작다면 모든 기능을 서버 한대로 구현할 수 있다. 이번 장에서 동시 접속자를 1M이라고 가정한다. 접속당 10K의 메모리가 필요하다고 가정하면 10GB 메모리만 있으면 처리할 수 있을 것이다. 하지만 서버 한대로 설계안을 내밀면 면접에서 좋은 점수를 따기는 어려울 것이다. 누구도 그 정도의 트래픽을 서버 한 대로 처리하지 않으려 할 것이고, SPOF도 한 가지 문제이다.

#### 저장소

- 중요한 한 가지는 어떤 DB를 쓰느냐다. RDB를 쓸 것인가 NoSQL를 채택할 것인가? 이 질문에 대한 답을 찾으려면 데이터의 유형과 읽기/쓰기 연산의 패턴을 살펴봐야 한다. 채팅 시스템이 다루는 데이터는 보통 두 가지이다. 사용자 프로필, 설정, 친구 목록처럼 일반적인 데이터이다. 이런 데이터는 안정성을 보장하는 RDB에 보관한다. 두 번째 유형의 데이터는 채팅 데이터로, 바로 채팅 이력이다.
- 채팅 이력 데이터의 양은 엄청나다. 왓츠앱은 매일 600억 개의 메시지를 처리한다. 이 중 빈번하게 사용되는 것은 최근에 주고받은 메시지다. 대부분의 사용자는 오래된 메시지를 보지 않는다. 1:1 채팅 앱의 경우 읽기 쓰기 비율은 1:1 이다.
- 본 설계안의 겨우 키-값 저장소를 추천하는데 이유는 아래와 같다.
  - 키 값 저장소는 수평적 규모 확장이 쉽다.
  - 데이터 접근 지연시간이 낮다.
  - 이미 많은 안정적인 채팅 시스템이 키 값 저장소를 채택하고 있다. 페이스북은 HBase를 사용하고 디스코드는 카산드라를 사용하고 있다.

### 상세 설계

- 채팅 시스템에는 서비스 탐색을 좀 더 살펴볼만 하다. 서비스 탐색 기능의 주 된 역할은 클라이언트에게 가장 적합한 채팅 서버를 추천하는 것이다. 기준으로는 클라이언트의 위치나 서버의 용량등이 있다. 서비스 탐색 기능을 구현하는데 널리 쓰이는 오픈 소스 솔루션으로는 아파치 주키퍼가 있다. 사용가능한 모든 채팅 서버를 여기에 등록시켜 두고 클라이언트가 접속을 시도하면 기준에 따라 최적의 채팅 서버를 골라준다.
- 주키퍼로 구현한 서비스 탐색 기능 절차는 다음과 같다.
  - 사용자 A가 시스템에 로그인을 시도한다.
  - 로드밸런서가 사용자 요청을 API 서버들 가운데 하나로 보낸다.
  - API 서버가 사용자 인증을 처리하고 나면 서비스 탐색 기능이 동작해 최적의 채팅 서버를 찾는다.
  - 사용자 A는 위에서 찾는 채팅 서버와 웹 소켓 연결을 맺는다.
- 1:1 채팅 메시지 처리 흐름
  - 사용자 A가 채팅 서버 1로 메시지 전송
  - 채팅 서버 1은 메시지를 메시지 큐로 전송
  - 메시지가 키 값 저장소에 보관됨
  - 사용자 B가 접속 중인 경우 메시지는 사용자 B가 접속 중인 채팅 서버로 전송됨.
  - 사용자 B가 접속 중인 채팅 서버에서 사용자 B에게 메시지 전송.
- 접속 상태 표시
  - 사용자의 접속 상태를 표시하는 것은 채팅 어플리케이션의 핵심 기능이다.
  - 사용자가 로그인을 하면 접속 상태 서버는 사용자의 상태(status: onLine)와 last_active_at을 키 값 저장소에 저장한다. 이 절차를 통해 사용자는 접속중으로 표시된다.
  - 로그아웃을 하면 상태가 onLine에서 offLine으로 바뀌게 된다.
  - 평소에는 클라이언트가 주기적으로 heartbeat 이벤트를 접속 상태 서버로 보내도록 하고, 마지막 이벤트를 받은지 x초 이내에 또 다른 이벤트를 받으면 사용자의 접속 상태를 계속 온라인으로 유지한다. 그렇지 않을 경우에만 오프라인으로 바꾼다.

## 검색어 자동완성 시스템

- 검색어 자동완성은 많은 서비스에서 주요하게 사용되는 기능이다. 가장 많이 이용된 검색어 k개를 자동완성하여 출력하는 시스템을 설계해보자.

### 문제 이해 및 설계 범위 확정

```text
  지원자: 사용자가 입력하는 단어는 자동완성될 검색어의 첫 부분인가요? 아니면 중간 부분도 될 수 있습니까?
  면접관: 첫 부분으로 한정하겠습니다.

  지원자: 몇 개의 자동완성 검색어가 표시되어야 합니까?
  면접관: 5개입니다.

  지원자: 자동 완성 검색어를 고르는 기준은 무엇입니까?
  면접관: 질의 빈도에 따라 정해지는 검색어 인기 순위를 기준으로 삼겠습니다.

  지원자: 대문자나 특수 문자도 처리해야 합니까?
  면접관: 아뇨. 모든 질의는 영어 소문자로 이루어진다고 가정하겠습니다.

  지원자: 얼마나 많은 사용자를 지원해야 하나요?
  면접관: DAU 기준으로 천만입니다.
```

- 요구사항을 정리해보자.
  - 빠른 응답속도를 제공한다. 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빨리 표시되어야 한다. 시스템 응답속도는 100ms 이하여야 한다. 그렇지 않으면 시스템 이용이 불편해진다.
  - 연관성: 인기도 등의 순위 모델에 의해 정렬되어 있어야 한다.
  - 규모 확장성: 시스템이 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
  - 고가용성: 시스템에 장애가 발생하거나 예상치 못한 네트워크 문제가 생겨도 시스템을 계속 사용할 수 있어야 한다.
- 규모 추정
  - 일간 DAU는 천만명으로 가정한다. 평균적으로 한명이 매일 10건의 검색을 수행한다.
  - 질의할 때마다 평균적으로 20 바이트의 데이터를 입력한다고 가정하자. (한 문자당 1 바이트라고 가정한다.)
  - 검색창에 글자를 입력할 때마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보낸다. 평균적으로 1회 검색당 20건의 요청이 백엔드로 전달된다.
  - 대략 초당 24,000건의 질의가 발생한다 (`천만 * 10건 * 20단어 * 24시간 / 3600`)

### 개략적 설계안 제시 및 동의 구하기

- 시스템은 크게 두 부분으로 나뉜다
  - 데이터 수집 서비스: 사용자가 입력한 단어를 실시간으로 수집하는 시스템이다.
  - 질의 서비스: 주어진 질의에 대한 인기 검색어를 정렬해 응답하는 서비스.
- 질의문과 사용빈도를 저장하는 frequency table이 있다고 가정하자. 처음에 비어있다가 사용자가 단어를 검색하면 이 테이블에 저장된다.
  - 컬럼은 query(검색된 단어)와 fequency(사용된 빈도)를 가지고 있다.
  - 가장 많이 사용된 검색어 5개는 아래 쿼리를 통해 계산할 수 있다.
  - `SELECT * FROM frequency_table WHERE query Like 'prefix%' ORDER BY frequency DESC LIMIT 5`
- 데이터 양이 적을 때는 나쁘지 않은 설계안이다. 하지만 데이터가 많아질수록 DB가 병목이 될 수 있다.

### 상세 설계

- 최적화를 위해 다음 방안들을 논의해 볼 것이다.
  - 트라이 자료구조
  - 데이터 수집 서비스
  - 질의 서비스
  - 규모 확장이 가능한 저장소
  - 트라이 연산

#### 트라이 자료구조

- 트라이는 문자열들을 간략하게 저장할 수 있는 자료구조이다. 트라이의 핵심 아이디어는 다음과 같다.
  - 트라이는 트리 형태의 자료구조로 루트 노드는 빈 문자열을 나타낸다.
  - 각 노드는 글자 하나를 저장하며 26개의 자식 노드를 가질 수 있다.
  - 각 트리 노드는 하나의 단어, 또는 접두어 문자열을 나타낸다.
- 기본 트라이 자료구조는 노드에 문자들을 저장한다. 빈도에 따라 정렬된 결과를 내놓기 위해 빈도 정보까지 저장할 필요가 있다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/trie.png" width="500">

- 그렇다면 트라이로 검색어 자동완성은 어떻게 구현할 수 있을까? 우선 용어를 몇 가지 정의해보자.
  - p: 접두어의 길이
  - n: 트라이 안에 있는 자식 노드
  - c: 주어진 노드의 자식 개수
- 가장 많이 사용된 질의어 k개는 다음과 같이 찾을 수 있다.
  - 해당 접두어를 표현하는 노드를 찾는다. 시간 복잡도는 O(n)이다.
  - 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 시간 복잡도는 O(c)이다.
  - 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다. 시간 복잡도는 O(clogc)이다.
- 이 알고리즘은 직관적이지만 최악의 경우에는 k개를 얻으려고 전체 트라이를 다 검색해야 하는 일이 생길 수 있다. 이 문제를 해결할 방법으로는 다음 두 가지가 있다.
  - 접두어의 최대 길이를 제한
    - 사용자가 긴 검색어를 입력하는 일은 거의 없다. 따라서 p값은 작은 정수 값이라고 가정해도 안전하다. 검색어의 최대 길이를 제한할 수 있다면 시간 복잡도는 O(p)에서 O(1)로 바뀔 것이다.
  - 각 노드에 인기 검색어를 캐시
    - 각 노드에 k개의 인기 검색어를 저장해두면 전체 트라이를 검색하는 일을 방지할 수 있고 복잡도를 낮출 수 있다. 하지만 각 노드에 질의어를 저장할 공간이 더 많이 필요하다는 단점도 있다. 그러나 빠른 응답 속도가 중요할 때는 이 정도 저장공간은 희생할 만한 가치가 있다.
- 위에 두 가지 최적화 기법을 사용하면 최고 인기 검색어 k개를 찾는 알고리즘의 복잡도는 O(1)로 바뀌게 된다.

#### 데이터 수집 서비스

- 이제까진 사용자가 검색창에 타이핑을 할 때마다 실시간으로 데이터를 수정했다. 이 방법은 아래의 문제로 실용적이지 못하다.
  - 매일 수천만 건의 질의가 입력될 텐데 그때마다 트라이를 갱신하면 서비스가 느려진다.
  - 일단 트라이가 만들어지면 검색어가 자주 바뀌진 않을 것이다. 그러니 트라이를 자주 갱신할 필요가 없다.
- 아래는 데이터 분석 서비스의 수정된 설계안이다.

  <img src="https://github.com/programmer-sjk/TIL/blob/main/images/books/architecture/trie-collect.png" width="500">

- 데이터 분석 서비스 로그
  - 검색창에 입력된 질의에 관한 원본 데이터가 보관된다.
- 로그 취합 서버
  - 데이터 분석 서비스에서 나오는 로그는 보통 그 양이 엄청많다. 이 데이터를 잘 취합하여 우리 시스템이 소비할 수 있도록 해야 한다.
  - 트위터와 같은 실시간 어플리케이션은 데이터 취합 주기를 보다 짧게 가져갈 필요가 있다. 대부분의 경우에는 일주일에 한 번 로그를 취합해도 충분할 것이다.
- 취합된 데이터
  - 매주 취합한 데이터이다. 어떤 질의가 얼마나 조회되었는지를 나타낸다.
- 작업 서버
  - 작업 서버는 주기적, 비동기적으로 트라이 자료구조를 만들고 트라이 DB에 저장하는 역할을 담당한다.
- 트라이 캐시
  - 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높인다. 매 주 트라이 DB의 스냅샷을 떠서 갱신한다.
- 트라이 DB
  - 트라이 DB는 지속성 저장소다. 트라이 데이터베이스로 사용할 수 있는 선택지는 문서 저장소나 키 값 저장소가 있다.

#### 질의 서비스

- 질의 서비스에 대한 요청의 흐름은 다음과 같다.
  - 검색 질의가 로드 밸런서로 전송된다.
  - 로드 밸런서는 해당 요청을 API 서버로 보낸다.
  - API 서버는 트라이 캐시에서 데이터를 가져와 자도완선 검색어를 응답한다.
  - 데이터가 트라이 캐시에 없는 겨우 데이터를 DB에서 가져와 캐시에 채운다.
- 질의 서비스는 번개처럼 빨라야 한다. 이를 위해 다음과 같은 최적화 방법을 고민해보자.
  - ajax 요청: 요처을 받고 페이지를 새로고침 할 필요가 없다는 장점이 있다.
  - 브라우저 캐싱: 제안된 검색어들을 브라우저 캐시에 넣어두면 후속 질의는 해당 캐시에서 바로 가져갈 수 있다. 구글 검색 엔진이 이런 기술을 사용한다.

#### 트라이 연산

- 트라이 생성은 작업 서버가 담당하며 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용한다.
- 트라이를 갱신하는데 두 가지 방법이 있다.
  - 매주 한 번 갱신하는 방법. 새로운 트라이를 만들고 기존 트라이를 대체한다.
  - 트라이의 각 노드를 개별적으로 갱신하는 방법. 본 설계에서는 성능이 좋지 않아 채택하지 않았다. 하지만 트라이가 작을 때는 고려해볼만한 방법이다.
- 혐오성이 짙거나 성적으로 노골적인 단어들은 자동완성 결과에서 제거해야 한다. 좋은 방법은 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어가 반환되지 않도록 하는 것이다.
