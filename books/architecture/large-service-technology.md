# 대규모 서비스를 지탱하는 기술

- [책 링크](https://product.kyobobook.co.kr/detail/S000001550638)

## 1. 대규모 웹 서비스 개발 오리엔테이션

### 대규모 서비스와 소규모 서비스

#### 소규모 서비스와 대규모 서비스의 차이

- 서버 몇 대 있는 소규모 서비스에는 없는, **`대규모 서비스에만 있는 문제나 어려움에는`** 어떤 점들이 있을까?
  - **확장성 확보, 부하 분산 필요**
    - 서버 1대일때는 필요 없던 로드 밸런서 도입이 필요
    - DB의 데이터 동기화는 어떻게 할 것인가?
  - **다중성 확보**
    - 서버가 고장나거나 성능이 저하되더라도 서비스를 계속할 수 있는 구성이 필요하다.
  - **효율적 운용**
    - 서버가 1대라면 정상 동작하는지 간단히 파악이 가능하다.
    - 서버 대수가 100대를 넘어서면 각 서버가 어떤 역할을 하는지 파악하는 것도 고생거리다.
    - 감시용 SW를 사용하고 정보관리를 위해 자동화를 하게 된다.
  - **개발자 수, 개발 방법**
    - 개발 표준화를 어떻게 할 것인가? 언어를 통일하고 코딩 규약을 표준화, 코드 버전관리 등 팀 매니저먼트가 필요해진다.

#### 대규모 데이터량에 대한 대처

- 컴퓨터에서 데이터는 `**디스크 -> 메모리 -> 캐시 메모리 -> CPU**` 와 같이 몇 단계를 경유해서 처리된다.
- 데이터량이 많아지면 처음부터 캐시 미스가 발생하게 되고 저속의 디스크 I/O가 많이 발생하게 된다.
- 데이터가 많아지면 문제가 복잡해 진다. 어떻게 데이터를 적게 가져갈까, 여러 서버로 분산시킬 수 있을까, 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을까 등이 본질적인 과제가 된다.

### 계속 성장하는 서비스와 대규모화의 벽

- 책의 저자가 일한 하테나라는 기업은 처음에 **펜티엄 PC 1대**로 시작했다.
- 사용자가 늘어나면서 **`다중화와 부하분산을`** 적용해 나갔다. 라우터, 아파치의 부하분산, MySQL 레플리케이션 기능을 사용
- 블로그 붐이 발생하면서 시스템이 다운되는 상황이 빈번히 발생
  - 서버 룸에서 인터넷 데이터 센터로 서버 이전
  - 로드밸런서 + 감시 프로그램 도입
  - 병목 지점과 각종 로직이나 DB 스키마를 재검토해서 비효율적인 부문을 서서히 배제
- 그러나 시스템이 안정되었다고 끝내면 결국 그 이후의 성장을 위해서는 동일한 작업이 반복된다.
- 그러지 않기 위해 현재도 개발/인프라 팀이 시스템 품질 개선을 수행

## 2. 대규모 데이터 처리 입문

### 하테나 북마크의 데이터 규모

- 하테나 북마크의 테이블 **건수는 3억 5천만** 건으로 아래와 같이 데이터를 1건 검색하자
  - `SELECT url FROM entry where eid = 15728423`
- 인덱스를 태우지 않고 **1건을 검색하는데 200초가 넘어도** 결과가 나오지 않는다.
  - 알겠는가? 200초다 200초. 뭔가 조치를 취해야 한다.

### 대규모 데이터 처리의 어려운 점

#### 메모리 내에서 계산할 수 없다

- 메모리 내에서 계산할 수 없으면 디스크에 있는 데이터를 검색하게 된다.
- 하지만 디스크는 느리므로 I/O 시간이 걸린다.

#### 메모리와 디스크 속도차

- 메모리에서 데이터를 찾는 탐색과 디스크의 원반 내에 있는 데이터를 찾는 것은 얼마의 속도차이가 날까?
  - **10만~100만 배.** 이런 수치 감각은 꽤 중요하다.

#### 디스크는 왜 늦을까?

- 메모리는 전기적인 부품이므로 조금 떨어진 데이터를 탐색할 때 마이크로초 단위로 포인터를 이동시킬 수 있다.
- 디스크는 원반이 회전하고 여기서 데이터를 읽어낸다. 즉 메모리와 달리 회전등의 **물리적인 동작을 수반하고 있다.**
- 이 물리적인 구조가 탐색 속도에 영향을 준다. 따라서 데이터가 메모리에 있다면 물리적인 동작이 없으므로 훨씬 빠르다.
- **메모리와 CPU는 빠른 버스로 연결**되어 있어 7.5GB/s 성능이 나오지만 디스크는 58MB/s 로 전송 속도에서 차이가 난다.
- **SSD**는 물리적인 회전이 아니라 탐색은 빠르지만 **`버스 속도가 병목이 되거나 그 밖에 구조로 인해`** 메모리만큼 속도는 나오지 않는다.

### 규모 조정의 요소

#### CPU 부하와 I/O 부하

- 스케일 아웃은 하드웨어를 나열해서 성능을 높여 확장성을 확보하게 된다. 이를 통해 CPU 부하의 확장성을 확보하긴 쉽다.

#### 웹 어플리케이션과 부하의 관계

- 앞 단의 프록시 서버나 로드 밸런서가 요청을 뒷 단에 서버로 전달하고, 서버는 DB에 쿼리를 요청한다.
- 이 과정에서 뒷 단에 서버는 스케일 아웃을 통해 분산을 할 수 있다.

#### DB 확장성 확보의 어려움

- DB는 데이터가 커질수록 메모리에서 처리 못하고 디스크상에서 처리할 수 밖에 없는 요건이 늘어난다.
- 즉 대규모 환경에서는 I/O 부하를 부담하는 DB 서버는 애초에 분산시키기 어렵고 디스크 I/O가 많이 발생하면 금방 느려진다.

### 대규모 데이터를 다루기 위한 기초지식

#### 대규모 데이터를 다루는 세 가지 요령

- 첫 번째 요령은 어떻게 하면 **`메모리에서 처리를 마칠 수 있을까?`** 라는 점이다.
  - 디스크 탐색은 확장성, 성능에 크게 영향을 주기 때문이다.
- 두 번째 요령은 데이터량 증가에 강한 알고리즘을 사용하는 것이다.
  - 레코드가 1000만건 있을 때 선형 탐색은 1000만번 수행해야 하지만 Log Order 알고리즘은 수십 번 만에 끝낼 수 있다.
- 데이터 압축이나 검색 기술과 같은 테크닉을 활용할 수 있다.

#### 대규모 데이터를 다루기 전 3대 전제지식

- 프로그램을 만드는 입장에서 **`알고리즘, 압축, 검색`** 등이 중요하다.
- 또한 프로그램 개발에 근간이 되는 기초 세 가지를 들겠다.
  - OS 캐시
  - 분산을 고려한 RDBMS 운영
  - 대규모 환경에서 알고리즘과 데이터 구조

## 3. OS 캐시와 분산

### OS의 캐시 구조

#### OS 캐시 구조를 알고 어플리케이션 작성하기

- OS에는 디스크 내의 데이터에 빠르게 엑세스할 수 있는 구조를 가지는데 이게 바로 OS 캐시다. 여기서는 페이지 캐시라고 부른다.
- 그렇다면 페이지라는 것은 무엇일까. 가상 메모리에 관해 알고 있는가?

#### 가상 메모리 구조

- 가상 메모리 구조가 존재하는 가장 큰 이유는 물리적인 하드웨어를 OS에서 추상화하기 위해서이다.
- 프로세스에서 메모리가 필요하면 OS에게 요청하며 OS는 비어있는 메모리를 찾아 반환한다.
- 이때 4KB 정도를 블록으로 확보해 프로세스에게 넘긴다. 여기서 1개의 블록을 페이지라고 부른다.
- OS는 프로세스에서 메모리 요청을 받으면 페이지를 1개 이상, 필요한 만큼 확보해서 프로세스에게 반환한다.

#### Linux 페이지 캐시 원리

- OS는 페이지를 메모리 상에 계속 확보하는 기능을 갖고 있다.
- OS는 디스크로부터 4KB 크기의 블록을 읽어 한 번은 메모리에 위치시켜야 한다. 프로세스는 디스크에 직접 엑세스 할 수 없기 때문이다.
- 프로세스가 엑세스 할 수 있는 것은 메모리다. 따라서 OS는 읽은 블록을 메모리에 쓴다. 그리고 OS는 그 메모리 주소를 프로세스에게 알려준다.
- 이 때 메모리에 할당한 페이지를 남겨두어 동일한 데이터가 필요할 경우 재사용할 수 있는데 이것이 페이지 캐시다.
- 즉 커널이 한 번 할당한 메모리를 해제하지 않고 남겨두는 것이 페이지 캐시의 기본이다.
- 현대의 OS는 윈도우와 리눅스 모두 페이지 캐시와 비슷한 구조를 가지고 있다.

#### Linux는 페이지 단위로 디스크를 캐싱한다

- 디스크에 4GB의 매우 큰 파일이 있고 메모리가 2GB가 있다고 가정하자. 2GB 중 500MB를 OS가 프로세스에 할당했다.
- 그러면 이제 1.5GB 여유가 있는데 4GB 파일을 캐싱할 수 있을까?
  - OS는 읽어낸 4KB 블록만을 캐싱하므로 특정 파일의 일부분만, 읽어낸 부분만을 캐싱할 수 있다.
  - 이렇게 디스크를 캐싱하는 단위가 페이지다.
- 메모리 여유분이 1.5GB 있고 파일을 4GB 전부 읽게 되면 어떻게 될까?
  - 구조상 LRU로 최근에 읽은 부분이 캐시에 남거 오래된 부분은 파기되어 간다.
  - DB도 계속 구동시키면 캐시가 점점 최적화되어 기동시킨 직후보다 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

#### 메모리를 늘려서 I/O 부하 줄이기

- 지금까지 설명으로 메모리를 늘리면 실제 I/O 부하를 줄일 수 있음을 알 수 있다.
- 메모리를 늘리면 캐시에 사용할 수 있는 용량이 늘어나고, 더 많은 데이터를 캐싱할 수 있고, 디스크를 읽는 횟수가 줄어든다.
- 데이터가 많아졌을 때 메모리를 늘려서 I/O 부하를 줄이자는 것이 기본 방침이다.
- 그렇다고 실무에서 발생하는 부하들이 메모리만 늘리는 걸로 해결될 수도 있지만 아닌 경우도 있을 것이다.

### I/O 부하를 줄이는 방법

#### 캐시를 전제로 한 I/O 줄이는 방법

- 캐시에 의한 I/O 경감 효과는 매우 크다. 캐시는 I/O 대책의 기본이며 메모리가 클수록 전부 캐싱할 수 있으므로 데이터 크기에 주목하자
- 대규모 데이터 처리에서 압축이 중요하다고 했는데, 압축해두면 디스크 내용을 전부 캐싱해 둘 수 있는 경우가 많다.
  - 텍스트 파일의 용량을 절반으로 압축할 수 있다면 4GB 텍스트 파일을 2GB 메모리로 대부분 캐싱할 수 있다.

#### 복수 서버로 확장하기

- 메모리를 늘려서 전부 캐싱할 수 있다면 좋겠지만 데이터를 전부 캐싱할 수 없는 규모가 될 수 있다.
- CPU 부하 분산에는 서버를 늘리면 되지만 DB 서버는 늘릴수록 좋다 라는 논리가 들어맞지 않는다.

#### 단순히 대수만 늘려서는 확장성을 확보할 수 없다

- 캐시 용량을 늘려야 한다고 했는데 단순히 대수만 늘리는 것으로는 안된다.
- 데이터를 복사해서 대수를 늘리게 되면 애초에 캐시 용량이 부족해서 늘렸는데 복사된 대수도 동일하게 용량이 부족하다.

### 국소성을 살리는 분산

#### 국소성을 고려한 분산이란?

- 국소성은 locality 라고도 하는데 데이터에 대한 엑세스 패턴을 고려해서 분산시키는 것을 의미한다.

#### 파티셔닝

- 국소성을 고려한 분산을 위해 파티셔닝이라는 방법을 자주 사용한다. 파티셔닝은 DB 한 대를 여러 서버로 분할하는 방법을 말한다.
- 간단한 방법으로 테이블 단위 분할이 있다. 테이블을 분할해서 각기 다른 서버에서 관리한다.
  - A, B 테이블은 같이 엑세스 하는 경우가 많아 같은 서버에 위치시킨다.
  - 테이블 단위로 분할하면 특정 테이블 요청은 특정 서버로 보내도록 어플리케이션을 변경해야 한다.
- 다른 방법으로 테이블의 데이터 분할이 있다.
  - 예를 들어 ID가 a~f는 1번 서버로, g~o는 2번 서버로 보내는 개념이다.

#### 페이지 캐시를 고려한 운용 규칙

- OS 기동 직후에 서버를 투입하지 말자. 기동 직후 디스크 액세스만 발생하게 되므로 대규모 정보를 다루는 서버는 실제로 내려가게 된다. OS를 기동하면 자주 사용하는 DB 파일을 한 번 조회해준다. 그 후 로드밸런서에 편입한다.

## 4. 분산을 고려한 MySQL 운용

### 인덱스를 올바로 운용하기

- 인덱스를 적절하게 설정하는 것은 매우 중요하다.

#### OS 캐시 활용

- 전체 데이터 크기에 주의해서 데이터량이 물리 메모리보다 가능한 작도록 유지한다.
- 서비스를 설계하는 초기 단계에선 깊게 생각할 필요는 없지만, 규모가 큰 서비스가 되면 컬럼 변경, 스키마 변경에도 주의를 기울여야 한다.
- 대량의 데이터를 저장하는 테이블은 레코드가 가능한 작아지도록 컴팩트하게 설계하자.
  - 정수형은 4 바이트, 문자열은 1바이트와 같은 수치를 잘 기억하자.

#### 인덱스의 중요성

- MySQL의 인덱스는 기본적으로 B+ 트리의 데이터 구조다.
- 또한 데이터의 삽입이나 삭제에 따라 트리에 치우침이 생기지 않는 평형(Balanced) 트리다.
- B 트리에 데이터를 삽입할 때는 일정한 규칙에 따라 삽입하는데 이로 인해 검색할 때 일부 노드를 순회하는 것만으로 데이터를 빠르게 찾을 수 있다.
- Binary Tree와 BTree 차이
  - 이분 트리는 반드시 자식이 2개. BTree는 자식이 여러개 있으며 자식 개수를 조절하여 크기를 4KB 등으로 할 수 있다.
  - BTree의 경우 각 노드를 1 블록에 모아 저장할 수 있어서 디스크 seek 발생 횟수를 최소화할 수 있다.
- B+ 트리는 각 노드가 자식 노드의 주소만 가지고 있, 실제 값은 제일 마지막인 leaf node만 가진다.
- B+ 트리가 DB에 데이터를 저장하는데 좀 더 최적화된 구조라는 점을 기억해두자.

#### MySQL에서 인덱스 만들기

- B+ 트리는 이론적으로 탐색 계산량이 O(log n) 으로 선형탐색인 O(n) 보다 훨씬 빠르다.
- 이게 바로 인덱스로 탐색하면 빨라지는 원리이다.

#### 인덱스 효과

- 4000 만건의 데이터가 있을 때 인덱스가 없는 선형 탐색의 경우 4000 만번 탐색한다.
- 반대로 인덱스가 있다면 25.25번만 탐색하면 된다.
- 3억건의 데이터에 인덱스 없이 데이터 1개를 찾는 쿼리를 수행하면 200초가 걸려도 결과가 나오지 않지만 인덱스가 걸려있을 경우 0.00초로 순식간에 반환하게 된다.
- 대규모가 될 수록 인덱스에 따라 성능의 차이가 매우 크다.

### MySQL의 분산

#### MySQL 레플리케이션

- MySQL 기본 기능으로 레플리케이션 기능이 있다. 마스터를 정하고 슬레이브가 폴링해서 동일한 내용으로 자신을 갱신하는 기능이다. 이 때 데이터의 갱신은 무조건 마스터가 담당해야 한다.

#### 마스터/슬레이브 특징

- 조회 쿼리는 슬레이브로 분산하면 되지만 명령 쿼리는 어떻게 분산할까?
- 마스터를 분산하면 상당히 험난해진다. 다행히 웹 어플리케이션은 90%가 조회 쿼리다.
- 명령/쓰기를 확장하고자 할 때
  - 테이블을 분할해서 테이블 크기를 작게 해준다. 그러면 분할로 인해 쓰기 작업이 분산된다.
  - 처음부터 RDBMS를 사용하지 않는 방법도 생각할 수 있다.
    - 실제로 동영상을 재생할 때 마다 갱신이 일어나는 경우 RDB로 감당할 수 없어서 key-value 스토어를 사용한다.
    - 단순히 값을 저장하고 꺼낸다면 key-value 스토어는 오버헤드도 적고 압도적으로 빠르다.

### MySQL의 스케일아웃과 파티셔닝

#### MySQL의 스케일 아웃 전략

- MySQL의 기본 전략은 데이터가 메모리보다 크면 메모리를 증설하고 인덱스는 제대로 걸자였다.
- 메모리 증설이 불가하면 파티셔닝을 활용할 수 있는데 파티셔닝에 대해 보충설명을 하도록 하겠다.

#### 파티셔닝에 관한 보충

- 파티셔닝이란 테이블 A와 테이블 B를 서로 다른 서버에 놓아서 분산하는 방법이다.
- 파티셔닝은 국소성을 활용해서 분산할 수 있으므로 캐시가 유효하고 파티셔닝이 효과적이다.

#### 파티셔닝을 전제로 한 설계

- MySQL에는 서로 다른 서버에 있는 테이블을 JOIN 하는 기능이 없다.
- 따라서 JOIN 쿼리의 대상이 되는 테이블은 다른 서버로 분할하지 않을 것이라고 보장할 수 있을때 사용한다.
- 긴밀하게 결합하고 있는 테이블들은 다른 서버로 나누면 안 된다.
- 다만 밀접하게 결합하지 않고, 데이터 크기를 볼 때 반드시 분할해야 하는 테이블은 JOIN 하지 않는 방침을 취해야 한다. 어플리케이션 개발자가 이 점을 잊고 JOIN 쿼리를 던지면 문제가 된다.

#### JOIN 배제

- INNER JOIN 하는 쿼리는 A 테이블에서 개별 조회하고 B 테이블에 id를 in 절로 넣어서 뽑아내면 동일한 데이터를 얻게 된다.

#### 파티셔닝의 상반관계

- 파티셔닝은 부하가 내려가고 국소성이 늘어나서 캐시 효과가 높아지는 장점이 있지만 반대로 단점도 있다.
- 운용이 복잡해진다
  - 파티셔닝은 기본적으로 서버가 나눠지는 것이다.
  - DB를 많이 분할해서 사용중이라면, 장애가 발생했을 때 파악 및 복구에 시간이 더 걸린다.
- 고장률이 높아진다
  - 대수가 늘어나는 만큼 고장확률이 높아지는 문제도 있다.
- 서버 대수
  - 파티셔닝으로 분할한 테이블이 여러 서버에 있고 여기에 master/slave 구조로 여럿 두면 대수가 한 꺼번에 늘어나게 된다.

#### 정리 포인트

- 파티셔닝을 적용하는게 오히려 더 복잡해질 것 같으니 책이 집필된 2011년 저자의 경험을 듣는 것으로 정리

## 5. 대규모 데이터 처리 실전 입문

### 용도 특화형 인덱싱

- RDBMS는 데이터 정렬, 통계처리, JOIN 등 범용적이고 다양한 목적에 사용할 수 있도록 만들어져 있다.
- 뭔가 특정한 목적으로 사용하고자 할 때에는 특정한 목적으로 사용할 수 있는 데이터 구조를 사용하면 매우 빠르다.
- 검색에서 역 인덱스가 전형적인 예로, 미리 인덱스를 만들어두면 RDBMS로 데이터를 순회하지 않아도 순식간에 검색이 가능하다.

### 이론과 실전 양쪽과의 싸움

- 대규모 웹 어플리케이션을 개발, 운영하려면 이론과 실전 모두를 하지 않으면 안 된다.
- 저자가 일한 하테나는 처음엔 실전이 강한 회사였다. 그러나 서비스가 히트를 해서 문제점 하나하나가 커져감에 따라 잔재주 수준의 테크닉으로는 해결할 수 없게 되었다. 이 시점에서 필요한 것은 새로운 노하우가 아닌 본질적인 이론이었다.

## 7. 알고리즘 실용화

- 대규모 데이터를 처리할 때 문제해결에 적합한 알고리즘과 데이터 구조를 사용해 하루 종일 걸리던 계산이 수 초만에 완료되는 경우도 있다.

### 알고리즘과 평가

#### 데이터 규모와 계산량 차이

- 데이터가 크면 클수록 알고리즘이나 데이터 구조 선택이 속도에 영향을 미친다.
  - 데이터가 100만번 일 때 선형탐색은 100만번 걸리는 반면, 이분탐색은 20번 만에 끝난다.

#### 알고리즘이란?

- 알고리즘은 값을 입력하면 정의된 계산절차에 따라 값이 출력으로 반환되는 것을 의미한다.
- 알고리즘을 배우는 의의
  - CPU나 메모리 등 컴퓨터의 자원은 유한하므로 알고리즘을 배우는 것은 중요하다.
  - 알고리즘을 배우는 또 다른 이점은, 배워두면 새로운 문제에도 대처할 수 있다는 점이다.
- 알고리즘 평가
  - 주로 빅오 표기법을 많이 사용한다.
  - 데이터 n의 크기에 상관없이 일정한 시간에 처리가 끝날 경우 O(1) 이라고 쓴다.
    - 해시 탐색은 key를 알면 값이 거의 고유하게 결정되므로 키로 값을 탐색하는 처리는 O(1)이다.
  - 여러 알고리즘의 빅오 계산량은 아래와 같이 오른쪽으로 갈 수록 계산량이 많아진다.
    - `O(1) < O(log n) < O(n) < O(n long n) < O(n^2) < O(n^3)`

#### 알고리즘과 데이터 구조

- 알고리즘의 로직에 맞춰 적절한 데이터 구조를 선택할 필요가 있다.
  - 예를 들어 적절한 트리구조로 데이터를 저장하면, 탐색처리를 단순화 할 수 있어 계산량을 줄일 수 있다.
  - RDBMS는 인덱스로 B+ 트리구조를 사용하기 때문에 데이터 구조에 알맞는 알고리즘으로 검색, 삽입, 정렬을 수행한다.

### 하테나 다이어리의 키워드 링크

- 하테나 다이어리에는 키워드 링크라는 기능이 있었다.
  - 사용자가 블로그에 글을 작성하면 일부 키워드에 링크가 자동으로 걸린다.
- 최초 구현 방법은 정규식을 활용했는데 키워드 링크에 등록된 키워드가 10만건을 넘어가면서 시스템이 비명을 지르게 된다.
- 해결방법?
  - 정규표현 방식에서 Trie(트라이)를 사용한 매칭 구현으로 변경
    - Trie는 문자열 집합을 트리구조로 해서 효율적으로 저장한다.
    - 탐색대상 데이터의 공통 접두사를 모아놓은 트리구조가 된다.
  - AC법으로 Trie 매칭을 더욱 빠르게 개선
- 하테나 다이어리의 키워드 링크를 개선하면서 알게 된점
  - 처음부터 최적의 구현을 사용하는게 반드시 옳은 것은 아니다.
  - 데이터가 대규모가 될 시기를 대비해서 본질적인 문제의 해결방법을 머릿속에 넣어두어야 한다.

## 9. 전문 검색기술 도전

### 전문 검색기술의 응용범위

- 하테나에는 블로그 내용을 전문 검색해서 키워드로 블로그를 검색할 수 있는 기능을 제공하고 있다.
- 처음에는 RDB를 이용해 새로운 글을 작성하면 글에 포함된 키워드를 전부 추출해 DB 레코드에 저장해두었다.
  - 하지만 레코드 수가 너무 많아서 무거워지며 확장성 측면에서 파탄을 가져왔다.
- 검색엔진을 만들어 문제를 회피했다.
