# 대규모 서비스를 지탱하는 기술

- [책 링크](https://product.kyobobook.co.kr/detail/S000001550638)

## 1. 대규모 웹 서비스 개발 오리엔테이션

### 대규모 서비스와 소규모 서비스

#### 소규모 서비스와 대규모 서비스의 차이

- 서버 몇 대 있는 소규모 서비스에는 없는, **`대규모 서비스에만 있는 문제나 어려움에는`** 어떤 점들이 있을까?
  - **`확장성 확보, 부하 분산 필요`**
    - 서버 1대일때는 필요 없던 로드 밸런서 도입이 필요
    - DB의 데이터 동기화는 어떻게 할 것인가?
  - **`다중성 확보`**
    - 서버가 고장나거나 성능이 저하되더라도 서비스를 계속할 수 있는 구성이 필요하다.
  - **`효율적 운용`**
    - 서버가 1대라면 정상 동작하는지 간단히 파악이 가능하다.
    - 서버 대수가 100대를 넘어서면 각 서버가 어떤 역할을 하는지 파악하는 것도 고생거리다.
    - 감시용 SW를 사용하고 정보관리를 위해 자동화를 하게 된다.
  - **`개발자 수, 개발 방법`**
    - 개발 표준화를 어떻게 할 것인가? 언어를 통일하고 코딩 규약을 표준화, 코드 버전관리 등 팀 매니저먼트가 필요해진다.

#### 대규모 데이터량에 대한 대처

- 컴퓨터에서 데이터는 **`디스크 -> 메모리 -> 캐시 메모리 -> CPU`** 와 같이 몇 단계를 경유해서 처리된다.
- 데이터량이 많아지면 처음부터 캐시 미스가 발생하게 되고 저속의 디스크 I/O가 많이 발생하게 된다.
- 데이터가 많아지면 문제가 복잡해 진다. 어떻게 데이터를 적게 가져갈까, 여러 서버로 분산시킬 수 있을까, 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을까 등이 본질적인 과제가 된다.

### 계속 성장하는 서비스와 대규모화의 벽

- 책의 저자가 일한 하테나라는 기업은 처음에 **`펜티엄 PC 1대`**로 시작했다.
- 사용자가 늘어나면서 **`다중화와 부하분산을`** 적용해 나갔다. 라우터, 아파치의 부하분산, MySQL 레플리케이션 기능을 사용
- 블로그 붐이 발생하면서 시스템이 다운되는 상황이 빈번히 발생
  - 서버 룸에서 인터넷 데이터 센터로 서버 이전
  - 로드밸런서 + 감시 프로그램 도입
  - 병목 지점과 각종 로직이나 DB 스키마를 재검토해서 비효율적인 부문을 서서히 배제
- 그러나 시스템이 안정되었다고 끝내면 결국 그 이후의 성장을 위해서는 동일한 작업이 반복된다.
- 그러지 않기 위해 현재도 개발/인프라 팀이 시스템 품질 개선을 수행

## 2. 대규모 데이터 처리 입문

### 하테나 북마크의 데이터 규모

- 하테나 북마크의 테이블 **건수는 3억 5천만** 건으로 아래와 같이 데이터를 1건 검색하자
  - `SELECT url FROM entry where eid = 15728423`
- 인덱스를 태우지 않고 **1건을 검색하는데 200초가 넘어도** 결과가 나오지 않는다.
  - 알겠는가? 200초다 200초. 뭔가 조치를 취해야 한다.

### 대규모 데이터 처리의 어려운 점

#### 메모리 내에서 계산할 수 없다

- 메모리 내에서 계산할 수 없으면 디스크에 있는 데이터를 검색하게 된다.
- 하지만 디스크는 느리므로 I/O 시간이 걸린다.

#### 메모리와 디스크 속도차

- 메모리에서 데이터를 찾는 탐색과 디스크의 원반 내에 있는 데이터를 찾는 것은 얼마의 속도차이가 날까?
  - **`10만~100만 배.`** 이런 수치 감각은 꽤 중요하다.

#### 디스크는 왜 늦을까?

- 메모리는 전기적인 부품이므로 조금 떨어진 데이터를 탐색할 때 마이크로초 단위로 포인터를 이동시킬 수 있다.
- 디스크는 원반이 회전하고 여기서 데이터를 읽어낸다. 즉 메모리와 달리 회전등의 **`물리적인 동작을 수반하고 있다.`**
- 이 물리적인 구조가 탐색 속도에 영향을 준다. 따라서 데이터가 메모리에 있다면 물리적인 동작이 없으므로 훨씬 빠르다.
- **메모리와 CPU는 빠른 버스로 연결**되어 있어 7.5GB/s 성능이 나오지만 디스크는 58MB/s 로 전송 속도에서 차이가 난다.
- **SSD**는 물리적인 회전이 아니라 탐색은 빠르지만 **`버스 속도가 병목이 되거나 그 밖에 구조로 인해`** 메모리만큼 속도는 나오지 않는다.

### 규모 조정의 요소

#### CPU 부하와 I/O 부하

- 스케일 아웃은 하드웨어를 나열해서 성능을 높여 확장성을 확보하게 된다. 이를 통해 CPU 부하의 확장성을 확보하긴 쉽다.

#### 웹 어플리케이션과 부하의 관계

- 앞 단의 프록시 서버나 로드 밸런서가 요청을 뒷 단에 서버로 전달하고, 서버는 DB에 쿼리를 요청한다.
- 이 과정에서 뒷 단에 서버는 스케일 아웃을 통해 분산을 할 수 있다.

#### DB 확장성 확보의 어려움

- DB는 데이터가 커질수록 메모리에서 처리 못하고 디스크상에서 처리할 수 밖에 없는 요건이 늘어난다.
- 즉 대규모 환경에서는 I/O 부하를 부담하는 DB 서버는 애초에 분산시키기 어렵고 디스크 I/O가 많이 발생하면 금방 느려진다.

### 대규모 데이터를 다루기 위한 기초지식

#### 대규모 데이터를 다루는 세 가지 요령

- 첫 번째 요령은 어떻게 하면 **`메모리에서 처리를 마칠 수 있을까?`** 라는 점이다.
  - 디스크 탐색은 확장성, 성능에 크게 영향을 주기 때문이다.
- 두 번째 요령은 데이터량 증가에 강한 알고리즘을 사용하는 것이다.
  - 레코드가 1000만건 있을 때 선형 탐색은 1000만번 수행해야 하지만 Log Order 알고리즘은 수십 번 만에 끝낼 수 있다.
- 데이터 압축이나 검색 기술과 같은 테크닉을 활용할 수 있다.

#### 대규모 데이터를 다루기 전 3대 전제지식

- 프로그램을 만드는 입장에서 **`알고리즘, 압축, 검색`** 등이 중요하다.
- 또한 프로그램 개발에 근간이 되는 기초 세 가지를 들겠다.
  - OS 캐시
  - 분산을 고려한 RDBMS 운영
  - 대규모 환경에서 알고리즘과 데이터 구조

## 3. OS 캐시와 분산

### OS의 캐시 구조

#### OS 캐시 구조를 알고 어플리케이션 작성하기

- OS에는 디스크 내의 데이터에 빠르게 엑세스할 수 있는 구조를 가지는데 이게 바로 OS 캐시다. 여기서는 **`페이지 캐시`**라고 부른다.
- 그렇다면 페이지라는 것은 무엇일까. 가상 메모리에 관해 알고 있는가?

#### 가상 메모리 구조

- **`가상 메모리 구조가 존재하는 가장 큰 이유는`** 물리적인 하드웨어를 OS에서 추상화하기 위해서이다.
- 프로세스에서 메모리가 필요하면 OS에게 요청하며 OS는 비어있는 메모리를 찾아 반환한다.
- 이때 4KB 정도를 블록으로 확보해 프로세스에게 넘긴다. 여기서 **`1개의 블록을 페이지`**라고 부른다.
- OS는 프로세스에서 메모리 요청을 받으면 페이지를 1개 이상, 필요한 만큼 확보해서 프로세스에게 반환한다.

#### Linux 페이지 캐시 원리

- OS는 페이지를 메모리 상에 계속 확보하는 기능을 갖고 있다.
- OS는 디스크로부터 4KB 크기의 블록을 읽어 한 번은 메모리에 위치시켜야 한다. **`프로세스는 디스크에 직접 엑세스 할 수 없기 때문이다.`**
- **`프로세스가 엑세스 할 수 있는 것은 메모리다.`** 따라서 OS는 읽은 블록을 메모리에 쓴다. 그리고 OS는 그 메모리 주소를 프로세스에게 알려준다.
- 이 때 메모리에 할당한 페이지를 남겨두어 동일한 데이터가 필요할 경우 재사용할 수 있는데 이것이 **`페이지 캐시`**다.
- 즉 커널이 한 번 할당한 메모리를 해제하지 않고 남겨두는 것이 페이지 캐시의 기본이다.
- 현대의 OS는 윈도우와 리눅스 모두 페이지 캐시와 비슷한 구조를 가지고 있다.

#### Linux는 페이지 단위로 디스크를 캐싱한다

- 디스크에 4GB의 매우 큰 파일이 있고 메모리가 2GB가 있다고 가정하자. 2GB 중 500MB를 OS가 프로세스에 할당했다.
- 그러면 이제 1.5GB 여유가 있는데 4GB 파일을 캐싱할 수 있을까?
  - OS는 읽어낸 4KB 블록만을 캐싱하므로 특정 파일의 일부분만, 읽어낸 부분만을 캐싱할 수 있다.
  - 이렇게 디스크를 캐싱하는 단위가 페이지다.
- 메모리 여유분이 1.5GB 있고 파일을 4GB 전부 읽게 되면 어떻게 될까?
  - 구조상 LRU로 최근에 읽은 부분이 캐시에 남거 오래된 부분은 파기되어 간다.
  - DB도 계속 구동시키면 캐시가 점점 최적화되어 기동시킨 직후보다 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

#### 메모리를 늘려서 I/O 부하 줄이기

- 지금까지 설명으로 메모리를 늘리면 실제 I/O 부하를 줄일 수 있음을 알 수 있다.
- **`메모리를 늘리면 캐시에 사용할 수 있는 용량이 늘어나고`**, 더 많은 데이터를 캐싱할 수 있고, 디스크를 읽는 횟수가 줄어든다.
- 데이터가 많아졌을 때 메모리를 늘려서 I/O 부하를 줄이자는 것이 기본 방침이다.
- 그렇다고 실무에서 발생하는 부하들이 메모리만 늘리는 걸로 해결될 수도 있지만 아닌 경우도 있을 것이다.

### I/O 부하를 줄이는 방법

#### 캐시를 전제로 한 I/O 줄이는 방법

- 캐시에 의한 I/O 경감 효과는 매우 크다. 캐시는 I/O 대책의 기본이며 메모리가 클수록 전부 캐싱할 수 있으므로 데이터 크기에 주목하자
- 대규모 데이터 처리에서 압축이 중요하다고 했는데, 압축해두면 디스크 내용을 전부 캐싱해 둘 수 있는 경우가 많다.
  - 텍스트 파일의 용량을 절반으로 압축할 수 있다면 4GB 텍스트 파일을 2GB 메모리로 대부분 캐싱할 수 있다.

#### 복수 서버로 확장하기

- 메모리를 늘려서 전부 캐싱할 수 있다면 좋겠지만 데이터를 전부 캐싱할 수 없는 규모가 될 수 있다.
- CPU 부하 분산에는 서버를 늘리면 되지만 DB 서버는 늘릴수록 좋다 라는 논리가 들어맞지 않는다.

#### 단순히 대수만 늘려서는 확장성을 확보할 수 없다

- 캐시 용량을 늘려야 한다고 했는데 단순히 대수만 늘리는 것으로는 안된다.
- 데이터를 복사해서 대수를 늘리게 되면 애초에 캐시 용량이 부족해서 늘렸는데 복사된 대수도 동일하게 용량이 부족하다.

### 국소성을 살리는 분산

#### 국소성을 고려한 분산이란?

- 국소성은 locality 라고도 하는데 데이터에 대한 **`엑세스 패턴을 고려해서 분산`**시키는 것을 의미한다.

#### 파티셔닝

- 국소성을 고려한 분산을 위해 **`파티셔닝이라는 방법`**을 자주 사용한다. 파티셔닝은 **`DB 한 대를 여러 서버로 분할하는 방법`**을 말한다.
- 간단한 방법으로 테이블 단위 분할이 있다. 테이블을 분할해서 각기 다른 서버에서 관리한다.
  - A, B 테이블은 같이 엑세스 하는 경우가 많아 같은 서버에 위치시킨다.
  - 테이블 단위로 분할하면 특정 테이블 요청은 특정 서버로 보내도록 어플리케이션을 변경해야 한다.
- 다른 방법으로 테이블의 데이터 분할이 있다.
  - 예를 들어 ID가 a-f는 1번 서버로, g~o는 2번 서버로 보내는 개념이다.

#### 페이지 캐시를 고려한 운용 규칙

- OS 기동 직후에 서버를 투입하지 말자. 기동 직후 디스크 액세스만 발생하게 되므로 대규모 정보를 다루는 서버는 실제로 내려가게 된다. OS를 기동하면 자주 사용하는 DB 파일을 한 번 조회해준다. 그 후 로드밸런서에 편입한다.

## 4. 분산을 고려한 MySQL 운용

### 인덱스를 올바로 운용하기

- 인덱스를 적절하게 설정하는 것은 매우 중요하다.

#### OS 캐시 활용

- 전체 데이터 크기에 주의해서 데이터량이 물리 **`메모리보다 가능한 작도록 유지`**한다.
- 서비스를 설계하는 초기 단계에선 깊게 생각할 필요는 없지만, **`규모가 큰 서비스가 되면 컬럼 변경, 스키마 변경에도 주의`**를 기울여야 한다.
- 대량의 데이터를 저장하는 테이블은 레코드가 가능한 작아지도록 컴팩트하게 설계하자.
  - 정수형은 4 바이트, 문자열은 1바이트와 같은 수치를 잘 기억하자.

#### 인덱스의 중요성

- MySQL의 **`인덱스는 기본적으로 B+ 트리의`** 데이터 구조다.
- 또한 데이터의 삽입이나 삭제에 따라 트리에 치우침이 생기지 않는 **`평형(Balanced) 트리다.`**
- B 트리에 데이터를 삽입할 때는 일정한 규칙에 따라 삽입하는데 이로 인해 검색할 때 일부 노드를 순회하는 것만으로 데이터를 빠르게 찾을 수 있다.
- **`Binary Tree와 BTree 차이`**
  - 이분 트리는 반드시 자식이 2개. BTree는 자식이 여러개 있으며 자식 개수를 조절하여 크기를 4KB 등으로 할 수 있다.
  - BTree의 경우 각 노드를 1 블록에 모아 저장할 수 있어서 디스크 seek 발생 횟수를 최소화할 수 있다.
- B+ 트리는 각 노드가 자식 노드의 주소만 가지고 있고, 실제 값은 제일 마지막인 leaf node만 가진다.
- B+ 트리가 DB에 데이터를 저장하는데 **`좀 더 최적화된 구조`**라는 점을 기억해두자.

#### MySQL에서 인덱스 만들기

- B+ 트리는 이론적으로 탐색 계산량이 `O(log n)` 으로 선형탐색인 `O(n)` 보다 훨씬 빠르다.
- 이게 바로 인덱스로 탐색하면 빨라지는 원리이다.

#### 인덱스 효과

- 4000 만건의 데이터가 있을 때 인덱스가 없는 선형 탐색의 경우 4000 만번 탐색한다.
- 반대로 **`인덱스가 있다면 25.25번만 탐색`**하면 된다.
- 3억건의 데이터에 인덱스 없이 데이터 1개를 찾는 쿼리를 수행하면 200초가 걸려도 결과가 나오지 않지만 인덱스가 걸려있을 경우 0.00초로 순식간에 반환하게 된다.
- 대규모가 될 수록 인덱스에 따라 성능의 차이가 매우 크다.

### MySQL의 분산

#### MySQL 레플리케이션

- MySQL 기본 기능으로 레플리케이션 기능이 있다. 마스터를 정하고 슬레이브가 폴링해서 동일한 내용으로 자신을 갱신하는 기능이다. 이 때 데이터의 갱신은 무조건 마스터가 담당해야 한다.

#### 마스터/슬레이브 특징

- 조회 쿼리는 슬레이브로 분산하면 되지만 명령 쿼리는 어떻게 분산할까?
- **`마스터를 분산하면 상당히 험난해진다.`** 다행히 웹 어플리케이션은 90%가 조회 쿼리다.
- 명령/쓰기를 확장하고자 할 때
  - 테이블을 분할해서 테이블 크기를 작게 해준다. 그러면 분할로 인해 쓰기 작업이 분산된다.
  - 처음부터 RDBMS를 사용하지 않는 방법도 생각할 수 있다.
    - 실제로 동영상을 재생할 때 마다 갱신이 일어나는 경우 RDB로 감당할 수 없어서 key-value 스토어를 사용한다.
    - 단순히 값을 저장하고 꺼낸다면 key-value 스토어는 오버헤드도 적고 압도적으로 빠르다.

### MySQL의 스케일아웃과 파티셔닝

#### MySQL의 스케일 아웃 전략

- MySQL의 기본 전략은 데이터가 메모리보다 크면 메모리를 증설하고 인덱스는 제대로 걸자였다.
- 메모리 증설이 불가하면 파티셔닝을 활용할 수 있는데 파티셔닝에 대해 보충설명을 하도록 하겠다.

#### 파티셔닝에 관한 보충

- 파티셔닝이란 테이블 A와 테이블 B를 서로 다른 서버에 놓아서 분산하는 방법이다.
- 파티셔닝은 국소성을 활용해서 분산할 수 있으므로 캐시가 유효하고 파티셔닝이 효과적이다.

#### 파티셔닝을 전제로 한 설계

- MySQL에는 서로 다른 서버에 있는 테이블을 JOIN 하는 기능이 없다.
- 따라서 JOIN 쿼리의 대상이 되는 테이블은 다른 서버로 분할하지 않을 것이라고 보장할 수 있을때 사용한다.
- 긴밀하게 결합하고 있는 테이블들은 다른 서버로 나누면 안 된다.
- 다만 밀접하게 결합하지 않고, 데이터 크기를 볼 때 반드시 분할해야 하는 테이블은 JOIN 하지 않는 방침을 취해야 한다. 어플리케이션 개발자가 이 점을 잊고 JOIN 쿼리를 던지면 문제가 된다.

#### JOIN 배제

- INNER JOIN 하는 쿼리는 A 테이블에서 개별 조회하고 B 테이블에 id를 in 절로 넣어서 뽑아내면 동일한 데이터를 얻게 된다.

#### 파티셔닝의 상반관계

- 파티셔닝은 부하가 내려가고 국소성이 늘어나서 캐시 효과가 높아지는 장점이 있지만 반대로 단점도 있다.
- 운용이 복잡해진다
  - 파티셔닝은 기본적으로 서버가 나눠지는 것이다.
  - DB를 많이 분할해서 사용중이라면, 장애가 발생했을 때 파악 및 복구에 시간이 더 걸린다.
- 고장률이 높아진다
  - 대수가 늘어나는 만큼 고장확률이 높아지는 문제도 있다.
- 서버 대수
  - 파티셔닝으로 분할한 테이블이 여러 서버에 있고 여기에 master/slave 구조로 여럿 두면 대수가 한 꺼번에 늘어나게 된다.

#### 정리 포인트

- **`파티셔닝을 적용하는게 오히려 더 복잡해질 것 같으니`** 책이 집필된 2011년 저자의 경험을 듣는 것으로 정리

## 5. 대규모 데이터 처리 실전 입문

### 용도 특화형 인덱싱

- **RDBMS**는 데이터 정렬, 통계처리, JOIN 등 범용적이고 다양한 목적에 사용할 수 있도록 만들어져 있다.
- 뭔가 **`특정한 목적으로 사용하고자 할 때에는`** 특정한 목적으로 사용할 수 있는 데이터 구조를 사용하면 매우 빠르다.
- 검색에서 역 인덱스가 전형적인 예로, 미리 인덱스를 만들어두면 RDBMS로 데이터를 순회하지 않아도 순식간에 검색이 가능하다.

### 이론과 실전 양쪽과의 싸움

- 대규모 웹 어플리케이션을 개발, 운영하려면 **`이론과 실전 모두를 하지 않으면 안 된다.`**
- 저자가 일한 하테나는 처음엔 실전이 강한 회사였다. 그러나 서비스가 히트를 해서 문제점 하나하나가 커져감에 따라 잔재주 수준의 테크닉으로는 해결할 수 없게 되었다. 이 시점에서 필요한 것은 새로운 노하우가 아닌 본질적인 이론이었다.

## 7. 알고리즘 실용화

- 대규모 데이터를 처리할 때 **`문제해결에 적합한 알고리즘과 데이터 구조를 사용해`** 하루 종일 걸리던 계산이 수 초만에 완료되는 경우도 있다.

### 알고리즘과 평가

#### 데이터 규모와 계산량 차이

- 데이터가 크면 클수록 알고리즘이나 데이터 구조 선택이 속도에 영향을 미친다.
  - 데이터가 100만번 일 때 선형탐색은 100만번 걸리는 반면, 이분탐색은 20번 만에 끝난다.

#### 알고리즘이란?

- 알고리즘은 값을 입력하면 정의된 계산절차에 따라 값이 출력으로 반환되는 것을 의미한다.
- 알고리즘을 배우는 의의
  - CPU나 메모리 등 컴퓨터의 자원은 유한하므로 알고리즘을 배우는 것은 중요하다.
  - 알고리즘을 배우는 또 다른 이점은, 배워두면 새로운 문제에도 대처할 수 있다는 점이다.
- 알고리즘 평가
  - 주로 빅오 표기법을 많이 사용한다.
  - 데이터 n의 크기에 상관없이 일정한 시간에 처리가 끝날 경우 O(1) 이라고 쓴다.
    - 해시 탐색은 key를 알면 값이 거의 고유하게 결정되므로 키로 값을 탐색하는 처리는 O(1)이다.
  - 여러 알고리즘의 빅오 계산량은 아래와 같이 오른쪽으로 갈 수록 계산량이 많아진다.
    - `O(1) < O(log n) < O(n) < O(n long n) < O(n^2) < O(n^3)`

#### 알고리즘과 데이터 구조

- 알고리즘의 로직에 맞춰 적절한 데이터 구조를 선택할 필요가 있다.
  - 예를 들어 적절한 트리구조로 데이터를 저장하면, 탐색처리를 단순화 할 수 있어 계산량을 줄일 수 있다.
  - RDBMS는 인덱스로 B+ 트리구조를 사용하기 때문에 데이터 구조에 알맞는 알고리즘으로 검색, 삽입, 정렬을 수행한다.

### 하테나 다이어리의 키워드 링크

- 하테나 다이어리에는 키워드 링크라는 기능이 있었다.
  - 사용자가 블로그에 글을 작성하면 일부 키워드에 링크가 자동으로 걸린다.
- 최초 구현 방법은 정규식을 활용했는데 키워드 링크에 등록된 키워드가 10만건을 넘어가면서 시스템이 비명을 지르게 된다.
- 해결방법?
  - **정규표현 방식에서 Trie(트라이)를 사용한 매칭 구현으로 변경**
    - Trie는 문자열 집합을 트리구조로 해서 효율적으로 저장한다.
    - 탐색대상 데이터의 공통 접두사를 모아놓은 트리구조가 된다.
  - **AC법으로 Trie 매칭을 더욱 빠르게 개선**
- 하테나 다이어리의 키워드 링크를 개선하면서 알게 된점
  - **처음부터 최적의 구현을 사용하는게 반드시 옳은 것은 아니다.**
  - 데이터가 대규모가 될 시기를 대비해서 본질적인 문제의 해결방법을 머릿속에 넣어두어야 한다.

## 9. 전문 검색기술 도전

### 전문 검색기술의 응용범위

- 하테나에는 블로그 내용을 전문 검색해서 키워드로 블로그를 검색할 수 있는 기능을 제공하고 있다.
- 처음에는 RDB를 이용해 새로운 글을 작성하면 글에 포함된 키워드를 전부 추출해 DB 레코드에 저장해두었다.
  - 하지만 레코드 수가 너무 많아서 무거워지며 확장성 측면에서 파탄을 가져왔다.
- 검색엔진을 만들어 문제를 회피했다.

## 11. 대규모 데이터 처리를 지탱하는 서버/인프라 입문

### 엔터프라이즈 vs 웹 서비스

#### 웹 서비스의 인프라

- 웹 서비스의 인프라에는 세가지 포인트가 있다.
  - 저비용 고효율 중시
    - 100%의 신뢰성은 목표로 하지 않는다.
  - 확장성이나 응답성에 대한 설계를 중시
  - 개발속도를 중시한 인프라로 구성
    - 빠른 배포나 롤백등이 가능한 인프라 환경 구축
- 클라우드 vs 자체구축 인프라
  - 클라우드 컴퓨팅은 저가로 사용하며 확장성이 높다는 장점이 있다.
  - 자체구축 인프라는 내부에서 하드웨어 구성을 유연하게 증설할 수 있고 병목현상 등을 자체적으로 확인할 수 있다.

## 12. 확장성 확보에 필요한 사고방식

- 운영하는 **`서버 1대에서 처리할 수 있는 트래픽 한계를 알고`** 어떻게 확장시켜 갈 것인지를 파악해야 한다.
- 서버 부하를 파악하고 그래프화하는 것이 중요하다.
  - 여러 웹 서버 중 CPU나 메모리를 사용하는 그래프를 가시화해서 병목이나 이상현상을 파악할 수 있어야 한다.

## 13. 다중성 확보, 시스템 안정화

### 다중성 확보 (웹 서버)

- 서버가 수십대로 확장해 있을 때, 이 중 1대의 서버에 장애가 발생하는 건 다반사다.
- 로드밸런서로 장애가 발생한 서버를 분리하고 정상으로 복구되면 복귀시킨다.
  - 로드밸런서는 서버에 대해 주기적으로 헬스체크를 진행해야 한다.

### 다중성 확보 (DB)

- 마스터 DB의 다중성을 어떻게 확보할 수 있을까?
- **`Active/Standby`** 로 멀티 마스터 방법을 사용
- 한 쪽에 쓰기 작업을 하면 반대쪽에 ms 단위로 데이터가 동기화 되지 않는 문제가 존재
  - 하테나의 경우 동기화가 되지 않음을 받아들이고 수동으로 복구
- 드물게 마스터가 다운될 경우 서비스 정지로 이어질 위험은 거의 막아둘 수 있다.

### 시스템 안정화

- **메모리나 CPU를** 한계에 다다를 정도로 사용하기 보다는 **7할 정도의 기준**을 두고 확장하도록 설계해야 한다.
  - 한계까지 사용하다가 장애로 이어지는 일이 빈번하게 발생
- **사용자의 엑세스 패턴**
  - yahoo 토픽에 하테나 다이어리 링크가 링크되면 **차원이 다른 접속이 들어와 다운되는 일**이 있었다.
  - **`캐시서버를 추가해서`** 게스트 사용자의 경우 캐시를 반환하도록 구성할 수 있다.
- 데이터량 증가
  - 별점을 달면 띠링 같은 밝은 소리가 나는데 아이들이 별을 수백개 달면서 비정상적으로 데이터 량이 증가
  - DB 설계를 바꿔 별점 1000개를 달면 1000개의 레코드를 추가하던 방식에서 1000개를 추가했다는 정보를 가진 레코드를 1건만 추가하도록 수정
  - 데이터가 비정상적으로 늘어나는 것을 빨리 눈치채고 적절한 조치를 취하는게 중요
- 외부 연계 추가
  - 웹 API나 외부 시스템이 다운될 때 덩달아서 다운되지 않도록 시스템을 구축하는 것도 중요

### 시스템 안정화 대책

- 먼저 적절한 버퍼 유지를 위해 한계의 7할 운용을 수행한다.
  - 시스템 수행 능력의 70%를 상한선으로 해서 이를 넘어서면 서버를 추가하거나 메모리를 늘리는 방안
- 운영 DB에 무거운 쿼리를 날리는 경우 사용자가 접근하는 DB가 아닌 별도의 DB에 쿼리한다.
- 새로고침이나 Dos 같이 특정 IP에서 일정 시간동안 다수의 접근이 오면 엑세스를 차단한다.
- 웹 서버가 지나치게 리소스를 사용했다가 판단하면 자동 재시작을 통해 안정된 시스템을 실현
- DB에 실행중인 쿼리 중 소요시간이 긴 SQL을 kill

## 14. 효율향상 전략

### 가상화 기술

- **가상화 기술의 목적**은 아래와 같을 것이다.
  - **확장성**: 오버헤드 최소화
  - **비용대비** 성능: 리소스 사용률 향상
  - **고가용성**: 환경의 격리
- 가상화 기술을 통해 얻은 장점에 대해 정리해보자
  - 물리적인 리소스 제약에서 해방됨으로써 동적으로 변경할 수 있게 되고 게스트 OS의 복제가 용이해졌다.
  - 이에 따라 서버 증설이 용이해지고 확장성을 확보할 수 있다.
- 단점으로는 성능상의 오버헤드가 있다는 점이다. 또한 가상기술 구현의 결함으로 네트워크가 단절되는 등의 불안정 요인도 있다.

### 하드웨어와 효율향상

- **`CPU, 메모리, SSD/HDD`** 가격이 점차 낮아지고 있으니 가격대비 적당한 성능의 부품들을 선택해 활용하자

## 15. 웹 서비스와 네트워크

### 글로벌화

- 세계 각지에서 하테나 데이터 센터의 video 파일(5-6MB)을 가져간다면 대략 20-30초 정도 걸릴 것이다.
- 수 MB 단위의 파일을 태평양을 넘어서 전송하는 것은 상당한 오버헤드지만 CDN을 사용하면 크게 달라진다.
  - CDN을 사용하면 대략 5~6초만에 파일을 받을 수 있으며 타임아웃도 발생하지 않고 양호한 응답시간을 유지할 수 있다.
- CDN은 **`Content Delivery Network`** 의 약자다.
  - 세계 각지에 서버를 두고 미디어를 캐싱시켜서 사용자가 **`가장 가까운 서버로 엑세스해 미디어를 다운로드 하도록 하는게 기본 동작원리다.`**
  - 예를 들면 미국 사용자는 미국에 가장 가까운 서버에 한국 사용자는 한국과 가장 가까운 서버에 접속해 응답시간을 단축시킨다.

## 부록. 현대 웹 서비스 구축에 필요한 실전 기술

### 작업큐 시스템

- 웹 서비스에서는 기본적으로 요청이 동기적으로 실행된다.
- 계속 성장하는 웹 서비스는 데이터가 축적되면서 데이터 갱신처리가 점점 무거워지고 사용자 경험에 영향을 주게 된다.
- 이런 경우 작업큐 시스템을 사용함으로써 **`나중으로 미뤄도 되는 처리를 비동기로 실행할 수 있고 사용자 경험도 개선할 수 있다.`**
- 어느 정도 양이 있는 비동기 처리를 안정적으로 수행하려면 작업큐와 워커를 세트로 한 시스템이 일반적이다.
  - 작업 큐 시스템에서는 비동기 처리 하려는 작업을 큐에 등록하고, 워커에서 큐의 작업을 추출해 실제로 처리한다.

### 스토리지 선택

- 수백 GB, 수백 TB를 넘는 데이터의 스토리지는 약간의 구성 변경이나 엑세스 패턴 변화로 응답속도가 저하되는 경우가 있다.
- 저장하고자 하는 데이터의 특성에 맞는 스토리지를 선택하는 것이 비용과 성능, 안정성의 균형을 위한 열쇠가 된다.
- 스토리지 선택의 몇 가지 조건은 아래와 같다.
  - 조회 빈도 / 쓰기 빈도
  - 신뢰성
  - 허용할 수 있는 장애 레벨
- 여러 종류의 스토리지를 소개하는데 좀 옛날 자료라 정리하지 않고 넘어간다.

### 캐시 시스템

- 웹 서버의 부하가 증가해 시스템 용량이 부족하면 API나 DB 서버를 증설할 수도 있지만 HTTP 캐싱을 수행하도록 대책을 세울수도 있다.
- 어느 정도 규모있는 웹 어플리케이션은 리버스 프록시를 이용하여 프록시에서 요청에 대한 응답을 캐싱하여 캐시 서버를 효과적으로 이용할 수 있다.

### 계산 클러스터

- 대규모 웹 서비스를 운영하면 로그 데이터도 대량으로 쌓여간다.
- 대량으로 쌓인 로그 데이터는 한 번에 읽어들이는 것도 어렵고 통계처리나 분석을 하려면 큰 리소스를 필요로 한다.
- 이와 같은 처리를 빠르게 수행하기 위해서는 병렬처리가 가능한 계산 클러스터가 필요하다.
- 하테나에서는 계산 클러스터로 Hadoop이라는 MapReduce의 오픈소스 구현을 사용한다.
  - Map Reduce는 거대한 데이터를 빠르게 병렬로 처리하는 것이 목적이다.
  - 다수의 계산 노드로 구성된 클러스터와 대량 데이터를 분산해서 저장하기 위한 분산 파일시스템으로 구성된다.
