# 기초부터 다지는 ES 운영 노하우

- [책 링크](https://www.yes24.com/Product/Goods/96520155)

## 1. ES 흝어보기

- ES는 **루씬 기반의 오픈 소스 검색 엔진**이다. **JSON 기반의 문서**를 저장하고 검색할 수 있다.
- ES의 몇 가지 특징은 아래와 같다.
  - ES는 **준실시간성 검색 엔진**으로 볼 수 있다. 문서를 입력하자마자 검색하는 것은 불가능하더라도 1초의 시간이 흐른뒤에는 검색이 가능하기 때문이다.
  - 클러스터로 구성하여 안정성을 높이고 부하를 분산시킬 수 있다.
  - **스키마리스로** 필드를 사전에 정의하지 않아도 된다.
  - **REST API 기반의 인터페이스를 지원**하여 진입 장벽이 낮은 편이다.

## 2. ES 기본동작

- 인덱스의 생성, 문서 색인/수정 등의 과정을 확인하자.

  ```Elixir
    # 인덱스 생성
    PUT /contents

    # 생성된 인덱스 조회
    GET _cat/indices?v

    # 문서 추가
    PUT /contents/_doc/1
    {
      "title": "제목~",
      "author": "seo.jeong.kuk"
    }

    # 문서 조회
    GET /contents/_mappings?pretty
  ```

## 3. ES 모니터링

- 오픈 소스인 Head, 프로메테우스, X-Pack을 이용해서 모니터링 방법과 장단점을 살펴본다.
- 2021년에 나온 내용이라 그런지 책의 내용과 로컬에 설치된 ES 8 버전과 kibana 화면이 달라 정리하지 않는다.

## 4. ES 기본개념

### 4.1 클러스터와 노드의 개념

- **클러스터란** 여러 컴퓨터를 논리적으로 결합하여 전체를 하나의 컴퓨터 혹은 구성 요소로 사용할 수 있도록 하는 기술이다. 이때 **클러스터를 구성하는 하나 하나의 ES 프로세스를 노드**라고 부른다. 여러 개의 ES 노드를 ES처럼 동작하는 것이 ES 클러스터라고 할 수 있다. 다수의 노드로 클러스터를 구성하면 하나의 노드에 장애가 발생해도 안정적으로 클러스터를 유지할 수 있다.
- `curl localhost:9200` 명령어를 통해 ES의 버전이나 클러스터의 정보를 확인할 수 있다.
- 마스터 노드는 클러스터의 메타데이터를 관리하며 반드시 한 대 이상으로 구성해야 한다. 클러스터의 모든 노드는 현재 노드의 상태, 성능 정보, 샤드의 정보를 마스터 노드에게 알린다.
- 데이터 노드는 사용자가 색인한 문서를 저장하고 검색 요청을 처리해 결과를 돌려주는 역할을 한다. 받은 요청 중 자신이 처리할 수 있는 요청을 직접 처리하고 다른 데이터 노드가 처리할 요청은 해당 데이터 노드에게 전달한다.

### 4.2 인덱스와 타입

- **ES 6.x 이후의 버전은 하나의 인덱스에 하나의 타입만을 사용**하도록 변경되었지만 ES 5.x 까지는 하나의 인덱스에 여러개의 타입을 사용할 수 있었다.

  ```Elixir
    PUT /test_index/test_type1
    PUT /test_index/test_type2
  ```

- ES 6.x 버전부터 멀티 타입을 허용하지 않는 이유는 인덱스의 여러 타입의 키가 동일한 경우 검색 결과에서 의도치 않은 결과가 나타났기 때문이다.

  ```Elixir
    PUT /test_index/test_type1
    {
      "name": "타입1_이름"
    }

    PUT /test_index/test_type2
    {
      "name": "타입2_이름"
    }

    # test_index에 검색 시 의도하지 않게 둘 다 검색될 수 있음
  ```

### 4.3 샤드와 세그먼트

- **샤드**는 인덱스에 색인되는 문서들이 저장되는 논리적인 공간을 의미하며 세그먼트는 샤드의 데이터를 가지고 있는 물리적인 파일을 의미한다. **하나의 인덱스는 다수의 샤드로 구성되고 하나의 샤드는 다수의 세그먼트로 구성**된다.
- 어떤 인덱스가 5개의 샤드로 구성된다면 실제 문서들은 5개의 샤드에 각각 나뉘어 저장된다.
  - 인덱스에서 샤드 3번에 문제가 생긴다면 샤드 3번에 저장된 문서들만 검색할 수 없거나 샤드 3번에 저장된 문서들만 색인이 되지 않는 문제가 발생한다.
- ES에서 인덱스는 샤드로 나누고, 샤드를 데이터 노드에 할당한다. 샤드는 원본인 프라이머리 샤드와 복제본인 레플리카 샤드로 구성된다. 복제본이 없으면 특정 샤드에 장애가 발생할 때 데이터를 유실할 수도 있다.
  - 프라이머리 샤드는 최초 인덱스를 생성할 때 개수를 결정하는데 이후 프라이머리 샤드의 개수를 변경할 수 없으므로 신중하게 결정해야 한다.
- **색인된 문서는 먼저 메모리 캐시**에 저장되고 이 단계에서는 검색되지 않는다. 이후 **refresh 과정을 거쳐야** 디스크에 세그먼트 단위로 문서가 저장되고 **문서의 검색이 가능**해진다.
- **세그먼트는 불변의 특성**을 갖는데, 이는 **기존에 기록한 데이터를 수정하지 않는다는 의미**다. 데이터를 업데이트 하면 새로운 세그먼트에 업데이트할 문서의 내용을 새롭게 쓰고 기존의 데이터는 더 이상 쓰지 못하도록 불용 처리한다.

### 4.4 프라이머리 샤드와 레플리카 샤드

- **레플리카 샤드는 프라이머리 샤드와 동일한 문서를 가지고 있기 때문에** 사용자의 검색 요청에 응답할 수 있다. 따라서 **레플리카 샤드를 늘리면 검색 요청에 대한 응답속도를 높일 수 있으므로** 설계시 이런 점도 고려해야 한다.
- ES가 문서를 색인할 때 어떤 프라이머리 샤드에 문서를 저장할까?
  - **`프라이머리 샤드 번호 = Hash(문서의 id) % 프라이머리 샤드 개수`**
  - 문서에 할당 된 Id를 기준으로 ES에서 샤드 할당 해시 함수를 이용해 몇 번째 프라이머리 샤드에 저장할지 결정한다.
  - 인덱스 생성시 별도로 설정하지 않으면 6.x 버전에서는 5개, 7.x 버전에서는 1개로 프라이머리 샤드가 설정된다.
- 특정 노드에 문제가 발생해 **클러스터에서 이탈하면 노드에 저장된 문서는 인덱스에 존재하지 않게 된다**. 이를 위해 레플리카 샤드가 존재하는데 따로 설정하지 않으면 **프라이머리 샤드 당 하나의 레플리카 샤드를 만드는게 기본 설정**이다.
  - 프라이머리 샤드와 달리 레플리카 샤드는 설정을 통해 개수를 변경할 수 있다.
- 정리하면 인덱스는 여러 샤드로 구성되어 있고 각 샤드는 클러스터를 구성하는 여러 노드들에 분산되어 있다. 각 샤드는 세그먼트로 구성되어 있으며 세그먼트 안에 각각의 문서들이 저장되어 있다. 세그먼트는 시간이 지남에 따라 늘어나는 세그먼트들을 병합하면서 갯수가 늘어났다가 줄어들기를 반복하는 형태로 운영된다.

### 4.5 매핑

- **매핑은** RDBMS의 스키마와 유사하며 **ES에 저장될 JSON 문서들이 어떤 키와 어떤 형태의 값**을 가지고 있는지 정의한다.
- **`mapping API를`** 활용해 인덱스의 매핑 정보를 확인할 수 있으며 매핑을 미리 정의하는 형태를 정적 매핑, 정의하지 않고 사용하는 것을 동적 매핑이라고 부른다. 동적 매핑은 높은 편의성을 제공하지만 실무에서 운영할 때는 정적 매핑을 추천한다.

## 5. 클러스터 구축하기

### 5.1 elasticsearch.yml 설정 파일

- **ES의 환경 설정**을 영역별로 특징을 확인해본다.

```Elixir
  ## 클러스터의 이름을 설정하는 항목. 동일한 클러스터에 속하는 노드들은 동일한 클러스터 이름을 사용해야 한다.
  #cluster.name: my-application

  ## 노드의 이름을 설정하는 항목으로 클러스터 내에서 유일해야 한다.
  #node.name: node-1

  ## 데이터와 로그를 저장하는 경로
  path.data: /var/lib/elasticsearch
  path.logs: /var/log/elasticsearch

  ## 스왑 메모리 영역을 사용하지 않도록 하는 설정. ES는 스왑 메모리를 사용하지 않도록 권고한다.
  #bootstrap.memory_lock: true

  ## IP 주소와 포트
  #network.host: 192.168.0.1
  #http.port: 9200

  ## 클러스터링을 위한 다른 노드들의 정보를 나열
  #discovery.zen.ping.unicast.hosts: ["host1", "host2"]

  ## 클러스터를 구축하기 위해 필요한 최소한의 마스터 노드 대수
  ## 만약 1로 설정했다고 가정하고 3대의 마스터 중 A,B <-> C 통신이 끊기면 두 개의 클러스터가 생기니 주의한다.
  #discovery.zen.minimum_master_nodes: 2
```

## 6. 클러스터 운영하기

### 6.1 버전 업그레이드

- ES 버전 업그레이드 방법은 두 가지가 있다.
  - **Full Cluster Restart**: 모든 노드를 동시에 재시작하는 방식으로 다운타임 발생
  - **Rolling Restart**: 노드를 한 대씩 재시작하는 방식으로 다운타임은 없지만 업그레이드 시간이 길어진다.
- Full Cluster Restart는 모든 노드를 중지하고 작업하기 때문에 작업방법이 간단하다.
- Rolling Restart로 업그레이드 할 때의 작업들을 살펴보자.
  - **우선 샤드 할당 작업을 하지 않도록 설정한다.**
    - 클러스터의 노드에 장애가 발생하면 그 노드가 더 데이터를 받을 수 없다고 판단해 샤드들을 다른 데이터 노드로 분배한다.
    - 하지만 업그레이드는 장애가 아니므로 샤드를 재 분배하면 네트워크나 디스크 I/O 비용이 크니 재분배 해서는 안 된다.
    - `cluster.routing.allocation.enable: "none"` 설정을 통해 샤드 할당 작업을 비활성화 할 수 있다.
  - **프라이머리 샤드와 레플리카 샤드간의 데이터를 똑같은 형태로 맞춘다.**
    - 두 샤드가 가지고 있는 문서가 일치해야 클러스터에서 노드가 제외되더라도 데이터의 정합성을 보장할 수 있다.
    - `POST _flush/synced`
  - **업그레이드 된 노드가 기존 클러스터에 정상적으로 합류했는지 확인한다.**
  - **비활성화 해 놓은 샤드 할당 기능을 다시 활성화한다.**
    - `cluster.routing.allocation.enable: null`

### 6.2 샤드 배치 방식 변경

- ES는 자동으로 샤드를 배치하지만 경우에 따라 샤드 배치 방식을 변경해야 할 때가 있다. 예를 들어 특정 노드에 장애가 발생하여 unassigned 샤드들에 대한 재할당 작업이 5회 이상 실패할 경우, 일정 기간이 지난 오래된 인덱스의 샤드를 특정 노드에 강제로 배치하는 경우에 속한다.
- **샤드의 배치 방식을 변경하는 방법**은 아래와 같다.
  - **reroute**: 샤드 하나하나를 특정 노드에 배치
  - **allocation**: 클러스터 전체의 샤드 배치 방식을 변경
  - **rebalance**: 클러스터 전체의 샤드 재분배 방식 변경
  - **filtering**: 특정 조건에 해당하는 샤드들을 특정 노드에 배치
- 구체적인 방법들은 필요할 때 살펴본다.

### 6.3 클러스터와 인덱스의 설정 변경

- 클러스터의 설정 변경은 **`cluster/settings API를`** 통해 변경할 수 있다.
- 클러스터의 적용된 설정을 확인하는 방법은 아래와 같다.
  - `GET _cluster/settings`

### 정리

- ES 클러스터 운영 중 중단 없이 버전 업그레이드를 하려면 **Rolling Restart** 방식을 사용하면 된다.
- 클러스터 API를 통해 샤드의 배치 방식을 변경할 수 있으며 reroute, allocation, filtering 등의 방법을 사용할 수 있다.
- 인덱스 API를 통해 인덱스의 다양한 설정값을 변경할 수 있으며 템플릿 API를 통해 인덱스가 생성될 때 기본으로 적용되는 설정값을 변경할 수 있다.

## 7. 클러스터 성능 모니터링과 최적화

- 응답 값에 대한 지표 설명은 필요할 때 찾아 읽어본다.

### 7.1 클러스터 상태 확인

- ES는 cat API를 통해 클러스터/노드/샤드의 상태 등 다양한 정보를 확인할 수 있다.
  - `GET _cat/health?format=json&pretty`
  - 응답 중 status는 상태를 의미하는데 아래와 같이 분류된다.
    - green: 모든 샤드가 정상동작
    - yellow: 모든 프라이머리 샤드는 정상 동작하고 있으나 일부/모든 레플리카 샤드가 정상적으로 동작하지 않음
    - red: 일부/모든 프라이머리 샤드/레플리카 샤드가 정상 동작하지 않음

### 7.2 노드의 상태 확인

- 클러스터를 구성하는 노드의 개수와 각 노드의 역할과 부하 상태를 확인할 수 있다.
  - `_cat/nodes?v`

### 7.3 인덱스의 상태와 정보 확인

- 인덱스의 상태로 클러스터와 같이 green, yellow, red로 표현된다. 의미 또한 클러스터의 상태값과 동일하다.
  - `_cat/indices`

### 7.4 샤드의 상태 확인

- `_cat/shards`

### 7.5 stats API로 지표 확인

- `_cluster/stats`

## 8. 분석 엔진으로 활용하기

### 8.1 Elastic Stack 이란

- Elastic Stack은 로그를 수집, 가공하고 이를 바탕으로 분석하는데 사용되는 플랫폼을 의미한다.
- ELK Stack 으로도 불리는데 로그를 전송하는 Filebeat, 전송된 로그를 JSON 문서로 파싱하는 Logstash, 파싱된 문서를 저장하는 ElasticSearch, 데이터를 시각화하는 Kibana 이렇게 4개의 시스템으로 구성된다.
- 각 시스템을 설치하는 방법이나 kibana에서 로그를 조회하고 시각화하는 방법을 다룬다. 필요할떄 학습한다.

## 9. 검색 엔진으로 활용하기

- ES는 Elastic Stack에 포함되어 로그 분석과 시각화 도구로도 많이 사용되지만 검색 엔진으로도 많이 활용된다.

### 9.1 inverted index란

- "I am a boy" 라는 문자열을 가진 문서가 있다고 가정해보자. 이 문자열을 공백을 기준으로 `i`, `am`, `a`, `boy` 라는 4개의 토큰으로 만들어진다. 그리고 아래와 같은 형태로 저장되는데 이것을 inverted index라고 부른다.

  ```text
    Tokens   Documents
       i       1
       am      1,2
       a       3,4
       boy     2
  ```

- 아래와 같이 API를 수행하여 어떻게 토큰이 생성되는지 확인할 수 있다.

  ```Elixir
    POST _analyze
    {
      "analyzer": "standard",
      "text": "I am a boyyyy"
    }
  ```

### 9.2 analyer 살펴보기

- 데이터가 token으로 구분될 때 아래와 같은 과정을 거치게 된다.
  - 문자열 -> character filter -> tokenizer -> token filter -> tokens
- 먼저 character filter는 문자열들을 1차로 변경한다. 특수 문자나 HTML 태그를 제거하는 과정을 통해 변경된 문자열은 tokenizer를 통해 n개의 토큰으로 나뉜다. 그 후 token filter가 토큰에 대해 다시 한 번 변형을 가한다. 예시로 토큰을 전부 소문자로 바꾸는 lowercase token filter가 대표적인 token filter이다.

### 9.3 analyer와 검색의 관계

- analyer를 통해 생성된 토큰들이 역인덱스에 저장되고, 검색할때는 역인덱스에 저장된 값을 바탕으로 문서를 찾는다. 따라서 검색 니즈를 잘 파악해서 적합한 analyze를 설정해야 한다.
- 필드에 text 타입과 keyword 타입으로 정의하면 검색 결과가 달라질 수 있는데 text 타입은 기본적으로 standard analyze를 사용하고 keyword 타입은 keyword analyze를 사용한다.

  ```Elixir
    POST _analyze
    {
      "analyzer": "keyword",
      "text": "I am a boy"
    }

    # 결과
    {
      "tokens": [
        {
          "token": "I am a boy",
          "start_offset": 0,
          "end_offset": 10,
          "type": "word",
          "position": 0
        }
      ]
    }
  ```

- standard analyze와 다르게 문자열을 나누지 않기 때문에 특정 단어로 검색하면 검색결과가 나오지 않게 된다.

### 9.4 Search API

- search API는 간단한 URI Search 형태로 제공하고 Request Body 작성도 제공한다.

  ```Elixir
    # 간단 검색
    GET test_data/_search
    {
      "query": { "term": { "title": "book" } }
    }

    # from/size를 활용
    GET test_data/_search
    {
      "from": 0,
      "size": 3,
      "query": { "term": { "title": "book" } }
    }

    # source 옵션으로 특정 필드만 조회
    GET test_data/_search
    {
      "_source": ["title", "description"],
      "query": { "term": { "title": "book" } }
    }
  ```

- from/size는 페이지네이션 하는 동안 새로운 문서가 유입되면 기존 검색 결과에 영향을 줄 수 있지만 scroll 옵션은 검색 시점의 스냅샷을 활용하기 때문에 페이지네이션이나 대량의 배치 작업에 활용된다.

### 9.5 Query DSL 이란

- search API에서 중요한 부분을 담당하는 검색 쿼리를 살펴보자. 검색 쿼리는 Query DSL이라 불리며 크게 Query Context와 Filter Context로 분류한다. Query Context는 Full Text Search라고도 불리며 전문검색에 활용된다. Filter Context는 검색어가 문서에 존재하는지 여부를 검사한다. 예를 들어 남자인지 여자인지 검색하는 경우가 Filter Context에 속한다.

### 9.6 Query Context

- 쿼리 컨텍스트의 종류는 아래와 같다.
  - match: 검색어에 맞는 토큰들이 존재하는지 확인한다.
  - match_phrase: match와 비슷하지만 검색어에 입력된 순서를 지켜야 한다.
  - multi_match: match와 비슷하지만 다수의 필드에 검색하기 위해 사용된다.
  - query_string: and, or이 같이 필요할 때 사용한다.

#### match 쿼리

- 검색어로 들어온 문자열을 analyzer로 분석한 뒤 해당 문자열의 토큰을 가지고 있는 문서를 검색한다.
- 아래 쿼리에서 ES는 검색어를 nginx, guide 두 개의 토큰으로 만들고 두 개의 토큰이 가장 많이 포함된 문서를 기준으로 score를 생성해서 검색 결과를 돌려준다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "match": {
          "description": "nginx guide"
        }
      }
    }
  ```

#### match_phrase 쿼리

- match와 달리 검색어의 순서를 고려한다. 예를 들어 nginx guide로 검색하면 match는 nginx, guide 두 개의 토큰으로 만들고 두 단어 중 하나라도 포함되어 있다면 검색 결과를 보여주지만 match_phrase는 정확한 순서를 가진 결과를 보여주기 때문에 둘다 순서에 맞게 포함되어 있어야 검색결과에 포함된다.

#### multi_match 쿼리

- match와 동일하지만 두 개 이상의 필드에 match 쿼리를 날릴 수 있다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "multi_match": {
          "query": "nginx guide",
          "fields": ["title", "description"]
        }
      }
    }
  ```

#### query_string 쿼리

- and와 or 같은 검색어 간 연산이 필요한 경우에 사용한다. 아래와 같이 query_string을 만들면 match 쿼리와 같은 의미이다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "query_string": {
          "query": "linux",
          "fields": ["title"]
        }
      }
    }
  ```

- 와일드 카드 검색도 가능하다.

```Elixir
    GET test_data/_search
    {
      "query": {
        "query_string": {
          "query": "*nux",
          "fields": ["title"]
        }
      }
    }
```

### 9.7 Filter Context

- 검색어가 문서에 포함되어 있는지 필터링에 사용되는 쿼리이다.
  - term: 검색어로 입력한 단어와 정확하게 일치하는 단어가 있는지 찾는다.
  - terms: term과 유사하지만 여러 개의 단어를 기준으로 하나 이상 일치하는 단어가 있는지 찾는다.
  - range: 특정 범위 안에 있는 값이 있는지 찾는다.
  - wildcard: 와일드 카드 패턴에 해당하는 값이 있는지 찾는다.

#### term 쿼리

- 정확하기 일치하는 단어를 찾을 때 사용하며 대소문자를 구분한다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "term": { "title": "Linux" } # 문서의 title이 linux면 검색되지 않음
      }
    }
  ```

#### terms 쿼리

- 둘 이상의 term을 검색할 때 사용한다.

#### range 쿼리

- 특정 값의 범위 이내에 있는 경우 사용된다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "range": {
          "createdAt": {
            "gte": "2015/01/01",
            "lte": "2015/12/31"
          }
        }
      }
    }
  ```

#### wildcard 쿼리

- 와일드 카드 특수문자를 이용해 일종의 Full-Scan이 가능한 쿼리다. 검색속도가 느리기 때문에 주의해야 한다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "wildcard": {
          "publisher.keyword": "*Media*"
        }
      }
    }
  ```

### 9.8 bool query를 이용해 쿼리 조합하기

- 실제 검색할 때는 Query Context와 Filter Context를 조합하는 방법도 필요하다. 그 중 대표적으로 사용되는 방법인 bool query에 대해 알아보자.
  - must: 항목 내 쿼리에 일치하는 문서를 검색 (스코어링 O, 캐싱 X)
  - filter: 항목 내 쿼리에 일치하는 문서를 검색 (스코어링 X, 캐싱 O)
  - should: 항목 내 쿼리에 일치하는 문서를 검색 (스코어링 O, 캐싱 X)
  - must_not: 항목 내 쿼리에 일치하는 않는 문서를 검색 (스코어링 X, 캐싱 O)
- 위 특징을 기준으로 must, should는 Query Context에서 실행되고 filter, must_not은 Filter Context에서 실행된다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "bool": {
          "must":[
            {
              "match": {
                "title": "nginx"
              }
            }
          ],
          "filter": [
            {
              "range": {
                "createdAt": {
                  "gte": "2015/01/01",
                  "lte": "2015/12/31"
                }
              }
            }
          ]
        }
      }
    }
  ```

- 위 쿼리는 must 절에서 title이 nginx가 들어간 문서를 찾고 filter 절에서 날짜에 해당하는 문서를 찾는다.
- 또한 아래 쿼리처럼 원치않는 문서를 제외할 수도 있다.

  ```Elixir
    GET test_data/_search
    {
      "query": {
        "bool": {
          "must":[
            {
              "match": {
                "title": "nginx"
              }
            },
            {
              "range": {
                "createdAt": {
                  "gte": "2015/01/01",
                  "lte": "2015/12/31"
                }
              }
            }
          ],
          "must_not": [
            {
              "match": {
                "description": "performance"
              }
            }
          ]
        }
      }
    }
  ```

## 10. 색인 성능 최적화

### 10.1 정적 매핑 적용하기

- 동적 매핑은 미리 매핑 정보를 생성하지 않아도 되지만 불 필요한 필드가 생성될 수 있고 정적 매핑은 미리 매핑 정보를 생성해야 하지만 필요한 필드만 사용할 수 있다.
- 동적 매핑을 사용하면 불 필요한 매핑 정보가 생성될 수 있으며 이런 매핑 정보는 색인 성능을 저하시킬 수 있다.
- 또한 동적 매핑으로 문자열 필드를 생성할 때 text, keyword 타입이 두 가지가 생성되기 때문에 조회나 색인 과정에서 성능이 저하될 수 있다. 실제로 책 예제에서 정적 매핑으로 100,000건 bulk API를 사용하는 경우 동적 매핑보다 25%가 빠른 결과를 보인다.

### 10.3 refresh interval 변경하기

- ES는 색인되는 문서들을 메모리 버퍼 캐시에 먼저 저장한 후 refresh_interval 주기가 지나면 디스크에 세그먼트 단위로 저장된다. refresh_interval의 기본 값은 1초이며 refresh 작업은 디스크 I/O를 발생히키기 때문에 성능을 저하시킬 수 있다. 그렇다고 refresh_interval을 너무 길게 설정하면 색인된 문서를 바로 검색할 수 없게 된다.
- ES를 실시간 검색 엔진으로 활용하고자 하면 기본 값 1초로 유지하고, 대용량의 로그를 수집하고 당장 검색할 필요가 없다면 refresh_interval을 충분히 늘려서 색인 성능을 확보할 수 있다.
- refresh_interval은 인덱스의 setting API를 통해 설정이 가능하고 여러 번 변경할 수 있기 때문에 새벽시간엔
  refresh_interval을 늘리고 업무 시간에는 다시 줄이는 방식으로도 운영할 수 있다.

### 10.4 bulk API

- 많은 문서를 단 건으로 호출하는 것 보다 bulk API를 통해 문서의 색인, 업데이트 작업을 모아서 한 번에 수행하는 것이 좋다. 단일 색인 요청을 1만번 하면 2분 정도 소요되지만 bulk API를 활용하면 1초가 채 걸리지 않는다.
  따라서 여러 문서에 대해 색인과 업데이트가 필요하면 bulk API를 활용해 성능을 확보하는게 좋다.

### 10.5 그 외 색인 성능을 확보하는 방법

- 문서를 색인할 때 PUT으로 id를 지정하며 색인할 수 있고 POST로 ES가 id를 생성하게 할 수 있다. POST를 통해 id를 지정하지 않고 색인하는 경우 id에 해당하는 문서가 존재하는지 확인하는 과정을 생략한다. 따라서 PUT 보다는 POST를 이용한 색인이 조금 더 빠르다.

## 11. 검색 성능 최적화

### 11.1 ES 캐시의 종류와 특성

- ES는 동일한 요청에 빠른 응답을 주기 위해 쿼리의 결과를 캐싱한다. ES에서 제공하는 대표적인 캐시 종류는 아래와 같다.
  - Node Query Cache: 쿼리에 의해 각 노드에 캐싱
  - Shard Request Cache: 쿼리에 의해 각 샤드에 캐싱
  - Field Data Cache: 쿼리에 의해 필드를 대상으로 각 노드에 캐싱
- 캐시들이 기본적으로 활성화 되어 있기 때문에 필요한 시점에 깊게 공부한다.

### 11.2 검색 쿼리 튜닝하기

- 많은 필드에 걸쳐 검색을 해야 하는 경우 copy_to 기능을 고려할 수 있다.

  - 예를 들어 first_name, last_name 두 개의 필드 조회를 full_name이라는 새로운 필드로 복사해서 한 번에 검색할 수 있다.

  ```Elixir
    PUT copy_to/_doc/_mapping
    {
      "_doc": {
        "properties": {
          "first_name": {
            "type": "text",
            "copy_to": "full_name"
          },
          "last_name": {
            "type": "text",
            "copy_to": "full_name"
          },
          "full_name": {
            "type": "text"
          }
        }
      }
    }

    # first_name, last_name이 아닌 full_name으로 한 번에 검색
      GET copy_to/_search
      {
        "query": {
          "match": {
            "full_name": "benjamin button"
          }
        }
      }
  ```

- 문서를 검색할 때 match를 많이 사용하는데 match 쿼리는 analyzer를 통해 검색어를 분석하는 과정이 포함되기 때문에 분석을 위한 추가시간이 필요하다. 따라서 match보다는 term 쿼리가 성능이 좋다.
- 또한 ES는 수치 계산이 없는 데이터는 keyword 필드 타입으로 매핑하도록 권고한다. 회원의 고유번호나 계좌 번호같은 숫자형 데이터는 더하거나 뺴는 연산이 필요없기 때문에 keyword 필드 데이터 타입으로 정의하고 term 쿼리를 사용하는 것이 적합하다. 숫자형 데이터는 주로 연산이나 range 같은 범위 검색 쿼리에 최적화되어 있기 때문에 용도에 맞게 활용하도록 하자.

### 11.3 샤드 배치 결정하기

- ES는 프라이머리 샤드를 설정하면 변경할 수 없기 때문에 처음 샤드 개수를 설정할 때 신중하게 설정해야 한다.
- 샤드 배치를 계획없이 진행하면 클러스터 내의 데이터 노드간 볼륨 사용량이 불균형해진다.
  - 3개의 노드에 4개의 샤드를 설정하면 1개의 노드는 2개의 샤드를 보유하는 문제
  - 3개의 노드에 2개의 샤드를 설정하면 1개의 노드가 놀게됨
  - 3개의 노드에 3개의 샤드를 설정했는데 1개의 노드가 추가되어 노드가 놀게 됨.
- 처음 클러스터를 구성할 때 추후 증설을 미리 계획하여 최초 구성한 노드 개수와 증설된 이후 노드의 개수로 최소 공배수로 샤드 개수를 설정하면 위 같은 문제를 예방가능하다.

### 11.5 그 외의 검색 성능을 확보하는 방법들

- ES는 문서를 모델링할 때 가급적 간결하게 구성하도록 권고한다. parent/child 구성이나 nested 타입같이 문서 간의 연결 관계 처리를 필요로 하는 구성은 권장하지 않는다.
- painless script를 사용하여 하나의 문서를 처리할 때 부가적인 리소스를 사용하지 않는 것도 권고 사항이다.
- 레플리카 샤드를 충분히 둘 것을 권고한다. 레플리카 샤드는 데이터 안정성을 확보할 뿐 아니라 검색 요청에 대해 더 많은 샤드들이 결과를 리턴해주는 역할을 한다. 레플리카 샤드가 많아질수록 검색성능은 좋아지게 되지만 인덱싱 성능과 볼륨 사용량이 증가하니 적절하게 추가하는 것이 좋다.

## 12. ES 클러스터 구축 시나리오

- ES는 주로 두 가지 용도로 사용된다.
  - 분석 엔진으로 ES 클러스터를 구성
  - 검색 엔진으로 ES 클러스터를 구성
- 분석 엔진으로 ES를 구성할 경우 하루에 적재되는 문서의 전체 용량과 보관 기간을 사전에 산정하는게 핈수다.
- 검색 엔진으로 ES를 구성할 경우 검색 서비스로 제공할 인덱스 몇 개만 사용하는게 일반적이며 분석 엔진과 달리 응답 시간이 가장 중요한 요소가 된다.

### 12.4 검색 엔진으로 활용하는 클러스터

- 검색 엔진이 100ms 내로 응답하라는 요구사항이 있을 떄 실제 테스트는 데이터 노드 한 대를 클러스터로 구성하고 해당 노드에 데이터를 저장한 후 사용자의 검색 쿼리에 대한 응답을 100ms 이하로 줄 수 있는지 테스트해야 한다. 클러스터의 구성은 데이터 노드 한 대, 레플리카 샤드 없이 프라이머리 샤드만 1개로 구성한다.
- 해당 샤드에 데이터를 계속 색인하면서 샤드의 크기가 커짐에 따라 검색 성능이 어떻게 변화하는지 측정한다. 일반적으로 인덱스의 크기가 커질수록 쿼리의 응답속도는 느려진다. 색인과 검색을 반복하다가 원하는 응답속도인 100ms에 도달하는 순간 색인을 멈춘다. 단일 샤드로 구성되었기 때문에 이 때 생성된 인덱스의 크기가 곧 단일 샤드의 크기가 된다. 예를 들어 인덱스 크기가 25GB일때 100ms 응답 속도에 도달했다고 가정하자. 요구사항에 검색엔진에 사용될 데이터는 500GB라고 가정하면 샤드의 개수를 20개로 산정해야 한다.
