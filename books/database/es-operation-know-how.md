# 기초부터 다지는 ES 운영 노하우

- [책 링크](https://www.yes24.com/Product/Goods/96520155)

## 1. ES 흝어보기

- ES는 루씬 기반의 오픈 소스 검색 엔진이다. JSON 기반의 문서를 저장하고 검색할 수 있다.
- ES의 몇 가지 특징은 아래와 같다.
  - ES는 준실시간성 검색 엔진으로 볼 수 있다. 문서를 입력하자마자 검색하는 것은 불가능하더라도 1초의 시간이 흐른뒤에는 검색이 가능하기 때문이다.
  - 클러스터로 구성하여 안정성을 높이고 부하를 분산시킬 수 있다.
  - 스키마리스로 필드를 사전에 정의하지 않아도 된다.
  - REST API 기반의 인터페이스를 지원하여 진입 장벽이 낮은 편이다.

## 2. ES 기본동작

- 인덱스의 생성, 문서 색인/수정 등의 과정을 확인하자.

  ```Elixir
    # 인덱스 생성
    PUT /contents

    # 생성된 인덱스 조회
    GET _cat/indices?v

    # 문서 추가
    PUT /contents/_doc/1
    {
      "title": "제목~",
      "author": "seo.jeong.kuk"
    }

    # 문서 조회
    GET /contents/_mappings?pretty
  ```

## 3. ES 모니터링

- 오픈 소스인 Head, 프로메테우스, X-Pack을 이용해서 모니터링 방법과 장단점을 살펴본다.
- 2021년에 나온 내용이라 그런지 책의 내용과 로컬에 설치된 ES 8 버전과 kibana 화면이 달라 정리하지 않는다.

## 4. ES 기본개념

### 4.1 클러스터와 노드의 개념

- 클러스터란 여러 컴퓨터를 논리적으로 결합하여 전체를 하나의 컴퓨터 혹은 구성 요소로 사용할 수 있도록 하는 기술이다. 이때 클러스터를 구성하는 하나 하나의 ES 프로세스를 노드라고 부른다. 여러 개의 ES 노드를 ES처럼 동작하는 것이 ES 클러스터라고 할 수 있다. 다수의 노드로 클러스터를 구성하면 하나의 노드에 장애가 발생해도 안정적으로 클러스터를 유지할 수 있다.
- `curl localhost:9200` 명령어를 통해 ES의 버전이나 클러스터의 정보를 확인할 수 있다.
- 마스터 노드는 클러스터의 메타데이터를 관리하며 반드시 한 대 이상으로 구성해야 한다. 클러스터의 모든 노드는 현재 노드의 상태, 성능 정보, 샤드의 정보를 마스터 노드에게 알린다.
- 데이터 노드는 사용자가 색인한 문서를 저장하고 검색 요청을 처리해 결과를 돌려주는 역할을 한다. 받은 요청 중 자신이 처리할 수 있는 요청을 직접 처리하고 다른 데이터 노드가 처리할 요청은 해당 데이터 노드에게 전달한다.

### 4.2 인덱스와 타입

- ES 6.x 이후의 버전은 하나의 인덱스에 하나의 타입만을 사용하도록 변경되었지만 ES 5.x 까지는 하나의 인덱스에 여러개의 타입을 사용할 수 있었다.

  ```Elixir
    PUT /test_index/test_type1
    PUT /test_index/test_type2
  ```

- ES 6.x 버전부터 멀티 타입을 허용하지 않는 이유는 인덱스의 여러 타입의 키가 동일한 경우 검색 결과에서 의도치 않은 결과가 나타났기 때문이다.

  ```Elixir
    PUT /test_index/test_type1
    {
      "name": "타입1_이름"
    }

    PUT /test_index/test_type2
    {
      "name": "타입2_이름"
    }

    # test_index에 검색 시 의도하지 않게 둘 다 검색될 수 있음
  ```

### 4.3 샤드와 세그먼트

- 샤드는 인덱스에 색인되는 문서들이 저장되는 논리적인 공간을 의미하며 세그먼트는 샤드의 데이터를 가지고 있는 물리적인 파일을 의미한다. 하나의 인덱스는 다수의 샤드로 구성되고 하나의 샤드는 다수의 세그먼트로 구성된다.
- 어떤 인덱스가 5개의 샤드로 구성된다면 실제 문서들은 5개의 샤드에 각각 나뉘어 저장된다.
  - 인덱스에서 샤드 3번에 문제가 생긴다면 샤드 3번에 저장된 문서들만 검색할 수 없거나 샤드 3번에 저장된 문서들만 색인이 되지 않는 문제가 발생한다.
- ES에서 인덱스는 샤드로 나누고, 샤드를 데이터 노드에 할당한다. 샤드는 원본인 프라이머리 샤드와 복제본인 레플리카 샤드로 구성된다. 복제본이 없으면 특정 샤드에 장애가 발생할 때 데이터를 유실할 수도 있다.
  - 프라이머리 샤드는 최초 인덱스를 생성할 때 개수를 결정하는데 이후 프라이머리 샤드의 개수를 변경할 수 없으므로 신중하게 결정해야 한다.
- 색인된 문서는 먼저 메모리 캐시에 저장되고 이 단계에서는 검색되지 않는다. 이후 refresh 과정을 거쳐야 디스크에 세그먼트 단위로 문서가 저장되고 문서의 검색이 가능해진다.
- 세그먼트는 불변의 특성을 갖는데, 이는 기존에 기록한 데이터를 수정하지 않는다는 의미다. 데이터를 업데이트 하면 새로운 세그먼트에 업데이트할 문서의 내용을 새롭게 쓰고 기존의 데이터는 더 이상 쓰지 못하도록 불용 처리한다.

### 4.4 프라이머리 샤드와 레플리카 샤드

- 레플리카 샤드는 프라이머리 샤드와 동일한 문서를 가지고 있기 때문에 사용자의 검색 요청에 응답할 수 있다. 따라서 레플리카 샤드를 늘리면 검색 요청에 대한 응답속도를 높일 수 있으므로 설계시 이런 점도 고려해야 한다.
- ES가 문서를 색인할 때 어떤 프라이머리 샤드에 문서를 저장할까?
  - 프라이머리 샤드 번호 = Hash(문서의 id) % 프라이머리 샤드 개수
  - 문서에 할당 된 Id를 기준으로 ES에서 샤드 할당 해시 함수를 이용해 몇 번째 프라이머리 샤드에 저장할지 결정한다.
  - 인덱스 생성시 별도로 설정하지 않으면 6.x 버전에서는 5개, 7.x 버전에서는 1개로 프라이머리 샤드가 설정된다.
- 특정 노드에 문제가 발생해 클러스터에서 이탈하면 노드에 저장된 문서는 인덱스에 존재하지 않게 된다. 이를 위해 레플리카 샤드가 존재하는데 따로 설정하지 않으면 프라이머리 샤드 당 하나의 레플리카 샤드를 만드는게 기본 설정이다.
  - 프라이머리 샤드와 달리 레플리카 샤드는 설정을 통해 개수를 변경할 수 있다.
- 정리하면 인덱스는 여러 샤드로 구성되어 있고 각 샤드는 클러스터를 구성하는 여러 노드들에 분산되어 있다. 각 샤드는 세그먼트로 구성되어 있으며 세그먼트 안에 각각의 문서들이 저장되어 있다. 세그먼트는 시간이 지남에 따라 늘어나는 세그먼트들을 병합하면서 갯수가 늘어났다가 줄어들기를 반복하는 형태로 운영된다.

### 4.5 매핑

- 매핑은 RDBMS의 스키마와 유사하며 ES에 저장될 JSON 문서들이 어떤 키와 어떤 형태의 값을 가지고 있는지 정의한다.
- mapping API를 활용해 인덱스의 매핑 정보를 확인할 수 있으며 매핑을 미리 정의하는 형태를 정적 매핑, 정의하지 않고 사용하는 것을 동적 매핑이라고 부른다. 동적 매핑은 높은 편의성을 제공하지만 실무에서 운영할 때는 정적 매핑을 추천한다.

## 5. 클러스터 구축하기

### 5.1 elasticsearch.yml 설정 파일

- ES의 환경 설정을 영역별로 특징을 확인해본다.

```Elixir
  ## 클러스터의 이름을 설정하는 항목. 동일한 클러스터에 속하는 노드들은 동일한 클러스터 이름을 사용해야 한다.
  #cluster.name: my-application

  ## 노드의 이름을 설정하는 항목으로 클러스터 내에서 유일해야 한다.
  #node.name: node-1

  ## 데이터와 로그를 저장하는 경로
  path.data: /var/lib/elasticsearch
  path.logs: /var/log/elasticsearch

  ## 스왑 메모리 영역을 사용하지 않도록 하는 설정. ES는 스왑 메모리를 사용하지 않도록 권고한다.
  #bootstrap.memory_lock: true

  ## IP 주소와 포트
  #network.host: 192.168.0.1
  #http.port: 9200

  ## 클러스터링을 위한 다른 노드들의 정보를 나열
  #discovery.zen.ping.unicast.hosts: ["host1", "host2"]

  ## 클러스터를 구축하기 위해 필요한 최소한의 마스터 노드 대수
  ## 만약 1로 설정했다고 가정하고 3대의 마스터 중 A,B <-> C 통신이 끊기면 두 개의 클러스터가 생기니 주의한다.
  #discovery.zen.minimum_master_nodes: 2
```

## 6. 클러스터 운영하기

### 6.1 버전 업그레이드

- ES 버전 업그레이드 방법은 두 가지가 있다.
  - Full Cluster Restart: 모든 노드를 동시에 재시작하는 방식으로 다운타임 발생
  - Rolling Restart: 노드를 한 대씩 재시작하는 방식으로 다운타임은 없지만 업그레이드 시간이 길어진다.
- Full Cluster Restart는 모든 노드를 중지하고 작업하기 때문에 작업방법이 간단하다.
- Rolling Restart로 업그레이드 할 때의 작업들을 살펴보자.
  - 우선 샤드 할당 작업을 하지 않도록 설정한다.
    - 클러스터의 노드에 장애가 발생하면 그 노드가 더 데이터를 받을 수 없다고 판단해 샤드들을 다른 데이터 노드로 분배한다.
    - 하지만 업그레이드는 장애가 아니므로 샤드를 재 분배하면 네트워크나 디스크 I/O 비용이 크니 재분배 해서는 안 된다.
    - `cluster.routing.allocation.enable: "none"` 설정을 통해 샤드 할당 작업을 비활성화 할 수 있다.
  - 프라이머리 샤드와 레플리카 샤드간의 데이터를 똑같은 형태로 맞춘다.
    - 두 샤드가 가지고 있는 문서가 일치해야 클러스터에서 노드가 제외되더라도 데이터의 정합성을 보장할 수 있다.
    - `POST _flush/synced`
  - 업그레이드 된 노드가 기존 클러스터에 정상적으로 합류했는지 확인한다.
  - 비활성화 해 놓은 샤드 할당 기능을 다시 활성화한다.
    - `cluster.routing.allocation.enable: null`

### 6.2 샤드 배치 방식 변경

- ES는 자동으로 샤드를 배치하지만 경우에 따라 샤드 배치 방식을 변경해야 할 때가 있다. 예를 들어 특정 노드에 장애가 발생하여 unassigned 샤드들에 대한 재할당 작업이 5회 이상 실패할 경우, 일정 기간이 지난 오래된 인덱스의 샤드를 특정 노드에 강제로 배치하는 경우에 속한다.
- 샤드의 배치 방식을 변경하는 방법은 아래와 같다.
  - reroute: 샤드 하나하나를 특정 노드에 배치
  - allocation: 클러스터 전체의 샤드 배치 방식을 변경
  - rebalance: 클러스터 전체의 샤드 재분배 방식 변경
  - filtering: 특정 조건에 해당하는 샤드들을 특정 노드에 배치
- 구체적인 방법들은 필요할 때 살펴본다.

### 6.3 클러스터와 인덱스의 설정 변경

- 클러스터의 설정 변경은 cluster/settings API를 통해 변경할 수 있다.
- 클러스터의 적용된 설정을 확인하는 방법은 아래와 같다.
  - `GET _cluster/settings`

### 정리

- ES 클러스터 운영 중 중단 없이 버전 업그레이드를 하려면 Rolling Restart 방식을 사용하면 된다.
- 클러스터 API를 통해 샤드의 배치 방식을 변경할 수 있으며 reroute, allocation, filtering 등의 방법을 사용할 수 있다.
- 인덱스 API를 통해 인덱스의 다양한 설정값을 변경할 수 있으며 템플릿 API를 통해 인덱스가 생성될 때 기본으로 적용되는 설정값을 변경할 수 있다.

## 7. 클러스터 성능 모니터링과 최적화

- 응답 값에 대한 지표 설명은 필요할 때 찾아 읽어본다.

### 7.1 클러스터 상태 확인

- ES는 cat API를 통해 클러스터/노드/샤드의 상태 등 다양한 정보를 확인할 수 있다.
  - `GET _cat/health?format=json&pretty`
  - 응답 중 status는 상태를 의미하는데 아래와 같이 분류된다.
    - green: 모든 샤드가 정상동작
    - yellow: 모든 프라이머리 샤드는 정상 동작하고 있으나 일부/모든 레플리카 샤드가 정상적으로 동작하지 않음
    - red: 일부/모든 프라이머리 샤드/레플리카 샤드가 정상 동작하지 않음

### 7.2 노드의 상태 확인

- 클러스터를 구성하는 노드의 개수와 각 노드의 역할과 부하 상태를 확인할 수 있다.
  - `_cat/nodes?v`

### 7.3 인덱스의 상태와 정보 확인

- 인덱스의 상태로 클러스터와 같이 green, yellow, red로 표현된다. 의미 또한 클러스터의 상태값과 동일하다.
  - `_cat/indices`

### 7.4 샤드의 상태 확인

- `_cat/shards`

### 7.5 stats API로 지표 확인

- `_cluster/stats`

## 8. 분석 엔진으로 활용하기

### 8.1 Elastic Stack 이란

- Elastic Stack은 로그를 수집, 가공하고 이를 바탕으로 분석하는데 사용되는 플랫폼을 의미한다.
- ELK Stack 으로도 불리는데 로그를 전송하는 Filebeat, 전송된 로그를 JSON 문서로 파싱하는 Logstash, 파싱된 문서를 저장하는 ElasticSearch, 데이터를 시각화하는 Kibana 이렇게 4개의 시스템으로 구성된다.
- 각 시스템을 설치하는 방법이나 kibana에서 로그를 조회하고 시각화하는 방법을 다룬다. 필요할떄 학습한다.

## 9. 검색 엔진으로 활용하기

- ES는 Elastic Stack에 포함되어 로그 분석과 시각화 도구로도 많이 사용되지만 검색 엔진으로도 많이 활용된다.

### 9.1 inverted index란

- "I am a boy" 라는 문자열을 가진 문서가 있다고 가정해보자. 이 문자열을 공백을 기준으로 `i`, `am`, `a`, `boy` 라는 4개의 토큰으로 만들어진다. 그리고 아래와 같은 형태로 저장되는데 이것을 inverted index라고 부른다.

  ```text
    Tokens   Documents
       i       1
       am      1,2
       a       3,4
       boy     2
  ```

- 아래와 같이 API를 수행하여 어떻게 토큰이 생성되는지 확인할 수 있다.

  ```Elixir
    POST _analyze
    {
      "analyzer": "standard",
      "text": "I am a boyyyy"
    }
  ```

### 9.2 analyer 살펴보기

- 데이터가 token으로 구분될 때 아래와 같은 과정을 거치게 된다.
  - 문자열 -> character filter -> tokenizer -> token filter -> tokens
- 먼저 character filter는 문자열들을 1차로 변경한다. 특수 문자나 HTML 태그를 제거하는 과정을 통해 변경된 문자열은 tokenizer를 통해 n개의 토큰으로 나뉜다. 그 후 token filter가 토큰에 대해 다시 한 번 변형을 가한다. 예시로 토큰을 전부 소문자로 바꾸는 lowercase token filter가 대표적인 token filter이다.

### 9.3 analyer와 검색의 관계

- analyer를 통해 생성된 토큰들이 역인덱스에 저장되고, 검색할때는 역인덱스에 저장된 값을 바탕으로 문서를 찾는다. 따라서 검색 니즈를 잘 파악해서 적합한 analyze를 설정해야 한다.
- 필드에 text 타입과 keyword 타입으로 정의하면 검색 결과가 달라질 수 있는데 text 타입은 기본적으로 standard analyze를 사용하고 keyword 타입은 keyword analyze를 사용한다.

  ```Elixir
    POST _analyze
    {
      "analyzer": "keyword",
      "text": "I am a boy"
    }

    # 결과
    {
      "tokens": [
        {
          "token": "I am a boy",
          "start_offset": 0,
          "end_offset": 10,
          "type": "word",
          "position": 0
        }
      ]
    }
  ```

- standard analyze와 다르게 문자열을 나누지 않기 때문에 특정 단어로 검색하면 검색결과가 나오지 않게 된다.

### 9.4 Search API

- search API는 간단한 URI Search 형태로 제공하고 Request Body 작성도 제공한다.

  ```Elixir
    # 간단 검색
    GET test_data/_search
    {
      "query": { "term": { "title": "book" } }
    }

    # from/size를 활용
    GET test_data/_search
    {
      "from": 0,
      "size": 3,
      "query": { "term": { "title": "book" } }
    }

    # source 옵션으로 특정 필드만 조회
    GET test_data/_search
    {
      "_source": ["title", "description"],
      "query": { "term": { "title": "book" } }
    }
  ```

- from/size는 페이지네이션 하는 동안 새로운 문서가 유입되면 기존 검색 결과에 영향을 줄 수 있지만 scroll 옵션은 검색 시점의 스냅샷을 활용하기 때문에 페이지네이션이나 대량의 배치 작업에 활용된다.

### 9.5 Query DSL 이란

- search API에서 중요한 부분을 담당하는 검색 쿼리를 살펴보자. 검색 쿼리는 Query DSL이라 불리며 크게 Query Context와 Filter Context로 분류한다. Query Context는 Full Text Search라고도 불리며 전문검색에 활용된다. Filter Context는 검색어가 문서에 존재하는지 여부를 검사한다. 예를 들어 남자인지 여자인지 검색하는 경우가 Filter Context에 속한다.
