# 엘라스틱서치 바이블

- [책 링크](https://www.yes24.com/Product/Goods/119719070)

## 1. ES 소개

- 데이터를 시각화하는 **키바나**와 ES에 색인할 데이터를 수집하고 변환하는 **로그 스태시**. 이를 합쳐서 **ELK 스택**이라 부른다.
- ES의 기본 컨셉
  - **검색 엔진**: ES는 기본적으로 검색 엔진으로 역색인을 사용하여 검색 속도가 빠르고 형태소 분석, 전문 검색이 가능하다.
  - **분산처리**: 데이터를 여러 노드에 분산 저장하며 검색이나 집계 작업을 수행할 수 있다.
  - **고가용성**: 클러스터를 구성하는 일부 노드에 장애가 발생해도 복제를 이용해 중단 없이 서비스를 지속할 수 있다.
  - **수평적 확장성**
  - **JSON 기반 REST API 제공**: ES는 JSON 형태의 문서를 저장, 색인, 검색하고 REST API를 사용한다.
  - **데이터 안정성**: 데이터 색인 요청후 200 OK 응답을 받았드면 그 데이터는 디스크에 저장됨을 보장한다.
  - **준실시간 검색**: ES가 역색인을 구성하고 검색이 가능해지기 까지 시간이 걸린다. 기본 설정은 1초 정도 걸리는데 이런 특성을 이해하고 있어야 한다.
  - **트랜잭션 지원되지 않음**: RDBMS와 달리 트랜잭션을 지원하지 않는다.
  - **조인 지원하지 않음**: ES는 기본적으로 조인을 염두에 두고 설계되지 않았다.

## 2. ES 기본 동작과 구조

### ES 기본 동작

- kibana의 `[dev tools]`에 들어가 간단한 API를 확인해본다.

  ```Elixir
  # 인덱스 이름이 my_index에 1번 문서를 색인
  PUT my_index/_doc/1
  {
    "title": "제목",
    "views": 10
  }

  # _id 지정없이 인덱스 색인 (ES가 _id를 자동 생성)
  POST my_index/_doc
  {
    "title": "제목",
    "views": 10
  }

  # 1번 문서 조회
  GET my_index/_doc/1

  # 문서 업데이트
  POST my_index/_update/1
  {
    "doc": {
      "title": "업데이트 된 제목"
    }
  }

  # 문서 삭제
  DELETE my_index/_doc/1
  ```

- ES는 쿼리 전용 DSL을 제공한다. `_search`를 붙여 GET 메서드를 사용한다.

  ```elixir
    GET my_index/_search
    {
      "query": {
        "match": {
          "title": "world"
        }
      }
    }
  ```

- 위에 대한 결과는 아래와 같은데 문서가 2개 검색되었고 `_score`에서 유사도 점수를 확인할 수 있다. 전통적인 RDBMS와는 동작방식이 상당히 다른걸 알 수 있다.

  ```elixir
    {
      "took": 12,
      "timed_out": false,
      "_shards": {
        "total": 1,
        "successful": 1,
        "skipped": 0,
        "failed": 0
      },
      "hits": {
        "total": {
          "value": 2,
          "relation": "eq"
        },
        "max_score": 0.13353139,
        "hits": [
          {
            "_index": "my_index",
            "_id": "O3D7VIsBd1YI2lqiQb6F",
            "_score": 0.13353139,
            "_source": {
              "title": "hello world",
              "views": 1234,
              "public": true
            }
          },
          {
            "_index": "my_index",
            "_id": "1",
            "_score": 0.13353139,
            "_source": {
              "title": "high world",
              "views": 1234,
              "public": true
            }
          }
        ]
      }
    }
  ```

### ES 구조

- ES 기본 구조와 용어를 살펴보자
  - **문서**: ES가 저장하고 색인하는 json 문서
  - **인덱스**: 문서를 모아 놓은 단위
  - **샤드**: 인덱스는 그 내용이 여러 샤드로 분산 저장된다. 원본 역할을 담당하는 주 샤드와 복제본 샤드가 있다.
  - **\_id**: 인덱스 내 문서에 부여되는 고유한 구분자.
  - **노드**: ES 프로세스 하나가 노드를 구성한다.
    - **데이터 노드**: 샤드를 보유하고 샤드에 읽기/쓰기 작업을 수행
    - **마스터 노드**: 클러스터를 관리하는 역할을 하는 노드
  - **클러스터**: ES 노드가 여러개 모여 하나의 클러스터를 구성

### ES 내부 구조와 루씬

- ES는 문서를 색인하고 검색하는 `아파치 루씬`을 코어 라이브러리로 사용한다.
- **루씬 flush**
  - 문서의 색인 요청이 들어오면 루씬은 역색인을 생성한다. 최초 생성은 메모리 버퍼에 들어가며 주기적으로 디스크에 flush한다.
  - 루씬은 파일을 연 시점에 색인이 완료된 문서만 검색할 수 있고, 이후 변경사항이 발생하고 검색하고 싶으면 파일을 새로 열어야 한다.
  - 루씬이 **파일을 열고 변경사항이 적용된 새로운 인덱스를 얻는데** 이를 ES에서 **`refresh`** 라고 부른다.
- **루씬 commit**
  - 루씬의 **`flush는`** OS Page Cache에 데이터를 넘겨주는 것을 보장하지만 디스크에 파일이 기록되는 것을 보장하지는 않는다.
  - 따라서 루씬은 주기적으로 commit을 통해 Page Cache와 디스크의 싱크를 맞추며 ES의 flush 작업은 내부적으로 루씬의 commit 과정을 거친다.
  - ES의 **flush는 refresh 보다 훨씬 비용이 드는 작업**이다. 따라서 refresh와 마찬가지로 적절한 주기로 수행된다.
- **세그먼트**
  - 디스크에 기록된 파일들이 모이면 **세그먼트**라는 단위가 된다. 이 세그먼트가 루씬의 검색 대상이다.
  - 새로운 문서가 들어오면 새 세그먼트가 생성되고 문서가 삭제되면 삭제 플래그만 표시해둔다. 불변인 세그먼트를 무작정 늘릴 수 없기에 루씬은 중간에 적당히 세그먼트의 병합을 수행한다. 이 과정에서 삭제 플래그가 표시된 데이터를 실제로 삭제하기도 한다.
  - 세그먼트 병합은 비싼 작업이지만 병합 후에 검색 성능의 향상을 기대할 수 있다. 다만 명시적인 세그먼트 병합은 추가 데이터 색인이 없는게 보장될 때 수행되어야 한다.
- **루씬 인덱스와 ES 인덱스**
  - 여러 세그먼트가 모이면 하나의 루씬 인덱스가 되어 검색이 가능하다. ES 샤드는 루씬의 인덱스 하나를 래핑한 개념이다.
  - ES 샤드가 여러 개 모이면 ES 인덱스가 된다. ES에서는 여러 샤드에 있는 문서를 모두 검색할 수 있다.
- **translog**
  - ES에 색인된 문서는 루씬 commit까지 완료되어야 디스크에 안전하게 기록되지만 **모든 요청에 대해 루신 commit을 하는 작업은 비싸다.** 그렇다고 주기적으로 commit하면 장애가 발생할 때 데이터 유실의 우려가 있기 때문에 **ES 샤드는 모든 작업마다 translog에 로그를 기록**한다.
  - **translog는 색인, 삭제 작업이 수행된 직후에 기록되고** ES는 장애가 발생한 뒤 샤드 복구 단계에서 translog를 읽어 유실된 데이터를 복구한다.
  - 이 translog가 커지면 샤드 복구에 시간이 오래 걸리기 때문에 translog의 크기를 적절히 유지해 줄 필요가 있다. 참고로 ES flush는 루씬의 commit을 수행하고 새로운 translog를 만드는 작업이다. ES flush는 백그라운드에서 주기적으로 수행되며 translog의 크기를 적절한 수준으로 유지한다.

## 3. 인덱스 설계

### 3.1 인덱스 설정

- **인덱스 설정 조회**

  ```elixir
    GET my_index/_settings

    // 응답
    {
    "my_index": {
      "settings": {
        "index": {
          "routing": {
            "allocation": {
              "include": {
                "_tier_preference": "data_content"
              }
            }
          },
          "number_of_shards": "1",
          "provided_name": "my_index",
          "creation_date": "1697937794587",
          "number_of_replicas": "1",
          "uuid": "AtAfbz1tROSfK4310S17AQ",
          "version": {
            "created": "8040299"
          }
        }
      }
    }
  }
  ```

- **존재하지 않는 인덱스에 문서 색인** 요청을 하면 ES는 인덱스를 **자동으로 생성**한다. 자동 생성된 인덱스가 어떤 기본값을 가지는지 알아보자.

  - **number_of_shards**
    - 인덱스가 데이터를 몇 개의 샤드로 쪼갤 것인지 지정하는 값이다. 한 번 지정하면 reindex 동작을 통해 인덱스를 통째로 색인하는 작업을 수행하지 않는 한 바꿀수 없다.
    - **샤드 개수를 어떻게 지정하느냐는 ES 전체의 성능**에도 큰 영향을 미친다. 클러스터에 샤드 숫자가 너무 많으면 색인 성능이 감소한다. 반대로 인덱스당 샤드 숫자를 적게 지정하면 샤드 하나의 크기가 너무 커진다. 샤드 하나의 크기가 크면 샤드 복구에 너무 많은 시간이 소요된다.
  - **number_of_replicas**

    - 주 샤드 하나당 복제본 샤드를 몇 개 둘 것인지 설장한다. 인덱스 생성 후에도 동적으로 변경이 가능하다.
    - 아래와 같이 **0으로 지정하면 복제본 샤드 없이 주 샤드**만 둔다.

    ```elixir
      PUT my_index/_setting
      {
        "index.number_of_replicas": 0
      }
    ```

  - **refresh_interval**

    - ES가 인덱스를 대상으로 refresh를 얼마나 자주 수행할지 지정한다. 인덱스에 색인된 문서는 refresh 되어야 검색 대상이 되기 때문에 중요한 설정이다. 아래와 같이 값을 지정할 수 있다.

    ```elixir
      PUT my_index/_setting
      {
        "index.refresh_interval": "1s"
      }
    ```

    - 값을 **-1로 지정하면 refresh를 수행하지 않는다**. 기본 값은 1초 마다 refresh를 수행하며 30초 이상 검색 쿼리가 들어오지 않으면 검색 쿼리가 들어올 때까지 refresh를 수행하지 않는다. 이 대기시간은 `index.search.idle.after` 설정으로 변경이 가능하며 `index.refresh_interval` 값을 null로 업데이트 하면 인덱스를 refresh_interval 값을 설정하지 않은 상태로 업데이트 할 수 있다.

- 위에서 사용한 my_index는 문서 색인 요청을 통해 자동으로 생성한 인덱스다. 이렇게 생성되면 **인덱스 설정이 모두 기본값으로 지정되기 때문에 실제 운영 환경에선 적절하지 않다.** 인덱스를 수동으로 생성/삭제 하는 방법을 알아보자.

  ```elixir
    // 인덱스 수동 생성
    PUT my_index
    {
      "settings": {
        "number_of_shards": 2,
        "number_of_replicas": 2
      }
    }

    // 인덱스 삭제
    DELETE my_index
  ```

### 3.2 매핑과 필드 타입

- **매핑**은 문서가 인덱스에 어떻게 색인되고 저장되는지 정의하는 부분이다.
- 아래와 같이 문서가 색인될 때 기존에 매핑 정보를 가지고 있지 않던 새로운 필드가 들어오면 ES는 자동으로 문서의 필드 타입을 지정해서 매핑 정보를 생성한다.

  ```elixir
    // 문서 색인
    PUT my_index2/_doc/1
    {
      "title": "hello world",
      "views": 1234,
      "public": true,
      "point": 4.5,
      "created": "2019-01-17T14:05:01.234Z"
    }

    // 응답
    {
    "my_index2": {
      "aliases": {},
      "mappings": {
        "properties": {
          "created": {
            "type": "date"
          },
          "point": {
            "type": "float"
          },
          "public": {
            "type": "boolean"
          },
          "title": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword",
                "ignore_above": 256
              }
            }
          },
          "views": {
            "type": "long"
          }
        }
      },
      "settings": {...}
    }
  }
  ```

#### 동적 매핑 vs 명시적 매핑

- ES가 자동 생성하는 매핑을 **동적 매핑**이라고 하고 사용자가 직접 매핑을 지정해 주는 방법을 **명시적 매핑**이라고 부른다.
- 아래와 같이 인덱스를 생성할 때 직접 매핑 정보를 지정할 수 있다.

  ```elixir
  mapping_test
  {
    "mappings": {
      "properties": {
        "createdDate": {
          "type": "date",
          "format": "strict_date_time || epoch_millis"
        },
        "keywordString": {
          "type": "keyword"
        },
        "textString": {
          "type": "text"
        }
      }
    },
    "settings": {
      "number_of_replicas": 1,
      "number_of_shards": 1
    }
  }
  ```

- 중요한 점은 필드 타입을 포함한 **매핑설정은 한 번 지정되면 변경이 불가능**하다는 점이다. 따라서 서비스 설계와 데이터 설계를 할 때는 매우 신중해야 한다. 서비스 운영 환경에서 대용량의 데이터를 처리해야 할 때는 명시적 매핑을 지정해서 인덱스를 운영해야 한다. 매핑을 어떻게 지정하냐에 따라 성능의 차이도 크다. 동적 매핑은 유연한 운영을 가능하게 해 주지만 그럼에도 명시적으로 매핑을 지정하는 것이 좋다.
- 이미 인덱스가 생성된 경우에도 매핑 정보를 아래와 같이 추가할 수 있다.

  ```elixir
    PUT mapping_test/_mapping
    {
      "properties": {
        "longValue": {
          "type": "long"
        }
      }
    }
  ```

#### 필드 타입

- ES 필드 타입은 크게 아래와 같이 분류할 수 있다.

  - **심플 타입**: text, keyword, date, long, boolean 등
  - **계층 구조를 지원하는 타입**: object, nested 등
  - **특수 타입**: get_point, get_shape 등

- 배열

  - ES는 **배열을 표현하는 별도의 타입이 없다**. long 타입 필드는 단일 숫자를 넣을수도 [1,2,3] 같은 배열 데이터도 넣을 수 있다. 아래와 같이 인덱스를 생성해 테스트한다.

  ```elixir
    // 인덱스 생성
    PUT array_test
    {
      "mappings": {
        "properties": {
          "longField": {
            "type": "long"
          },
          "keywordField": {
            "type": "keyword"
          }
        }
      }
    }

    // 1번 문서 추가
    PUT array_test/_doc/1
    {
      "longField": 309,
      "keywordField": ["hello", "world"]
    }

    // 2번 문서 추가
    PUT array_test/_doc/2
    {
      "longField": [221, 309, 999],
      "keywordField": "hello"
    }

    // 309로 조회하면 1,2번 문서 모두 조회됨
    GET array_test/_search
    {
      "query": {
        "term": {
          "longField": 309
        }
      }
    }
  ```

  - ES는 색인 과정에서 데이터가 단일인지 배열인지 상관없이 독립적인 역색인을 구성하기 때문에 위 결과처럼 둘다 검색된다.

- 계층 구조를 지원하는 타입
  - 계층 구조를 담는 데이터로 **`object와 nested`** 가 있는데 이 둘은 배열을 처리할 때의 동작이 다르다.
  - **object**는 일반적인 계층 구조에 사용하고 가볍고 일반 쿼리를 사용한다.
  - **nested**는 배열 각 객체를 독립적으로 취급해야 하는 특수 상황에서 사용하며 무겁고 전용 nested 쿼리를 사용해야 한다.

#### text 타입과 keyword 타입

- text로 지정된 필드 값은 문자열 그대로 역색인을 구성하지 않고 애널라이저가 값을 분석해서 여러 토큰으로 쪼갠 후 역색인을 구성한다. **쪼개진 토큰이 최종적으로 역색인데 들어가는 형태를 term**(텀) 이라고 한다. keyword로 지정된 필드는 값 그대로 역색인을 한다.
- 아래 쿼리에서 차이점을 비교해보자.

  ```elixir
  PUT mapping_test/_doc/3
  {
    "keywordString": "Hello, World!",
    "textString": "Hello, World!"
  }

  // 검색 결과 있음
  GET mapping_test/_search
  {
    "query": {
      "match": {
        "textString": "hello"
      }
    }
  }

  // 검색 결과 없음
  GET mapping_test/_search
  {
    "query": {
      "match": {
        "keywordString": "hello"
      }
    }
  }
  ```

- 위 쿼리에서 text 필드는 `Hello, World!` 문자열이 hello 문자열 텀과 world 문자열 텀으로 쪼개져 찾을 수 있지만 keyword 필드는 `Hello, World!` 전체를 넣어야 검색할 수 있다.
- 색인 방식의 차이로 **text 타입은 주로 전문 검색**에 적합하고 **keyword 타입은 일치 검색**에 적합하다. 또한 정렬과 집계의 대상이 될 필드는 keyword 타입을 쓰는게 좋다. keyword 타입은 기본적으로 doc_values 캐시를 사용하기 때문이다.

#### doc_values

- ES의 검색은 역색인을 기반으로 한 색인을 이용한다. 그러나 정렬, 집계 작업에서 doc_values를 사용해 효율적으로 작업을
  할 수 있다. ES는 text 타입을 제외한 거의 모든 필드 타입이 doc_values를 지원하며 정렬, 집계 작업을 할 필요가 없는 필드는 매핑을 지정시 false로 전달하면 끌 수 있다.

#### fielddata

- text 타입은 doc_values 캐시를 사용할 수 없어 fielddata 캐시를 이용하는데 OOM 문제를 야기할 수 있어 기본적으로 비활성화 상태이다.

#### source

- `_source` 필드는 문서 색인 시점에 ES에 전달된 원본 JSON 문서를 저장하는 메타데이터 필드다.
- `_source` 필드는 JSON 문서를 통째로 담기 때문에 디스크를 많이 사용하지만 비활성화 할 경우 reindex를 사용할 수 없기 때문에 활성화 상태로 유지해야 한다.

#### index

- index 속성은 해당 필드의 역색인을 만들 것인지 지정하며 기본값은 true다. false로 설정하면 검색 대상이 되진 않지만 다른 필드로 검색된 필드에 문서가 검색되면 검색 결과에 포함된다.

### 3.3 애널라이저와 토크나이저

- **애널라이저**는 `캐릭터 필터와 토크나이저, 토큰 필터`로 구성된다. 애널라이저는 입력된 텍스트에 캐릭터 필터를 적용하여 문자열로 변형시킨 뒤 토크나이저를 적용해 여러 토큰으로 조깬다. 쪼개진 토큰에 토큰 필터를 적용해 변형을 가한 결과가 최종적으로 분석 완료된 텀이 된다.

#### 토크나이저

- **standard 토크나이저**
  - 기본 토크나이저로 대부분의 문장 부호가 사라진다.
- **keyword 토크나이저**
  - 들어온 텍스트를 쪼개지 않고 그대로 내보낸다.
- **ngram 토크나이저**

  - 텍스트를 min_gram 이상, max_gram 이하의 단위로 쪼갠다. 주로 **RBMS의 like 검색을 구현**하거나 자동 완성 서비스를 구현하고 싶을 때 주로 활용된다.

  ```elixir
    POST _analyze
    {
      "tokenizer": {
        "type": "ngram",
        "min_gram": 3,
        "max_gram": 4
      },
      "text": "Hello, World!"
    }
  ```

- **edge_ngram 토크나이저**
  - ngram과 다르게 토큰의 시작 글자를 단어의 시작 글자로 고정시켜 생성한다.

#### 토큰 필터

- 토큰 필터는 쪼개진 토큰을 추가, 변경, 삭제 한다. 아래는 내장 토큰 필터의 일부이다.
  - **lowercase / uppercase**: 토큰의 내용을 소문자/대문자로 변환
  - **stop 토큰 필터**: 불용어를 지정하여 제거 (ex: the, a, an, in)
  - **pattern_replace**: 정규식을 사용해 토큰 내용 치환
  - **trim**: 토큰의 전후에 위치한 공백 문자를 제거
  - **truncate**: 지정한 길이로 토큰을 자른다.

```elixir
  POST _analyze
  {
    "filter": [ "lowercase" ],
    "text": "Hello, World!"
  }
```

#### 플러그인 설치를 통한 애널라이저 추가화 한국의 형태소 분석

- 한국의 형태소 분석을 지원하는 기본 내장 애널라이저는 없다. 하지만 **ES가 공식 제공하는 nori 플러그인**을 설치하면 한국어를 분석할 수 있다. 아래와 같이 플러그인을 설치할 수 있다.

  ```text
    bin/elasticsearch-plugin install analysis-nori
  ```

- 플러그인을 설치할 때는 클러스터를 구성하는 모든 노드에 설치해야 한다. 즉 모든 노드에 위 명령어를 수행해야 한다.
- 플러그인을 설치하면 ES를 재기동해야 하고 아래와 같이 nori 플러그인을 테스트 할 수 있다.

  ```elixir
    POST _analyze
    {
      "analyzer": "nori",
      "text": "우리는 컴퓨터를 다룬다"
    }

    // 응답
    {
      "tokens": [
        {
          "token": "우리",
          "start_offset": 0,
          "end_offset": 2,
          "type": "word",
          "position": 0
        },
        {
          "token": "컴퓨터",
          "start_offset": 4,
          "end_offset": 7,
          "type": "word",
          "position": 2
        },
        {
          "token": "다루",
          "start_offset": 9,
          "end_offset": 12,
          "type": "word",
          "position": 4
        }
      ]
    }
  ```

### 3.4 템플릿

- ES를 실무에서 운영하다 보면 유사한 인덱스를 계속 생성할 때가 많은데 **템플릿을 사전에 정의하여 인덱스를 생성하는 방법**을 알아보자.

#### 인덱스 템플릿

- **`index_patterns`은** 인덱스 패턴을 지정한다. 아래와 같이 인덱스 템플릿을 생성한 후, 새로 생성되는 인덱스의 이름이 pattern_test_index 형태라면 이 템플릿에 맞춰 인덱스가 생성된다.

  ```elixir
    PUT _index_template/my_template
    {
      "index_patterns": ["pattern_test_index-*"],
      "priority": 1,
      "template": {
        "settings": {
          "number_of_shards": 2,
          "number_of_replicas": 2
        }
      }
    }
  ```

#### 컴포넌트 템플릿

- 템플릿 간 중복되는 부분을 재사용할 수 있도록 쪼갠것이 **컴포넌트 템플릿**이다.

  ```elixir
    PUT _component_template/timestamps_mappings
    {
      "template": {
        "mappings": {
          "properties": {
            "timestamp": {
              "type": "date"
            }
          }
        }
      }
    }

    PUT _component_template/my_shard_settings
    {
      "template": {
        "settings": {
          "number_of_shards": 2,
          "number_of_replicas": 2
        }
      }
    }

    PUT _index_template/my_template2
    {
      "index_patterns": ["timestamp_index-*"],
      "composed_of": ["timestamps_mappings", "my_shard_settings"]
    }
  ```

#### 동적 템플릿

- 동적 템플릿은 **인덱스에 새로 들어온 필드의 매핑을 사전에 정의한대로 동적 생성**하는 기능이다.
- 동적 템플릿은 인덱스 템플릿과는 다르게 매핑 안에 정의한다. 아래 예시를 살펴보자.

```elixir
  PUT _index_template/dynamic_mapping_template
  {
    "index_patterns": ["dynamic_mapping*"],
    "priority": 1,
    "template": {
      "settings": {
        "number_of_shards": 2,
        "number_of_replicas": 2
      },
      "mappings": {
        "dynamic_templates": [
          {
            "my_text": {
              "match_mapping_type": "string",
              "match": "*_text",
              "mapping": {
                "type": "text"
              }
            },
            "my_keyword": {
              "match_mapping_type": "string",
              "match": "*_keyword",
              "mapping": {
                "type": "keyword"
              }
            }
          }
        ]
      }
    }
  }
```

#### 라우팅

- 라우팅은 ES가 **인덱스를 구성하는 샤드 중 몇 번 샤드를 대상으로 작업할지 지정**하기 위해 사용하는 값이다.
- ES에서 검색할 때 라우팅 값을 기입하지 않으면 전체 샤드를 대상으로 검색을 수행하고, 라우팅 값을 명시하면 단일 샤드를 대상으로 검색한다. 많은 데이터가 저장된 운영 환경에서 복잡한 쿼리를 수행할 때 라우팅 값을 지정 유무에 따라 성능의 차이가 날 수 있다.
- `_search` API를 호출하면 라우팅 값을 지정하더라도 전체 샤드를 검색한다.

```elixir
  // 5개 샤드를 가진 인덱스 생성
  PUT routing_test
  {
    "settings": {
        "number_of_shards": 5,
        "number_of_replicas": 1
      }
  }

  PUT routing_test/_doc/1?routing=myid
  {
    "login_id": "myid"
  }
```

## 4. 데이터 다루기

### 4.1 단건 문서 API

- **색인 API**
  - 문서 단건을 색인한다. PUT, POST 메서드에 `_doc, _create`를 지정해 호출할 수 있다.
    - PUT [인덱스 이름]/\_doc/[_id값]
    - POST [인덱스 이름]/\_doc
    - PUT [인덱스 이름]/\_create/[_id값]
    - POST [인덱스 이름]/\_create/[_id값]
  - `_doc, _create` 차이는 PUT으로 `_create`를 사용하면 새로 추가만 가능하고 기존에 id가 있으면 실패한다.
  - **refresh**
    - 색인 시, **refresh 매개 변수를 지정하면** 문서를 색인한 직후에 해당 샤드를 refresh 해서 즉시 검색 가능하게 만들것인지 지정할 수 있다. 매개변수에는 다음과 같은 3개의 옵션을 지정할 수 있다.
      - **true**: 색인 직후 문서가 색인된 샤드를 refresh하고 응답을 반환
      - **wait_for**: 색인 이후 문서가 refresh 될 때까지 기다리고 응답을 반환한다. true와 달리 refresh를 직접 유발하지 않는다.
      - **false**: 기본 값으로 refresh와 관련된 동작을 수행하지 않는다.
    - 색인 직후 검색 결과에 최신 변경 내용이 포함되어야 하는 비니지스 요구사항이 있을 때 refresh 값 지정을 고려해볼 수 있다. 그러나 **refresh는 비용이 큰 작업**이므로 매번 refresh를 true로 지정하면 전체 클러스터 성능이 저하될 수 있다.
    - 기본적으로 문서 색인 요청의 결과가 검색 역색인에 **즉시 동기적으로 반영되어야 하는 요청은 많지 않도록 서비스를 설계**하는 것이 바람직하다.
- **조회 API**
  - 문서 단건을 조회하는 API로 검색과 달리 색인이 refresh 되지 않은 상태에서 변경된 내용을 확인할 수 있다. **고유 식별자를 지정해서 단건 문서를 조회하는 것은 역색인을 사용할 필요가 없다**.
    - GET [인덱스 이름]/\_doc/[_id값]
    - GET [인덱스 이름]/\_source/[_id값]
  - 기본적으로 doc을 이용하여 인덱스, 메타데이터를 함께 조회한다. 메타데이터 없이 문서의 본문만을 원한다면 source를 지정해 호출할 수 있다.
- **업데이트 API**

  - 지정한 문서를 업데이트하며 **기본적으로 부분 업데이트**로 동작한다. 문서 전체를 교체하려면 색인 API를 사용해야 한다.
    - **`POST [인덱스 이름]/_update/[_id값]`**
  - **ES 업데이트 작업은 내부적으로** 기존 문서를 수정하는 것이 아니라 기존 문서의 내용을 조회한 뒤 부분 업데이트 될 내용을 합쳐 **새 문서를 만들어 색인하는 형태**로 진행된다.

    ```elixir
      PUT update_test/_doc/1
      {
        "title": "hello world",
        "views": 10
      }

      POST update_test/_update/1
      {
        "doc": {
          "views": 20
        }
      }
    ```

  - ES는 **업데이트를 수행하기 전에 업데이트가 필요한지 판단한다**. 즉 views를 20으로 업데이트 요청했는데 값이 이미 20이라면 업데이트 작업을 수행하지 않는다. 이 경우 응답결과에 noop이 포함된다.

  ```elixir
  {
    "_index": "update_test",
    "_id": "1",
    "_version": 2,
    "result": "noop", // 값이 동일해 업데이트 되지 않은 경우
    .
    .
  }
  ```

  - **doc_as_upsert**

    - 업데이트 API는 기존 문서를 읽은 후 업데이트를 수행하므로 문서가 없다면 요청은 실패한다.
    - **upsert가** 필요하다면 **`doc_as_upsert`** 옵션을 true로 지정해주면 된다.

    ```elixir
      POST update_test/_update/1
      {
        "doc": {
          "views": 20
        },
        "doc_as_upsert": true
      }
    ```

  - **script를 이용한 업데이트**

    - 업데이트를 하는 다른 방법으로 별도의 스크립트 언어를 넣어 문서를 업데이트 할 수 있다. ES는 자체 스크립트 언어인 **painless를** 이용한다.

    ```elixir
      POST update_test/_update/1
      {
        "script": {
          "source": "ctx._source.views += params.amount",
          "lang": "painless",
          "params": {
            "amount": 1
          }
        }
      }
    ```

- 삭제 API
  - **`DELETE [인덱스 이름]/_doc/[_id 값]`**
  - 삭제한 문서는 되돌릴 수 없기 때문에 신중해야 한다. 또한 뒷 부분을 빼먹고 DELETE [인덱스 이름]으로 호출할 경우 인덱스 전체가 삭제되기 때문에 조심해야 한다.

### 4.2 복수 문서 API

#### bulk API

- bulk API는 요청 본문이 NDJSON(JSON을 줄바꿈 문자로 구분) 형태이다.
- `Content-Type` 헤더도 `application/x-ndjson을` 사용해야 한다.

  ```elixir
    POST _bulk
    {"index": { "_index": "bulk_test", "_id": 1}}
    {"field1": "value1"}
    {"index": { "_index": "bulk_test", "_id": 2}}
    {"field1": "value2"}
    {"delete": { "_index": "bulk_test", "_id": 3}}
    {"update": { "_index": "bulk_test", "_id": 1}}
    {"doc": { "field2": "value2"}}
  ```

- bulk API에 기술된 작업은 순서대로 수행된다는 보장이 없다. 조정 역할을 하는 노드가 요청의 내용을 보고 적절한 주 샤드로 요청을 넘겨준다. 여러개의 주 샤드로 넘어간 각 요청은 독자적으로 수행된다. 그러나 완전한 동일한 인덱스, `_id` 조합을 가진 요청은 동일한 주 샤드로 넘어간다.
- 네트워크 요청을 여러번 반복해서 호출해야 한다면 이를 묶어 한꺼번에 전송하는 것이 성능상 이득이다. ES도 **단건 문서 API를 여러번 호출하는 것보다 bulk API를 호출**하는게 월등히 빠르다.

#### multi get API

- id를 여럿 지정해 한 번에 조회하는 API다.

  - **`GET [인덱스 이름]/_mget`**

  ```elixir
    GET bulk_test/_mget
    {
      "ids": ["1", "2"]
    }
  ```

#### update by query

- **`POST [인덱스 이름]/_update_by_query`**
  - 단건 업데이트 API와 달리 doc을 이용한 업데이트를 지원하지 않고 script를 통한 업데이트만을 지원한다.
  - 위와 같이 호출하면 ES는 검색 조건에 맞는 문서를 찾아 일종의 스냅샷을 찍고 이후 각 문서마다 업데이트를 실시한다.
  - 여러 문서의 업데이트를 순차적으로 하는 도중 다른 작업으로 문서의 변경이 발생하면 update_by_query API는 전체 작업을 그만둘 수도 있고 다음 작업으로 넘어갈 수도 있다. 이를 `conflicts` 매개변수로 abort를 지정하면 작업중단, proceed를 지정하면 다름 작업으로 넘어간다. 기본 값은 abort이다.
  - **update by query를** 이용한 작업은 충돌이 나더라도 그때까지 업데이트 된 내용은 롤백되진 않으니 염두해 두어야 한다.
- 스로틀링

  - 적절한 스로틀링 적용을 통해 클러스터의 부하와 서비스 영향을 줄일 수 있다.

  ```elixir
    POST bulk_test/_update_by_query?scroll_size=1000&scroll=1m&requests_per_second=500
    {
      .
      .
    }
  ```

  - **scroll_size**
    - update_by_query는 업데이트 전 검색을 수행한다. 기본적으로 한 번의 검색 수행에 1000개의 문서를 가져와 업데이트를 수행하고 완료되면 다음 검색을 1001 ~ 2000번까지 문서를 1000개 가져온다. scroll_size는 이 값을 조정하는 설정이다.
  - **scroll**
    - update_by_query가 스냅샷을 찍을 때 이 내용을 얼마나 보존할지 지정하는 설정이다.
    - 즉 이 설정 값 동안 scroll_size 만큼의 작업처리가 가능해야 하므로 너무 작은 값을 설정하면 안된다.
  - **requests_per_second**
    - 초당 몇 개까지의 작업을 수행할지 지정한다. scroll_size가 1000이고 requests_per_second 값이 500이라면 ES는 2초마다 1000개를 업데이트 한다. 스로틀링 조정 값의 핵심은 scroll_size, requests_per_second 값이며 requests_per_second의 기본값은 -1로 스로틀링을 적용하지 않는 설정이다.

#### delete by query

- 검색 쿼리로 삭제할 대상을 지정한 뒤 삭제를 수행하는 작업이다.
  - **`POST [인덱스 이름]/_delete_by_query`**
- delete_by_query 역시 검색 조건에 맞는 문서를 찾아 스냅샷을 찍으며 삭제 중 문서 내용이 변경되면 conflicts 매개 변수를 사용하는 것, 스로틀링 역시 동일하다.

### 4.3 검색 API

#### 검색 대상 지정

- ES는 다양한 검색 쿼리를 제공한다. GET과 POST 무엇을 사용해도 동작은 동일하고 인덱스 이름을 지정하지 않으면 전체 인덱스에 대해 검색한다. 와일드 카드 문자(\*)와 콤마로 구분해 여러 인덱스를 지정하는 것도 가능하다.

```elixir
GET [인덱스 이름]/_search
POST [인덱스 이름]/_search
GET _search
POST _search

GET my_index-*,test*,mapping_test/_search
```

#### 쿼리 DSL 검색과 쿼리 문자열 검색

- 쿼리 DSL 검색

  ```elixir
    GET my_index/_search
    {
      "query": {
        "match": {
          "title": "hello"
        }
      }
    }
  ```

- 쿼리 문자열 검색
  - 루씬 쿼리 문자열을 지정하는 방법으로 간단한 요청을 하는 경우 사용된다.
  - `GET my_index/_search?q=title:hello`

#### match_all

- match_all 쿼리는 모든 문서를 매치하는 쿼리다. query를 비워두면 기본값으로 지정된다.

  ```elixir
    GET [인덱스 이름]/_search
    {
      "query": {
        "match_all": {}
      }
    }
  ```

#### match

- 필드의 내용이 질의어와 매치되는 문서를 찾는 쿼리다. **match 쿼리의 기본 동작은 OR로 동작**하기에 다음과 같이 operator를 and로 지정하면 모든 텀이 매치된 문서만 검색되도록 할 수 있다.

  ```elixir
  GET my_index/_search
  {
    "query": {
      "match": {
        "title": { // field name
          "query": "world",
          "operator": "and"
        }
      }
    }
  }
  ```

#### term 쿼리

- **term** 쿼리는 필드 값이 질의어와 **정확히 일치하는 문서**를 찾는 쿼리다.

  ```elixir
    GET my_index/_search
    {
      "query": {
        "term": {
          "title": { // field name
            "value": "world"
          }
        }
      }
    }
  ```

#### terms 쿼리

- 질의어를 여러개 지정할 수 있으며 하나 이상의 질의어와 일치하면 검색결과에 포함된다.

  ```elixir
    GET my_index/_search
    {
      "query": {
        "terms": {
          "title": ["hello", "world"]
        }
      }
    }
  ```

#### range 쿼리

- 필드의 값이 특정 범위 내에 있는 문서를 찾는 쿼리다.

  ```elixir
    GET my_index/_search
    {
      "query": {
        "range": {
          "views": {
            "gte": 10,
            "lt": 2000
          }
        }
      }
    }
  ```

- range 쿼리 대상 필드가 date 타입이면 간단한 날짜 시간 계산식도 사용할 수 있다.

  ```elixir
    GET my_index/_search
    {
      "query": {
        "range": {
          "dateField": {
            "gte": "2019-01-15T00:00:00.000Z||+36h/d",
            "lt": "now-3h/d"
          }
        }
      }
    }
  ```

  - now: 현재시간을 나타낸다.
  - ||: 날짜 시간 문자열의 마지막에 붙인다. 시간 계산식으로 파싱된다.
  - +와 -: 지정한 시간만큼 더하거나 빼는 연산을 수행
  - /: 버림을 수행. /d는 날짜 단위 이하의 시간을 버림한다.

#### exists 쿼리

- 지정한 필드를 포함한 문서를 검색한다.

  ```elixir
    GET my_index/_search
    {
      "query": {
        "exists": {
          "field": "title"
        }
      }
    }
  ```

#### 검색결과 정렬

- 요청 본문에 sort를 지정하면 검색 결과를 정렬할 수 있다. 정렬에 사용할 필드 이름과 종류를 지정하면 된다.

  ```elixir
    GET my_index/_search
    {
      "query": {..},
      "sort": [
        {
          "title": { "order": "desc"},
          "views": { "order": "desc"}
        }
      ]
    }
  ```

- ES 필드타입에는 정렬이 가능한 타입과 불가능한 타입이 있다. 숫자, date, boolean, keyword 타입은 정렬 대상이 될 수 있지만 text 타입은 정렬 대상이 될 수 없다.

#### 페이지네이션

- from과 사이즈

  - size는 limit 개념이고 from은 오프셋을 뜻한다.

    ```elixir
      GET my_index/_search
      {
        "query": {..},
        "from": 0,
        "size": 20
      }
    ```

  - from 값이 올라갈수록 CPU와 메모리 사용량을 크게 증가시키기 때문에 본격적인 페이지네이션을 해야 한다면 아래에서 소개할 scroll이나 search_after를 사용해야 한다.

- scroll

  - 검색 조건에 매칭되는 전체 문서를 순회할 때 적합하다.

    ```elixir
      GET my_index/_search?scroll=1m
      {
        "query": {..},
        "size": 20
      }
    ```

  - scroll은 서비스에서 지속적으로 호출하는 것을 의도한 기능이 아니다. 주료 대량의 데이터를 덤프하는 용도로 사용한다. 서비스에서 사용자가 지속적으로 호출하기 위한 페이지네이션 용도로는 search_after를 사용해야 한다.

- search_after

  - 페이지네이션에 가장 적합하며 sort를 지정해야 한다.

    ```elixir
      GET kibana_sample_data_ecommerce/_search
      {
        "size": 20,
        "query": {
          "term": {
            "currency": {
              "value": "ER"
            }
          }
        },
        "sort": [
          { "order_date": "desc" },
          { "order_id": "asc" }
        ]
      }
    ```

### 4.4 집계

#### 집계 기본

- 요청 본문에 aggs를 추가해서 작업한다. 과도한 집계는 성능에 영향을 줄 수 있는데 특히 키바나 대시보드를 구성하기 위한 시각화 그래프를 만들고 다수의 유저가 대시보드를 조회하면 순식간에 클러스터를 장애 상황에 빠드릴 수 있다. 따라서 **통제되지 않은 사용자에게는 키바나를 열지 말고** 키바나 대시보드의 위험성을 인지하고 있어야 한다.

#### 매트릭 집계

- **avg,max,min,max 집계**

  - 검색에 매칭된 문서의 필드 값을 가져온 뒤 각각 평균,최대,최소,합을 계산하여 반환한다.

  ```elixir
    GET kibana_sample_data_ecommerce/_search
    {
      "size": 0,
      "query": {
        "term": { "currency": { "value": "EUR" } } },
      "aggs": {
        "my-agg-name": {
          "avg": {
            "field": "taxless_total_price"
          }
        }
      }
    }
  ```

- **stats 집계**

  - 지정한 필드의 평균, 최대, 최소, 합, 개수를 모두 계산하여 반환한다.

    ```elixir
      GET kibana_sample_data_ecommerce/_search
      {
        "size": 0,
        "query": {
          "term": { "currency": { "value": "EUR" } } },
        "aggs": {
          "my-agg-name": {
            "stats": {
              "field": "taxless_total_price"
            }
          }
        }
      }
    ```

#### 버킷 집계

- **range 집계**

  ```elixir
    GET kibana_sample_data_ecommerce/_search
    {
      "size": 0,
      "query": { "match_all": {} },
      "aggs": {
        "my-agg-name": {
          "range": {
            "field": "DistanceKilometers",
            "ranges": [
              { "to": 5000 },
              { "from": 5000, "to": 10000 }
            ]
          }
        }
      }
    }
  ```

- **date_range 집계**

  - range 집계와 유사하나 data 타입필드를 사용하는 점, from과 to에 날짜 시간 계산식을 사용할 수 있다는 차이가 있다.

    ```elixir
      GET kibana_sample_data_ecommerce/_search
      {
        "size": 0,
        "query": { "match_all": {} },
        "aggs": {
          "my-agg-name": {
            "date_range": {
              "field": "order_date",
              "ranges": [
                { "to": "now-10d/d" },
                { "from": "now-10d/d", "to": "now" }
              ]
            }
          }
        }
      }
    ```

- **terms 집계**

  - 필드에 대해 가장 빈도수가 높은 term 순서대로 버킷을 생성한다.
  - 모든 term에 대해 페이지네이션으로 전부 순회하며 집계 하려고 한다면 composite 집계를 사용하는게 좋다.

    ```elixir
      GET kibana_sample_data_logs/_search
      {
        "size": 0,
        "query": { "match_all": {} },
        "aggs": {
          "my-agg-name": {
            "terms": {
              "field": "host.keyword",
              "size": 10
            }
          }
        }
      }
    ```

### 4.5 서비스 코드에서 ES 클라이언트 사용

- JVM에서 ES를 사용하는 코드 예시가 나오니 필요할 때 정리하자.

## 5. 서비스 환경에 클러스터 구성

### 5.1 운영 환경을 위한 설정과 클러스터 구성

#### 노드 설정과 역할

- ES 노드에는 역할이 있다. 이 역할에 따라 노드가 클러스터 내에서 어떤 작업을 담당할지 정해진다.
- **주요 노드 역할**은 다음과 같다.
  - **마스터 후보 노드**
    - 노드 역할에 master를 지정하면 해당 노드는 마스터 후보 노드가 된다.
    - 마스터 후보 노드 중에 선거로 마스터 노드가 선출된다. 마스터 노드는 클러스터를 관리하는 역할을 수행한다.
    - 인덱스 생성이나 삭제, 어떤 샤드를 어떤 노드에 할당한지 선택한다.
  - **데이터 노드**
    - 실제 데이터를 들고 있는 노드
  - **조정 노드**
    - 클라이언트의 요청을 받아 다른 노드에 분배하고 최종 응답을 돌려준다.
- 그 외 내용으로 ES 설치 및 운영 관점에서 아래 내용을 담고 있으니 필요한 시점에 다시 공부해서 정리하자.
  - config/elasticsearch.yml 주요 설정
  - 힙 크기
  - 스와핑 끄기
  - JVM 설정

### 5.2 클러스터 구성전략

#### 마스터 후보 노드와 데이터 노드를 분리

- **규모가 큰 서비스**를 위해 클러스터를 운영한다면 **마스터 후보 노드와 데이터 노드를 분리**시켜야 한다. ES 운영 상황에서는 **상대적으로 데이터 노드가 죽을 확률이 높다**. 만약 마스터 역할과 데이터 역할을 분리해 두지 않았다면 마스터 역할이 제대로 수행되지 않아 클러스터 안정성이 매우 크게 떨어진다.
- 만약 마스터 후보 노드와 데이터 노드가 분리되어 있었다면 데이터 노드 하나만 죽는다. 이후 마스터 노드가 자연스럽게 문제를 복구하고 서비스의 고가용성도 유지된다.
- 장애 대응을 위해 특정 노드를 재시작할 때도 장애 원인에 따라 마스터 노드와 데이터 노드를 재시작해야 하는 상황이 다르다. 데이터 노드를 재시작할 필요가 없는데 재시작한다면 불필요한 샤드 복구 과정이 수행된다. 이때 생기는 부하가 장애 상황인 클러스터를 더 심각한 상황으로 몰아갈 수 있다. 마스터 노드를 재시작할 필요가 없는데 재시작한다면 불필요한 마스터 재선출 과정이 발생한다. 따라서 서버를 적게 써야 하는 상황이 아니라면 마스터 후보 노드와 데이터 노드를 분리하는 것이 낫다.

#### 마스터 후보 노드와 투표 구성원

- 클러스터가 운용되는 동안 마스터 노드가 선출되어 있어야 한다. 이런 마스터 노드를 선출하는 집단이 바로 투표 구성원이다. **마스터 후보 노드는 홀수대를 준비하는 것이 비용대비 효용성**이 좋다.

#### 서버 자원이 많지 않은 경우

- 적어도 노드 3대가 확보되야 클러스터를 구성하는 의미가 있다. 마스터 후보 역할을 하는 노드가 최소 3대, 데이터 역할을 하는 노드가 최소 3대 확보돼야 기본적인 고가용성이 제공되기 때문이다.
- **최소의 서버 자원**으로 ES 클러스터를 구성한다면 **3대의 노드가 모두 마스터 후보 역할과 데이터 역할을 겸임하는 구성**이 된다.
- **장비 6대부터는 마스터 후보 노드와 데이터 노드를 완전히 분리**할 수 있다. 따라서 일반적으로 분리하는 편이 서비스 안정성 면에서 훨씬 이득이다.

### 5.3 보안 기능 적용

- 보안설정과 TLS 적용을 통해 통신데이터 암호화, 인증서 설정을 학습할 수 있다. 필요한 시점에 정리하자.

## 6. 클러스터 운영

### 6.1 클러스터 설정 API

- ES 운영 중 **설정을 동적으로 변경**해야 할 때가 있다. 클러스터 설정 API는 그런 상황에서 클러스터와 관련된 설정을 확인 및 변경할 수 있는 API다. 먼저 클러스터 설정은 다음 방법으로 확인한다.

  ```elixir
    GET _cluster/settings
  ```

### 6.2 cat API를 통한 클러스터 관리와 모니터링

- cat API는 ES의 현재 상태를 조회할 수 있는 API다. 관리 목적이나 **모니터링 용도로 cat API를** 자주 사용하게 되는데 몇 가지를 소개하면 아래와 같다.

  ```elixir
    GET _cat/health # 클러스터의 전반적인 상태 조회
    GET _cat/indices # 인덱스의 종류와 상태 확인
    GET _cat/nodes # 각 노드의 상태 조회
    GET _cat/shards # 샤드의 상태 조회
    GET _cat/segments # 루씬 세그먼트 상태 조회
    GET _cat/recovery # 진행중 or 완료된 샤드 복구 작업에 대한 정보 조회
    GET _cat/allocation # 샤드 할당과 관련된 정보를 조회
    GET _cat/master # 현재 마스터 노드 확인
  ```

### 6.3 인덱스 운영전략

- 템플릿과 명시적 매핑 활용
  - 실제 서비스를 운영할 때 매핑이 동적으로 생성되도록 하기보다 최대한 **명시적으로 매핑을 지정하는게 좋다**.
- 라우팅 활용
  - 라우팅 지정은 성능을 유의미하게 상승 시킨다.
- 시계열 인덱스 이름
  - 인덱스 이름에 api-example-20231023과 같은 시간표현이 들어간 인덱스를 생성하자.
  - 이렇게 생성하면 오래된 데이터를 백업하고 삭제하는 것이 편하다.
- alias
  - 인덱스를 다른 이름으로 가리키도록 하는 기능이다.
- reindex

  - 원본 인덱스 문서의 `_source`를 읽어서 대상 인덱스에 새로 색인하는 작업

    ```elixir
      POST _reindex
      {
        "source": {
          "index": "source_index"
        },
        "dest": {
          "index": "target_index"
        },
        "conflicts": "abort"
      }
    ```

  - 작업 도중에 버전 충돌이 일어나면 해당 부분까지 진행되고 취소된다. 이를 원치 않으면 conflicts 값을 proceed로 지정해야 한다. 이 경우 충돌이 발생한 문서는 건너띄고 다음 작업을 진행한다. 기본값은 abort다.
  - 검색 쿼리를 지정해서 걸린 일부 문서만을 재인덱싱할 수 있고, painless 스크립트를 이용해서 재인덱승 작업의 상세 동작을 변경할 수 있다.

### 6.4 샤드 운영 전략

#### 샤드의 크기와 개수 조정

- 클러스터에 **샤드 숫자가 너무 많으면 클러스터 성능이 떨어진다**. 그렇다고 샤드 숫자를 적게 지정하면 샤드 하나의 크기가 커져서 재기동이나 장애 상황에서 샤드 복구 등에 많은 시간이 소요된다.
- ES 가이드에서는 샤드 하나당 20~40GB가 적절하다고 소개하지만 저자의 경험상으로 **샤드 하나의 크기가 20GB만 되어도 꽤 느리고 무겁다**. 샤드의 크기는 cat API로 확인할 수 있다.
  - `GET _cat/shards?v&s=store:desc`

#### 모든 노드가 충분히 일을 하고 있는지

- ES의 샤드는 분산처리를 위해 생긴 개념이다. 전체 샤드 개수를 줄이는 것을 생각하면 분산처리의 강점을 충분히 살리지 못할 수도 있다. 노드 대수가 n대라면 **number_of_shards**를 n의 배수로 지정해 모든 노드가 작업을 고르게 분산받도록 설정하는 방법이 사용된다.

#### 미래에 데이터가 커질 것을 우려

- 인덱스 이름에 시간값을 넣어 정기적으로 신규 인덱스를 생성하면 템플릿에 number_of_shards 값을 변경해서 문제를 어느정도 유연하게 대처할 수 있다. 그러나 단일 인덱스에 담고 있다면 지켜보다 reindex를 할 수 밖에 없다.

### 6.5 롤링 리스타트

- ES 운영 중에는 **롤링 리스타트**를 수행할 일이 많다. 동적으로 변경할 수 없는 설정을 적용하거나 플러그인 설치 및 삭제, ES 버전 업그레이드 등 다양한 상황에서 롤링 리스타트가 필요하다.
- 롤링 리스타타는 크게 **`샤드 할당 비활성화 -> flush 수행 -> 노드 재기동 -> 샤드 할당 활성화 -> green 상태 대기`** 순으로 수행된다.

### 6.6 스냅샷과 복구

- **스냅샷은** ES 클러스터의 **인덱스를 백업**하는 방법이다. ES는 데이터를 파일 기반으로 저장하지만 ES는 **파일시스템에서 데이터를 복구하는 방법을 지원하지 않기 때문에** 동작중인 ES의 데이터를 백업하고 복구하는 기능은 스냅샷을 사용하는게 좋다.
- 스냅샷 설정부터 등록과 조회 삭제까지 내용을 다루고 있으니 필요할 때 참고하자.

### 6.11 슬로우 로그 설정

- 검색이나 색인 작업시 **시간이 오래 걸리면 별도로 로그를 남기도록 설정**할 수 있다. 이런 슬로우 로그는 장애 원일을 추적하는데 큰 도움이 된다. 기본 설정이 없으므로 직접 설정해야 한다. 느린 검색 로그는 다음과 같이 설정한다.

  ```elixir
    PUT _settings
    {
      "index.search.slowlog": { # 느린 검색
        "threshold": {
          "query.warn": "10s",
          "query.info": "5s",
          "query.debug": "2s",
          "fetch.warn": "1s"
        }
      },
      "index.indexing.slowlog": { # 느린 색인
        "source": "1000",
        "threshold": {
          "index.warn": "10s",
          "index.info": "5s",
          "index.debug": "2s"
        }
      }
    }
  ```

### 6.12 버전 업그레이드

- ES 버전업에는 성능이나 안정성이 크게 개선되는 작업이 많기 때문에 버전 업그레이드를 염두해가며 운영하는 것이 좋다. 버전 업그레이드를 하는 과정에서 생각치 못한 원인으로 노드나 클러스터가 제대로 기동되지 않을 수 있기 때문에 사전에 꼼꼼하게 준비해야 한다.
- 업그레이드 방법에는 **롤링 업그레이드**와 **풀 리스타트 업그레이드**가 있다. **롤링 업그레이드는** 노드를 한 대씩 롤링 리스타트 하는 과정에서 **종료한 노드의 버전을 재기동하며 한 대씩 버전을 올리는 방법**이다. 서비스 다운타임도 없고 챙기지 못한 사항이 있어 노드가 기동되지 않아도 문제를 해결할 수 있는 시간이 확보되기 때문에 롤링 업그레이드 가능하다면 이 방법을 선택하는 것이 좋다.
- ES는 득이 많다면 호환성이 손상되는 변경도 감수한다. 버전을 많이 올려야 한다면 공식 홈페이지의 릴리스 노트와 호환성 손상 변경 고지를 점검해야 한다.
- 메이저 버전을 올리는 경우 생각치 못한 문제가 발생할 수 있으니 **항상 개발환경에서 사전 테스트를 해야 한다.**

## 7. 운영 도중 발생하는 장애 대응

### 7.1 장애 징후 탐지를 위한 사전 모니터링 등록

- 매트릭비트와 키바나의 스택 모니터링을 이용해 모니터링 시스템을 갖추고 알림을 받는 내용이 나온다. 필요할때 공부한다.

### 7.2 장애 발생시 대응

- 모니터링 도구나 **cat API**를 호출해서 상태를 확인한다. 모든 노드가 클러스터에 붙어 있는지 미할당 샤드가 생겼는지 확인하는 것이 중요하다.
- `GET _cat/health`나 `GET _cat/nodes` 수행 결과 클러스터의 노드의 수가 원래 있어야 할 노드 수보다 적다면 **샤드 할당을 끄는 것이 중요하다.** 노드 하나가 클러스터에 빠지면 그 노드가 가지고 있던 샤드의 수만큼 복제본 샤드의 수도 줄어든다. 이 경우 ES는 인덱스 설정에 지정된 **`number_of_replicas를`** 맞추기 위해 새 복제본 샤드를 할당하고 데이터 복제 작업을 수행한다. 장애 상황은 클러스터의 부하가 높기 때문에 복제본 샤드 할당은 연쇄적인 장애를 일으키기 때문에 샤드 할당을 비활성화 해야 한다.
- 샤드 할당을 비활성화한 뒤에는 클라이언트의 트래픽을 차단하는 것이 좋다. 이는 클러스터의 리소스를 장애 복구에 집중할 수 있게 해준다.
- 샤드 할당 비활성화와 클라이언트 트래픽 차단을 끝냈으면 cat API를 수행하거나 프로세스가 올라가 있는지를 확인하고 로그를 통해 어떤 문제가 있는지 장애의 원인을 파악해야 한다.
- 장애 원인을 해소하고 클러스터 상태를 정상적으로 돌리기 위해 샤드 할당을 다시 활성화하고 클라이언트 트래픽을 다시 붙여서 상황을 모니터링 한다.

### 7.3 자주 발생하는 장애 유형

#### 키바나에서 과도한 요청 인입

- 먼저 **통제되지 않은 사용자에게 키바나를 열지 않아야 한다**. 사용자가 무거운 대시보드를 구성해서 조회기간을 길게 잡고 짧은 주기로 리프레시를 걸면 순식간에 클러스터를 죽게 만들 수 있다.
- 슬로우 로그를 보면 키바나가 자동 생성하는 ES 쿼리는 사람이 작성한 쿼리와 달리 깔끔하지 않고 불필요한 속성이 많기 때문에 금방 알아볼 수 있다.

#### GC로 인한 stop-the-world

- 빠르게 샤드 할당을 비활성화 하고 트래픽 유입을 막은 뒤 문제되는 노드를 재기동하는 방향으로 대응한다.
- 메모리 서킷 브레이커가 추가된 최신 버전의 ES는 이런 문제 발생 빈도가 개선됬다. 7 버전 미만의 오래된 버전을 운영하고 있다면 메이저 버전 업그레이드를 고려하자.

#### 디스크 풀 상황

- 비교적 사전 모니터링을 통해 회피하기 쉽다. **`GET _cat/indices?v&s=store.size:desc`** 명령어를 통해 사이즈가 큰 인덱스를 확인하고 삭제할 수 있는 파일 인덱스인지 확인해서 디스크를 비운다.

#### 미할당 샤드가 남았는데 샤드 할당이 진행되지 않는 상황

- 장애 상황 처리나 설정 변경으로 노드를 재기동한 뒤 샤드 복구 단계에서 클러스터가 green 상태로 돌아오지 않을 때 **`GET _cluster/allocation/explain`** 명령어를 통해 미할당 샤드의 할당을 더 진행하지 않는 이유를 파악한다.
- 샤드 할당 실패 원인은 다양한데 가장 많이 발생하는 최대 재시도 횟수에 도달한 경우 바로 재할당을 요청하면 된다.

#### 댕글링 인덱스

- 클러스터가 노드에 합류할 때 로컬 데이터에는 샤드 데이터가 있는데 클러스터의 메타 데이터에는 해당 인덱스와 샤드 정보가 없을 경우 ES는 이들을 댕글링 인덱스와 샤드로 취급한다. 이 외에도 마스터 노드에 심각한 문제가 발생해서 메타데이터가 깨지고 각 노드의 로컬 데이터와 메타데이터가 맞지 않을 경우 발생할 수 있는데 이 경우는 심각해진다.

#### 날짜가 넘어가는 순간 대량으로 새 인덱스가 생성되며 부하가 몰려 죽는 상황

- cron이나 배치 작업 도구에서 비어있는 인덱스를 생성하는 시간을 분산해 위험을 회피할 수 있다.

#### 특정 노드의 성능이 떨어지는 상황

- 해당 노드의 **서버 로그와 GC 로그를 확인**한다. 슬로우 로그를 확인해 무거운 쿼리가 인입되었는지 확인하고 재기동으로 개선될 것 같으면 재기동을 고려한다.
- 지속적이고 일관적으로 성능이 떨어지면 샤드 배분 상태를 확인하고 해당 노드에 부하가 많이 몰릴 사유가 있는지 확인한다.

### 7.4 샤드 복구 전략

- 장애로 노드가 클러스터에 빠질 때, 노드를 재기동할 때, 정적인 설정이나 플러그인을 설치하기 위해 롤링 리스타트를 할때에도 샤드 복구 과정은 반드시 따라온다. 데이터의 규모가 큰 클러스터를 운영한다면 샤드 복구에 굉장히 많은 시간이 소요된다. 즉 샤드 복구를 얼마나 잘, 빨리 끝내느냐는 운영의 안정성을 좌우한다.
- 우선 앞에서 설명했듯 **너무 큰 샤드를 만들지 않도록 주의**한다.
- 샤드 복구의 진행 상황은 인덱스 복구 API를 호출해서 확인한다. human 매개변수를 지정하면 읽기 쉬운 형태로 추가 변환해준다.
  - `GET _recovery?human`

### 7.5 원활한 장애 복구를 위한 서비스 구조 설계

#### 앞쪽에 메시지 큐를 둔다

- **서비스가 ES에 직접 색인 요청을 하는 것보다 앞쪽에 메시지 큐를 두는 것이 좋다.** 서비스에서 색인할 데이터가 발생하면 메시지 큐에 데이터를 넣고, 별도의 시스템이 메시지 큐에서 데이터를 꺼내 ES에 색인하도록 구축한다.
- 이런 설계는 **문제 상황 시, 메시지 큐에서 데이터를 꺼내 ES에 색인하는 작업만 내리면 자연스럽게 추가 색인 작업을 차단할 수 있다.** 또 서비스는 지속적으로 데이터를 생산해 메시지 큐에 담을 수 있으며 결과적으로 서비스와 ES의 결합이 느슨해진다.

#### 멱등하게 설계한다

- 메시지 큐를 두고 데이터를 재처리할 때 항상 **데이터를 재처리한 결과가 멱등하도록 설계**해야 한다.
- bulk API로 ES에 색인하던 클라이언트가 중간에 죽어버릴 경우 ES가 데이터를 제대로 색인했는지 확신하기 어렵다. **데이터 재처리가 멱등하게 설계되었다면 메시지 큐에서 데이터를 넉넉하게 꺼내와 재처리**하면 그만이다. 그러나 멱등하게 설계되지 않았다면 어떤 요청까지 성공하고 실패했는지를 구분해야 한다.

#### 용도나 중요도 별로 클러스터를 분리해야 한다

- 서비스에 사용할 **데이터를 저장할 NoSQL 용도로 사용할지, 서비스 로그를 수집하는 용도로 사용할지를 파악**해야 한다. 만약 서비스에 직접 사용할 데이터와 지표를 뽑기위한 데이터를 같은 클러스터에 넣고 운영할 경우, 지표를 뽑기 위한 키바나 작업이 장애를 유발시켜 서비스의 장애로 이어진다. 클러스터를 분리해야 장애의 전파 영향이 줄어든다.

## 8. ES 내부 동작 상세

### 8.1 ES의 데이터 분산처리 과정

#### 쓰기 작업 시 ES 동작과 동시성 제어

- 쓰기 작업은 **`조정 단계 -> 주 샤드 단계 -> 복제 단계의 3단계로`** 수행된다. ES 클러스터에 쓰기 요청이 들어오면 먼저 라우팅을 통해 어느 샤드에 작업할지를 파악한다. 몇 번 샤드에 작업할지가 확인되면 해당 샤드 중에서 현재 주 샤드를 찾아 작업을 넘겨준다.
- 주 샤드는 먼저 요청에 문제가 있는지 검증하고 문제가 없다면 로컬에서 쓰기 작업을 수행한다. 작업이 완료되면 각 복제본 샤드로 요청을 넘긴다. **마스터 노드는 복제받을 샤드 목록을 관리하고 있는데 이 목록을 in-sync 복제본**이라고 한다. 주 샤드는 in-sync 복제본에 병렬적으로 요청을 넘긴다. 이후 모든 복제본이 작업을 성공하면 주샤드에 응답을 돌려준다.
- **낙관성 동시제어**
  - 주 샤드의 변경 내용은 복제본 샤드로 복제된다. 한 문서의 views 필드 값을 1로 색인했다면 잠시 후 복제본에게도 적용된다. 그런데 복제본 샤드에 적용되기 전에 다른 클라이언트에서 views 필드 값을 2로 색인하는 작업이 발생한다면 **분산시스템 특성 상 두 요청 중 어떤 요청이 먼저 복제본 샤드로 들어올지는 보장할 수 없다**.
  - veiws를 2로 색인하는 요청이 먼저 들어오고 1로 색인 요청이 나중에 들어온다면 복제본에서 **최종 값이 1로 역전될 수 있는데** 이런 현상을 막기 위해 ES는 **`_seq_no`** 가 존재한다.
  - `_seq_no`는 주 샤드마다 들고 있는 시퀀스 숫자 값으로 매 작업마다 1씩 증가하고 ES는 문서를 색인할 때 이 값을 함께 저장한다. **주 샤드에 들어온 변경 내용은 복제본 샤드로 전송될 때 분산 네트워크 특성상 요청이 역전될 수 있다.** 하지만 복제본 샤드는 **색인된 `_seq_no` 값 보다 작은 `_seq_no`가 들어오면 작업을 수행하지 않기 때문에 역전 적용을 방지한다.**
- 버전

  - ES의 `_version` 값은 동시성을 제어하기 위한 메타데이터로 기본적으로 1부터 시작해서 수정될 때 마다 1씩 증가한다. `_version`이 `_seq_no`와 다른 점은 클라이언트가 문서의 `_version`을 직접 지정할 수 있다는 점이다.
  - 특별히 설정하지 않아도 자동으로 붙는 version_type은 internal이라고 하며 version_type을 external로 설정하면 더 높은 버전으로만 업데이트가 가능하다. 이를 이용해 명시적으로 동시적 제어를 할 수 있다.
  - version_type 종류

    - **internal**: ES가 자동으로 매기며 클라이언트가 명시적으로 지정할 수 없다.
    - **external**: 클라이언트가 명시적으로 지정하며 기존 문서의 버전보다 새 문서의 버전이 큰 경우 색인 수행
    - **external_gte**: external과 동일하지만 새 문서의 버전이 크고 같은 경우에 색인 수행

    ```elixir
      PUT concurrency_test/_doc/1 # 문서 생성
      {
        "views": 0
      }

      # 버전을 3으로 수정
      PUT concurrency_test/_doc/1?version=3&version_type=external
      {
        "views": 0
      }

      # 버전을 2로 작은 버전으로 업데이트시 에러
      PUT concurrency_test/_doc/1?version=2
      {
        "views": 0
      }
    ```

#### 읽기 작업 시 ES 동작

- 클라이언트로부터 읽기 작업을 요청받은 **조정 노드**는 라우팅을 통해 적절한 샤드를 찾아 요청을 넘긴다.
- 쓰기 작업과 다르게 주 샤드가 아니라 복제본 샤드로 요청이 넘어갈 수 있다. 검색이 다수의 문서를 요청할 경우 다수의 샤드에 요청을 넘겨줄 수도 있다. 요청을 받은 각 샤드는 읽기 작업을 수행한뒤 결과를 조정 노드로 돌려준다.
- 읽기 요청의 경우 주 샤드에는 색인이 됐지만 특정 복제본에는 반영이 완료되지 않은 데이터를 읽을 수 있다는 걸 알아야 한다.

#### 체크 포인트와 샤드 복구 과정

- 특정 노드가 재기동되면 그 노드가 들고 있던 샤드에 복구 작업이 진행된다. 이 과정에서 복구 중인 샤드가 현재 주 샤드의 내용과 일치하는지 파악할 필요가 있다. 재기동 되는 동안 주 샤드에 색인 작업이 있었다면 그 내용을 복구 중인 샤드에도 반영해야 할 것이다.
- 문서 색인시 `_seq_no`와 `_primary_term`이 있는데 이를 조합해서 샤드와 샤드 사이에 어떤 차이점이 있는지 알 수 있다. 만약 `_seq_no가` **`1,2,3,5,7인`** 작업을 수행한 샤드는 **로컬 체크포인트 값을 3으로 기록**한다. 3번 작업까지는 빠짐없이 반영되었다는 뜻이다. 이후 복제본 샤드가 4번을 수신하면 로컬 체크 포인트를 5로 업데이트 한다.
- 주 샤드는 각 복제본 샤드로부터 받은 로컬 체크포인트를 비교하여 **가장 낮은 값을 글로벌 체크포인트로 기록한다. 해당 작업까지는 모든 샤드에 반영 완료됐다는 것을 나타낸다**. 글로벌 체크포인트가 업데이트 되면 다음 색인 작업시 주 샤드가 복제본 샤드로 전달한다.
- 문제가 발생해 샤드를 복구하는 경우 ES는 샤드 간 글로벌 체크포인트를 비교한다. **주 샤드와 복제본 샤드의 글로벌 체크 포인트가 같다면 이 샤드는 추가 복구 작업이 필요없다.** 글로벌 체크 포인트가 차이 난다면 두 샤드간 체크포인트를 확인해서 필요한 작업만 재처리 후 복구한다.

### 8.2 ES 검색 동작 상세

- 검색 동작에 대해 클래스와 메서드 등 코드 레벨에서 구체적인 설명이 나옴. 필요할 때 학습
